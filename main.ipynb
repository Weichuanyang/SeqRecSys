{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LinearGRU(nn.Module):\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = hidden_units\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = hidden_units)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        \n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            gru_input = torch.cat([users[:,i,:],items[:,i,:]],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        \n",
    "        output_ln = self.linear(ln_input)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rectified Linear User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "class RectifiedLinearGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = hidden_units\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.k1 = nn.Linear(hidden_units+2*emb_size,emb_size)\n",
    "        self.k2 = nn.Linear(hidden_units+2*emb_size,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = hidden_units)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users =  self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            rect_users = rectified_users(self,users[:,i,:],items[:,i,:],h)\n",
    "            gru_input = torch.cat([rect_users,items[:,i,:]],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        output_ln = self.linear(ln_input)\n",
    "\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n",
    "def rectified_users(self,users,items,h):\n",
    "    \n",
    "    k1 = self.k1(torch.cat([users,items,h],dim = -1))\n",
    "    k2 = self.k2(torch.cat([users,items,h],dim = -1))\n",
    "    rect_users = users\n",
    "    rect_users[users<k2] = rect_users[users<k2]*0.2\n",
    "    rect_users[users<k1] = 0\n",
    "    return rect_users\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Attentional User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "class AttentionalLinearGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = hidden_units\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = hidden_units)\n",
    "        self.att_linear = nn.Linear(hidden_units+emb_size*2,emb_size)\n",
    "        torch.nn.init.constant_(self.att_linear.weight,1e-6)\n",
    "        torch.nn.init.constant_(self.att_linear.bias,1e-6)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            attention = F.sigmoid(self.att_linear(torch.cat([users[:,i,:],items[:,i,:],h],dim = -1)))\n",
    "            gru_input = torch.cat([attention*users[:,i,:],(1-attention)*items[:,i,:]],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        output_ln = self.linear(ln_input)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multi-head Attentional User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / np.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class MHLinearGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users,n_items, emb_size=1000,head_num = 5,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = emb_size\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = self.hidden_units)\n",
    "        #self.att_linear = nn.Linear(hidden_units+emb_size*2,emb_size)\n",
    "#         torch.nn.init.constant_(self.att_linear.weight,1e-6)\n",
    "#         torch.nn.init.constant_(self.att_linear.bias,1e-6)\n",
    "        self.linear = nn.Linear(self.hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        self.user_attention = MultiHeadedAttention(head_num, self.emb_size)\n",
    "        self.item_attention = MultiHeadedAttention(head_num, self.emb_size)\n",
    "        self.bn_user = nn.BatchNorm1d(self.emb_size)\n",
    "        self.bn_item = nn.BatchNorm1d(self.emb_size)\n",
    "        self.bn_last = nn.BatchNorm1d(self.emb_size)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            #attention = F.sigmoid(self.att_linear(torch.cat([users[:,i,:],items[:,i,:],h],dim = -1)))\n",
    "            attnd_users = self.user_attention(items[:,i,:],h,users[:,i,:]).squeeze(1)\n",
    "            attnd_items = self.item_attention(users[:,i,:],h,items[:,i,:]).squeeze(1)\n",
    "            attnd_users = self.bn_user(attnd_users)\n",
    "            attnd_items = self.bn_item(attnd_items)\n",
    "            gru_input = torch.cat([attnd_users,attnd_items],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        output_ln = self.linear(ln_input)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_test_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9a1f49a1970e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_test_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mml_train_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mml_val_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mml_test_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_test_users' is not defined"
     ]
    }
   ],
   "source": [
    "n_users = int(ml_test_users.max()+1)\n",
    "n_items = int(np.max([ml_train_items.max()+1,ml_val_items.max()+1,ml_test_items.max()])+1)\n",
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10678])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# network = MHLinearGRU(n_users=3,n_items=3,emb_size=20).to(device)\n",
    "network = MHLinearGRU(n_users=n_users,n_items=n_items).to(device)\n",
    "\n",
    "users = np.array([[1,1,1,1,1],\n",
    "                  [2,2,2,2,2]])\n",
    "items = np.array([[0,1,2,1,1],\n",
    "                  [0,2,2,1,0]])\n",
    "pred = network(Variable(torch.LongTensor(users)).to(device),Variable(torch.LongTensor(items)).to(device))\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens Prerocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and provided functions\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import wget\n",
    "from io import StringIO \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from tqdm import tqdm # Very useful library to see progress bar during range iterations: just type `for i in tqdm(range(10)):`\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "\n",
    "def drop_unused_items(train,val,test):\n",
    "    train_items = train.itemid.unique()\n",
    "    val_items = val.itemid.unique()\n",
    "    test_items = test.itemid.unique()\n",
    "    \n",
    "    droped_items = list((set(val_items)|set(test_items)) - set(train_items))\n",
    "    val_mask = val.userid == droped_items[0]\n",
    "    test_mask = test.userid == droped_items[0]\n",
    "    for droped_item in droped_items:\n",
    "        val_mask += val.itemid==droped_item\n",
    "        test_mask += test.itemid==droped_item\n",
    "    val = val[~val_mask]\n",
    "    test = test[~test_mask]\n",
    "    return val,test\n",
    "\n",
    "def move_timestamps_to_end(x,max_order):\n",
    "    new_order = x.groupby('timestamp', sort=True).grouper.group_info[0]\n",
    "    x[\"timestamp\"] = (max_order - new_order.max())+new_order\n",
    "    return x\n",
    "\n",
    "def normalize_timestamp(x):\n",
    "    x[\"timestamp\"] = x.groupby(['timestamp','itemid'], sort=True).grouper.group_info[0]\n",
    "    return x\n",
    "\n",
    "def set_timestamp_length(x):\n",
    "    x['length'] = len(x)\n",
    "    return x\n",
    "\n",
    "def to_coo(data):\n",
    "        \n",
    "    user_idx, item_idx, feedback = data['userid'], data['itemid'], data['rating']\n",
    "    return user_idx, item_idx, feedback\n",
    "\n",
    "def to_matrices(data):\n",
    "    data = split_by_groups(data)\n",
    "    \n",
    "    data_max_order = data['timestamp'].max()\n",
    "    data = data.groupby(\"index\").apply(move_timestamps_to_end,data_max_order)\n",
    "\n",
    "    data_shape = data[['index', 'timestamp']].max()+1\n",
    "    data_matrix = sp.sparse.csr_matrix((data['itemid'],\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    mask_matrix = sp.sparse.csr_matrix((np.ones(len(data)),\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    \n",
    "    data_users = data.drop_duplicates(['index'])\n",
    "    user_data_shape = data_users['index'].max()+1\n",
    "    user_vector = sp.sparse.csr_matrix((data_users['userid'],\n",
    "                                   (data_users['index'],np.zeros(user_data_shape))),\n",
    "                                    shape=(user_data_shape,1), dtype=np.float64).todense()\n",
    "    user_matrix = np.tile(user_vector,(1,data_shape[1]))\n",
    "    return data_matrix, mask_matrix, user_matrix\n",
    "\n",
    "def train_val_test_split(data,frac):\n",
    "    data = data.groupby(\"userid\").apply(set_timestamp_length)\n",
    "    max_time_stamp = data['length']*frac\n",
    "    timestamp = data['timestamp']\n",
    "    data_train = data[timestamp<max_time_stamp*0.9].groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_val = data[(0.9*max_time_stamp<=timestamp)&(timestamp<0.95*max_time_stamp)]                                                       \n",
    "    data_test = data[(0.95*max_time_stamp<=timestamp)&(timestamp<=max_time_stamp)]\n",
    "    \n",
    "    data_val, data_test = drop_unused_items(data_train,data_val,data_test)\n",
    "    data_val, data_test = data_val.groupby(\"userid\").apply(normalize_timestamp),\\\n",
    "                          data_test.groupby(\"userid\").apply(normalize_timestamp)\n",
    "        \n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "def split_by_groups(data,group_length=20):\n",
    "    data[\"group\"] = data['timestamp']//group_length\n",
    "    data[\"timestamp\"] = data['timestamp']%group_length\n",
    "    data[\"index\"] = data.groupby(['userid','group'], sort=False).grouper.group_info[0]\n",
    "    return data\n",
    "\n",
    "def get_prepared_data(data,frac = 1):\n",
    "    print(\"Normalizing indices to avoid gaps\")\n",
    "    # normalize indices to avoid gaps\n",
    "    data['itemid'] = data.groupby('itemid', sort=False).grouper.group_info[0]\n",
    "    data['userid'] = data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    data = data.groupby(\"userid\").apply(normalize_timestamp)\n",
    "\n",
    "    # build sparse user-movie matrix\n",
    "    print(\"Splitting into train, validation and test parts\")\n",
    "    \n",
    "    data_train, data_val, data_test = train_val_test_split(data,frac)\n",
    "    \n",
    "    user_idx, item_idx, feedback =  to_coo(data_train.copy())\n",
    "    \n",
    "    train_items, train_mask, train_users= to_matrices(data_train.copy())\n",
    "    val_items, val_mask, val_users = to_matrices(data_val.copy())\n",
    "    test_items, test_mask, test_users = to_matrices(data_test.copy())\n",
    "    \n",
    "    \n",
    "    print('Done.')\n",
    "    return (train_items, train_mask, train_users),\\\n",
    "           (val_items, val_mask, val_users),\\\n",
    "           (test_items, test_mask, test_users),\\\n",
    "           (user_idx, item_idx, feedback)\n",
    "        \n",
    "\n",
    "def get_movielens_data():\n",
    "    '''Downloads movielens data, normalizes users, timesteps and movies ids,\n",
    "    returns data in sparse CSR format.\n",
    "    '''\n",
    "    print('Loading data into memory...')\n",
    "    with zipfile.ZipFile(\"ml-10m.zip\") as zfile:\n",
    "        zdata = zfile.read('ml-10M100K/ratings.dat').decode()\n",
    "        delimiter = ';'\n",
    "        zdata = zdata.replace('::', delimiter) # makes data compatible with pandas c-engine\n",
    "        ml_data = pd.read_csv(StringIO(zdata), sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'movieid' ,'rating','timestamp'],\n",
    "                                  usecols=['userid', 'movieid','rating','timestamp'])\n",
    "        ml_data['itemid'] = ml_data['movieid']\n",
    "    return ml_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory...\n",
      "Normalizing indices to avoid gaps\n",
      "Splitting into train, validation and test parts\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "ml_data = get_movielens_data()\n",
    "\n",
    "(ml_train_items, ml_train_mask,ml_train_users),\\\n",
    "(ml_val_items, ml_val_mask,ml_val_users),\\\n",
    "(ml_test_items, ml_test_mask,ml_test_users),\\\n",
    "(ml_train_user_idx, ml_train_item_idx, ml_train_feedback) = get_prepared_data(ml_data)\n",
    "\n",
    "# np.save(\"ml_train_items\",ml_train_items)\n",
    "# np.save('ml_train_mask',ml_train_mask)\n",
    "# np.save('ml_train_users',ml_train_users)\n",
    "# np.sarvalve('ml_val_items',ml_val_items)\n",
    "# np.save('ml_val_mask',ml_val_mask)\n",
    "# np.save('ml_val_users',ml_val_users)\n",
    "# np.save('ml_test_items',ml_test_items)\n",
    "# np.save('ml_test_mask',ml_test_mask)\n",
    "# np.save('ml_test_users',ml_test_users)\n",
    "# np.save('ml_train_user_idx',ml_train_user_idx)\n",
    "# np.save('ml_train_item_idx',ml_train_item_idx)\n",
    "# np.save('ml_train_feedback',ml_train_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train_items = np.load(\"ml_train_items.npy\")\n",
    "ml_train_mask = np.load(\"ml_train_mask.npy\")\n",
    "ml_train_users = np.load(\"ml_train_users.npy\")\n",
    "ml_val_items = np.load(\"ml_val_items.npy\")\n",
    "ml_val_mask = np.load(\"ml_val_mask.npy\")\n",
    "ml_val_users = np.load(\"ml_val_users.npy\")\n",
    "ml_test_items = np.load(\"ml_test_items.npy\")\n",
    "ml_test_mask = np.load(\"ml_test_mask.npy\")\n",
    "ml_test_users = np.load(\"ml_test_users.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LastFM Prerocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def get_lastfm_data(frac = 0.1):\n",
    "    with tarfile.TarFile(\"lastfm-dataset-1K.tar\") as tfile:\n",
    "        member = tfile.getmember('lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv')\n",
    "        f = tfile.extractfile(member)\n",
    "        delimiter = '\\t'\n",
    "        lf_data = pd.read_csv(f, sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'timestamp','artid','artname','traid','traname'],\n",
    "                                  usecols=['userid', 'timestamp','artid','artname','traid','traname'])\n",
    "        lf_data['timestamp'] = pd.to_datetime(lf_data['timestamp'])\n",
    "        lf_data['itemid'] = lf_data['traname']\n",
    "        lf_data['rating'] = np.ones(len(lf_data))\n",
    "        lf_data = lf_data[['userid','timestamp','itemid','rating']]\n",
    "        \n",
    "        lf_data.itemid = lf_data.groupby('itemid', sort=False).grouper.group_info[0]\n",
    "        itemid_max = lf_data.itemid.max()\n",
    "        lf_data = lf_data[lf_data.itemid<=itemid_max*frac]\n",
    "        \n",
    "        lf_data = lf_data.drop_duplicates(['userid','timestamp','itemid'])\n",
    "    return lf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_data = get_lastfm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 23:08:57</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:54:10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:52:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:52</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:42:11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:38:31</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:33:28</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:23:45</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:19:22</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user_000001</td>\n",
       "      <td>2009-05-04 13:13:38</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid           timestamp  itemid  rating\n",
       "0  user_000001 2009-05-04 23:08:57       0     1.0\n",
       "1  user_000001 2009-05-04 13:54:10       1     1.0\n",
       "2  user_000001 2009-05-04 13:52:04       2     1.0\n",
       "3  user_000001 2009-05-04 13:42:52       3     1.0\n",
       "4  user_000001 2009-05-04 13:42:11       4     1.0\n",
       "5  user_000001 2009-05-04 13:38:31       5     1.0\n",
       "6  user_000001 2009-05-04 13:33:28       6     1.0\n",
       "7  user_000001 2009-05-04 13:23:45       7     1.0\n",
       "8  user_000001 2009-05-04 13:19:22       8     1.0\n",
       "9  user_000001 2009-05-04 13:13:38       9     1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing indices to avoid gaps\n",
      "Splitting into train, validation and test parts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/expressions.py:179: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lf_data = get_lastfm_data()\n",
    "\n",
    "(lf_train_items, lf_train_mask,lf_train_users),\\\n",
    "(lf_val_items, lf_val_mask,lf_val_users),\\\n",
    "(lf_test_items, lf_test_mask,lf_test_users),\\\n",
    "(lf_train_user_idx, lf_train_item_idx, lf_train_feedback)= get_prepared_data(lf_data)\n",
    "\n",
    "np.save(\"lf_train_items\",lf_train_items)\n",
    "np.save('lf_train_mask',lf_train_mask)\n",
    "np.save('lf_train_users',lf_train_users)\n",
    "np.save('lf_val_items',lf_val_items)\n",
    "np.save('lf_val_mask',lf_val_mask)\n",
    "np.save('lf_val_users',lf_val_users)\n",
    "np.save('lf_test_items',lf_test_items)\n",
    "np.save('lf_test_mask',lf_test_mask)\n",
    "np.save('lf_test_users',lf_test_users)\n",
    "np.save('lf_train_user_idx',lf_train_user_idx)\n",
    "np.save('lf_train_item_idx',lf_train_item_idx)\n",
    "np.save('lf_train_feedback',lf_train_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_train_items = np.load(\"lf_train_items.npy\")\n",
    "lf_train_mask = np.load(\"lf_train_mask.npy\")\n",
    "lf_train_users = np.load(\"lf_train_users.npy\")\n",
    "lf_val_items = np.load(\"lf_val_items.npy\")\n",
    "lf_val_mask = np.load(\"lf_val_mask.npy\")\n",
    "lf_val_users = np.load(\"lf_val_users.npy\")\n",
    "lf_test_items = np.load(\"lf_test_items.npy\")\n",
    "lf_test_mask = np.load(\"lf_test_mask.npy\")\n",
    "lf_test_users = np.load(\"lf_test_users.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml_test_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d29228199571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:2\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# device = torch.device(\"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mn_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_test_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mml_train_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mml_val_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mml_test_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMHLinearGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_users\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_test_users' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "n_users = int(ml_test_users.max()+1)\n",
    "n_items = int(np.max([ml_train_items.max()+1,ml_val_items.max()+1,ml_test_items.max()])+1)\n",
    "network = MHLinearGRU(n_users=n_users,n_items=n_items).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "opt = torch.optim.Adam(network.parameters(),lr =0.001)\n",
    "\n",
    "history = []\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(ml_train_users),torch.LongTensor(ml_train_items),torch.FloatTensor(ml_train_mask))),\\\n",
    "            batch_size=1000,shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(ml_val_users),torch.LongTensor(ml_val_items),torch.FloatTensor(ml_val_mask))),\\\n",
    "            batch_size=1000,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(ml_test_users),torch.LongTensor(ml_test_items),torch.FloatTensor(ml_test_mask))),\\\n",
    "            batch_size=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def validate_lce(network,val_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in val_loader:\n",
    "\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def train_network(network,train_loader,val_loader):\n",
    "    for epoch in range(10):\n",
    "        i=0\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in train_loader:\n",
    "            network.train()\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "\n",
    "            # train with backprop\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(network.parameters(),5)\n",
    "            opt.step()\n",
    "            \n",
    "            if (i+1)%50==0:\n",
    "                val_loss = validate_lce(network,val_loader)\n",
    "                history.append(val_loss)\n",
    "\n",
    "                clear_output(True)\n",
    "                plt.title(\"Validation error\")\n",
    "                plt.plot(history)\n",
    "                plt.ylabel('Cross-entropy Error')\n",
    "                plt.xlabel('#iter')\n",
    "                plt.show()\n",
    "            i+=1\n",
    "            if len(history)==100:\n",
    "                return\n",
    "\n",
    "    val_loss = validate_lce(network,val_loader)\n",
    "    history.append(val_loss)\n",
    "\n",
    "    clear_output(True)\n",
    "    plt.plot(history,label='val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4leWd//H3NycJ2UhCQkhISNiUzSAIUXHDVrRqVayjjto6VVtr++um0/l1atvpPr/pojO2vWzLONqpvVr3utZ9q2JVFJAdUXayQBIgCwnZv78/zkFDDCSBk5yccz6v6+JqzvPcec73nD58uL2f57lvc3dERCS2JES6ABERCT+Fu4hIDFK4i4jEIIW7iEgMUriLiMQghbuISAxSuIuIxCCFu4hIDFK4i4jEoMRIvfHo0aN9woQJkXp7EZGotGzZslp3z+urXcTCfcKECSxdujRSby8iEpXMbFt/2vVrWMbM/tnM1prZGjO718xSeuz/hpmtM7NVZvaimY0/kqJFRCQ8+gx3MysCvg6UuXspEACu7NHsndD+44GHgF+Eu1AREem//l5QTQRSzSwRSAMqu+9095fdvTn08k1gXPhKFBGRgepzzN3dK8zsVmA7sB94zt2fO8yvfB54Okz1iUiMam9vp7y8nJaWlkiXMiylpKQwbtw4kpKSjuj3+wx3MxsFXAxMBOqAB83sanf/Uy9trwbKgDMPcawbgBsASkpKjqhgEYkN5eXljBw5kgkTJmBmkS5nWHF3du/eTXl5ORMnTjyiY/RnWOZsYIu717h7O/AwcGrPRmZ2NvBdYKG7tx6i4Dvcvczdy/Ly+ryTR0RiWEtLC7m5uQr2XpgZubm5R/VfNf0J9+3APDNLs+D/CwuA9T0KOQH4b4LBXn3E1YhIXFGwH9rRfjd9hru7LyF4B8xyYHXod+4wsx+b2cJQs1uADIJDNivM7PGjquow3t3ZwK3PbmBPU9tgvYWISNTr10NM7v4D4Ac9Nn+/2/6zw1nU4WytbeL2lzdy/swCctKTh+ptRUTIyMhg3759/d4eSVE3t0xmavDKcX1ze4QrEREZvqIu3LNTg731+v0KdxE5cjfffDO/+c1vPnj9wx/+kFtvvZV9+/axYMEC5syZw8yZM3nsscf6fUx355vf/CalpaXMnDmT+++/H4Cqqirmz5/P7NmzKS0tZfHixXR2dnLttdd+0Pa2224L6+eL2NwyRyorLdRzV7iLxIwfPbGWdZUNYT3mjMJMfnDRcYfcf8UVV3DTTTfxla98BYAHHniAZ599lpSUFB555BEyMzOpra1l3rx5LFy4sF8XOB9++GFWrFjBypUrqa2t5cQTT2T+/Pncc889nHvuuXz3u9+ls7OT5uZmVqxYQUVFBWvWrAGgrq4uPB88JPrCPTQsU6dwF5GjcMIJJ1BdXU1lZSU1NTWMGjWK4uJi2tvb+c53vsOrr75KQkICFRUV7Nq1i4KCgj6P+dprr3HVVVcRCATIz8/nzDPP5O233+bEE0/kc5/7HO3t7XzqU59i9uzZTJo0ic2bN/O1r32NCy64gE984hNh/XxRF+7pyQESE0w9d5EYcrge9mC6/PLLeeihh9i5cydXXHEFAH/+85+pqalh2bJlJCUlMWHChKN+inb+/Pm8+uqrPPnkk1x77bV84xvf4LOf/SwrV67k2WefZdGiRTzwwAP8/ve/D8fHAqJwzN3MyEpNok4XVEXkKF1xxRXcd999PPTQQ1x++eUA1NfXM2bMGJKSknj55ZfZtq1fM+wCcMYZZ3D//ffT2dlJTU0Nr776KieddBLbtm0jPz+fL3zhC1x//fUsX76c2tpaurq6uPTSS/n3f/93li9fHtbPFnU9dwiOuzeo5y4iR+m4446jsbGRoqIixo4dC8BnPvMZLrroImbOnElZWRnTpk3r9/EuueQS3njjDWbNmoWZ8Ytf/IKCggLuvvtubrnlFpKSksjIyOCPf/wjFRUVXHfddXR1dQHw05/+NKyfzdw9rAfsr7KyMj/SxTou+e3fSU9O5E/XnxzmqkRkqKxfv57p06dHuoxhrbfvyMyWuXtZX78bdcMyANmpSdTt1xOqIiKHEpXhnpWapAuqIiKHEbXhrguqItEvUsPC0eBov5voDPe0ZBpbOujs0okhEq1SUlLYvXu3Ar4XB+ZzT0lJ6bvxIUTn3TKhB5kaW9rJTtPkYSLRaNy4cZSXl1NTUxPpUoalAysxHamoDPfsA0+pNivcRaJVUlLSEa8yJH2LzmGZVM0vIyJyOFEZ7tlpml9GRORw+hXuZvbPZrbWzNaY2b1mltJj/wgzu9/MNprZEjObMBjFHqCeu4jI4fUZ7mZWBHwdKHP3UiAAXNmj2eeBve5+DHAb8PNwF9qdwl1E5PD6OyyTCKSaWSKQBlT22H8xcHfo54eABTaIK99+uBqTnlIVEelNfxbIrgBuBbYDVUC9uz/Xo1kRsCPUvgOoB3LDW+qHUpICpCQlqOcuInII/RmWGUWwZz4RKATSzezqI3kzM7vBzJaa2dKjvbc1OzVZ4S4icgj9GZY5G9ji7jXu3g48DJzao00FUAwQGrrJAnb3PJC73+HuZe5elpeXd1SFawoCEZFD60+4bwfmmVlaaBx9AbC+R5vHgWtCP18GvOSD/EyxJg8TETm0/oy5LyF4kXQ5sDr0O3eY2Y/NbGGo2V1ArpltBL4B3DxI9X4gK03hLiJyKP2afsDdfwD8oMfm73fb3wJcHsa6+pSVmsQahbuISK+i8glVCM4vo567iEjvojbcs1KTaG7rpK2jK9KliIgMO1Eb7gfml1HvXUTko6I23D94SlVrqYqIfETUhrvmlxERObSoDfcDi3Qo3EVEPipqwz2r22pMIiJysKgN92wNy4iIHFLUhnumeu4iIocUteEeSDBGpiSq5y4i0ouoDXcIjrs3KNxFRD4i6sNdi2SLiHxUVId7tmaGFBHpVVSHe3DBDj2hKiLSU5SHezL1+zsiXYaIyLAT5eEevKA6yIs+iYhEnf4skD3VzFZ0+9NgZjf1aJNlZk+Y2UozW2tm1w1eyR/KSk2irbOL/e2dQ/F2IiJRo8+VmNx9AzAbwMwCBBfDfqRHs68A69z9IjPLAzaY2Z/dfVAHxLtP+5uW3K9FpURE4sJAh2UWAJvcfVuP7Q6MDC2gnQHsAQZ9MFzzy4iI9G6g4X4lcG8v228HpgOVBBfRvtHdP7JEkpndYGZLzWxpTU3NgIvtSfPLiIj0rt/hbmbJwELgwV52nwusAAoJDuHcbmaZPRu5+x3uXubuZXl5eUdY8ocyFe4iIr0aSM/9fGC5u+/qZd91wMMetBHYAkwLR4GH88GYu4ZlREQOMpBwv4reh2QAthMcj8fM8oGpwOajK61vWo1JRKR3/brFxMzSgXOAL3bb9iUAd18E/AT4g5mtBgz4lrvXhr/cg2WMSCSQYNRpHVURkYP0K9zdvQnI7bFtUbefK4FPhLe0vpkZeRkj2NXQOtRvLSIyrEX1E6oAJTlpbN/THOkyRESGlagP93E5qexQuIuIHCTqw70kJ42dDS20dmgKAhGRA2Ii3N2hYu/+SJciIjJsRH24F+ekAWjcXUSkm6gP95JQuGvcXUTkQ1Ef7nkZIxiRmMAODcuIiHwg6sM9IcEozklj+2713EVEDoj6cAcoHpWqMXcRkW5iItxLctLYsadZy+2JiITERLgX56TR2NqhCcREREJiJtxBt0OKiBwQE+FeonAXETlITIS7eu4iIgeLiXDPGJFITnoyO/boXncREehHuJvZVDNb0e1Pg5nd1Eu7j4X2rzWzVwan3EMrDt0xIyIi/Visw903EFz0GjMLABXAI93bmFk28FvgPHffbmZjBqHWwyrJSWPljrqhflsRkWFpoMMyC4BN7r6tx/ZPE1wgezuAu1eHo7iBKB6VSmXdfjo6u4b6rUVEhp2BhvuV9L5I9hRglJn9zcyWmdlnj760gSnJSaOjy6mqbxnqtxYRGXb6He5mlgwsBB7sZXciMBe4ADgX+J6ZTenlGDeY2VIzW1pTU3OEJfdOs0OKiHxoID3384Hl7r6rl33lwLPu3uTutcCrwKyejdz9Dncvc/eyvLy8I6v4EHQ7pIjIhwYS7lfR+5AMwGPA6WaWaGZpwMnA+qMtbiDGZqUQSDB27FW4i4j0ebcMgJmlA+cAX+y27UsA7r7I3deb2TPAKqALuNPd1wxCvYeUGEigKDuV7brXXUSkf+Hu7k1Abo9ti3q8vgW4JXylDVxxjqb+FRGBGHlC9YCSnDS27W7S1L8iEvdiKtxnjcumrrmdzbVNkS5FRCSiYircT5yYA8BbW/ZEuBIRkciKqXCfNDqd0RnJCncRiXsxFe5mxkkTcxTuIhL3YircAU6akENF3X7Kdb+7iMSx2Av3icE7Nt/eqt67iMSvmAv3qQUjyUxJ1NCMiMS1mAv3QIJx4oQclijcRSSOxVy4A5w0MYfNNU3UNLZGuhQRkYiIyXA/cL+7xt1FJF7FZLiXFmaRmhTQuLuIxK2YDPfkxATmjM/WuLuIxK2YDHeAkybk8u7OBur3t0e6FBGRIRe74T4xB3fNMyMi8Slmw33O+GzSkwO8vKE60qWIiAy5PsPdzKaa2YpufxrM7KZDtD3RzDrM7LLwlzowIxIDnHFsHi+tr9b87iISd/oMd3ff4O6z3X02MBdoBh7p2c7MAsDPgefCXuURWjB9DDsbWlhb2RDpUkREhtRAh2UWAJvcfVsv+74G/AUYNuMgH582BjN4cf2wKUlEZEgMNNyvBO7tudHMioBLgN+Fo6hwGZ0xgtnF2bz07q5IlyIiMqT6He5mlgwsBB7sZfcvgW+5e1cfx7jBzJaa2dKampqBVXqEFkwbw8ryeqobWobk/UREhoOB9NzPB5a7e2/d4DLgPjPbClwG/NbMPtWzkbvf4e5l7l6Wl5d3RAUP1ILp+QC6a0ZE4spAwv0qehmSAXD3ie4+wd0nAA8BX3b3R8NQ31GbVjCSwqwUXtC4u4jEkX6Fu5mlA+cAD3fb9iUz+9JgFRYuZsaC6fm89n4tLe2dkS5HRGRI9Cvc3b3J3XPdvb7btkXuvqiXtte6+0PhLPJonTV9DPvbO3lj8+5IlyIiMiRi9gnV7k6ZlEtqUoAX1umuGRGJD3ER7ilJAc6aPoanVlfR2qGhGRGJfXER7gD/WFbM3uZ2PdAkInEhbsL99GNGMzYrhfvf3hHpUkREBl3chHsgwbhs7jhefb+Gyrr9kS5HRGRQxU24A1w2dxzu8PDy8kiXIiIyqOIq3MfnpjNvUg4PLC2nq0vTAItI7IqrcIfghdXte5p5a6tWaBKR2BV34X5+6VgyRiTywFJdWBWR2BV34Z6aHOCiWYU8tbqKmsbWSJcjIjIo4i7cAa4/YyKdXc5Pn1of6VJERAZFXIb75LwMvjh/Mg+/U8Hrm2ojXY6ISNjFZbgDfPWsYyjOSeV7j66hreOwa4yIiESduA33lKQAP15YyqaaJv5n8eZIlyMiElZxG+4QXED7vOMK+PWL77NjT3OkyxERCZu4DneAHyycQSDB+NETayNdiohI2PQZ7mY21cxWdPvTYGY39WjzGTNbZWarzex1M5s1eCWH19isVG5ccCwvrK/mxfWa711EYkOf4e7uG9x9trvPBuYCzcAjPZptAc5095nAT4A7wl7pILrutIlMzkvnR0+s01J8IhITBjosswDY5O7bum9099fdfW/o5ZvAuHAUN1SSExP48cWlbN/TzH+/oourIhL9BhruVwL39tHm88DTR1ZO5Jx2zGguPH4sv/3bRl1cFZGo1+9wN7NkYCHw4GHafJxguH/rEPtvMLOlZra0pqZmoLUOuu9eMJ1AgvH9x9bgrlkjRSR6DaTnfj6w3N17vepoZscDdwIXu/vu3tq4+x3uXubuZXl5eQOvdpCNzUrlm+dO5eUNNdz9+tZIlyMicsQGEu5XcYghGTMrAR4G/snd3wtHYZFy7akTWDBtDP/x1LusqaiPdDkiIkekX+FuZunAOQQD/MC2L5nZl0Ivvw/kAr8N3S65NOyVDhEz45bLZ5GTnsxX71nOvtaOSJckIjJg/Qp3d29y91x3r++2bZG7Lwr9fL27jzpwy6S7lw1WwUMhJz2ZX191Atv3NPNvj6zW+LuIRJ24f0L1UE6amMNNZ0/h0RWVPL9ODzeJSHRRuB/Glz82mUl56fzsmXfp6NTMkSISPRTuh5EYSODm86axuaaJ+7Usn4hEEYV7H86Zkc+JE0Zx2/Pv06SLqyISJRTufTAzvv3J6dTua9W87yISNRTu/TCnZBSfnFnAHa9uprqxJdLliIj0SeHeT988dxptHV189Z53qG5QwIvI8KZw76eJo9O55fLjWVVex/m/Wswr7w2/uXFERA5QuA/AJSeM44mvns7ojBFc8/u3+NnT79KuWyRFZBhSuA/Qsfkjeeyrp3HVSSUsemUTV97xJhV1+yNdlojIQRTuRyAlKcBP/2Emv77qBDbsbOSCXy/mBT3FKiLDiML9KCycVcgTXzudouxUrv/jUn7y13W0dWiYRkQiT+F+lCaOTucv/+dUrjllPHe9toXLFr3Ott1NkS5LROKcwj0MUpIC/OjiUhZdPZettU1c+OvXeODtHXR2aTZJEYkMhXsYnVdawFM3nsHUgpH8619Wcc5tr/DYigqFvIgMOYV7mI0blcYDXzyFRVfPISkhgRvvW8H5v3qVlTvqIl2aiMSRPsPdzKaGVlc68KfBzG7q0cbM7NdmttHMVpnZnMErefhLSDDOKx3L0zeewe2fPoF9LR1c+rvX+e3fNqoXLyJDos9wd/cNB1ZYAuYCzcAjPZqdDxwb+nMD8LtwFxqNEhKMC48v5Okb53NuaQG/eGYDn7nzTXbsaY50aSIS4wY6LLMA2OTu23psvxj4owe9CWSb2diwVBgDstKSuP2qE7jlsuNZXV7P2f/1Cr984T1a2jsjXZqIxKiBhvuVwL29bC8Cuq9mUR7adhAzu8HMlprZ0pqa+Jqbxcy4vKyY575xJmfPyOeXL7zPgv8MXnDVFAYiEm79DnczSwYWAg8e6Zu5+x3uXubuZXl5eUd6mKhWlJ3Kbz49h3u/MI+RKYnceN8KTv3ZS/zncxuo1DQGIhImA+m5nw8sd/fenrOvAIq7vR4X2iaHcMrkXJ78+hncdU0ZpYWZ3P7yRk7/+Ut879E17G1qi3R5IhLlEgfQ9ip6H5IBeBz4qpndB5wM1Lt71dEWF+sCCcaC6fksmJ7Pjj3N/M/izfx5yXYeX1nJv3xiCp8+qYTEgO5WFZGBM/e+b80zs3RgOzDJ3etD274E4O6LzMyA24HzCN5Nc527Lz3cMcvKynzp0sM2iUsbdjbyoyfW8vqm3cwal8Xtn55DcU5apMsSkWHCzJa5e1mf7foT7oNB4X5o7s6Tq6v49sOrAfj5pcfzyZm6+UhE+h/u+m/+YcgseH/8U18/g0l5GXz5z8v55oMreXPzbt1ZIyL9op77MNfW0cWtz23g969toaPLyRiRyCmTc/n41DGcNW0MBVkpkS5RRIaQhmViTGNLO69v2s0r79XwyoaaD1Z/mjE2kwuOH8vV88aTlZoU4SpFZLAp3GOYu/N+9T5eXF/Ni+t3sXTbXkaOSOTqU8bzudMmkjdyRKRLFJFBonCPI2sr6/nt3zbx1OoqkgIJnF9awBVlxcyblEtCgkW6PBEJI4V7HNpcs4///ftWHl1RQWNLByU5aVxw/FjOmjaGE4qzdc+8SAxQuMexlvZOnl27kweXlvPm5t10dDlZqUmcfsxo5owfxdzxo5gxNpPkRIW9SLTpb7gP5AlViRIpSQEunl3ExbOLaGhp57X3a3np3Wre2LSbJ1dXhdokcM2pE/jqx49hZIouxIrEGvXc48zO+haWb9/Lc2t38uiKSvJGjuBfz53KpXPGaXxeJApoWEb6tHJHHT98Yi3vbK+jKDuV047J5bRjRnPq5NG640ZkmFK4S790dTl/XV3FU6uqeGPzbur3txNIMC48fixfnD+ZGYWZkS5RRLpRuMuAdXY56yobeHxlBfcs2U5TWyfzp+RxfmkBM4uymJI/UhdhRSJM4S5Hpb65nT8t2cYfXt9KTWMrAMmBBKaPHcms4myOH5fN7OJsJuelE5wUVESGgsJdwsLd2b6nmVXl9ayuqGdVeR2ry+tpaguu/1qUncrZ08ewYHo+J07IITU5EOGKRWKbwl0GTWeXs7lmH0u37eXF9dW8trGGlvYuzKB4VBrHjslg+thM5k3KZe74UQp8kTBSuMuQaWnv5PVNtawub+C96kY27trHxpp9dHY5yYEEZpdkc35pAQtnFZKbobtwRI5GWMPdzLKBO4FSwIHPufsb3fZnAX8CSgg+GHWru//v4Y6pcI9t+1o7eHvrHt4MzWT57s5GEhOMj03N46JZhcw/No9R6cmRLlMk6oQ73O8GFrv7nWaWDKS5e123/d8Bstz9W2aWB2wACtz9kCs9K9zjy7s7G3hkeQWPvFNBdWMrCQazirP52JQxnDI5l1nFWYxI1PCNSF/CFu6hXvkKguun9trYzL4NFANfASYAzwNT3P2QywYp3ONTZ5ezqryOv22o4W/v1bCqvA53GJGYwNzxo7hoViGXnFBESpKCXqQ34Qz32cAdwDpgFrAMuNHdm7q1GQk8DkwDRgJXuPuTvRzrBuAGgJKSkrnbtm3r9weS2FTX3MZbW/bw5uY9LH6/hver95GTnszV88Zz6Zwi8jNTFPQi3YQz3MuAN4HT3H2Jmf0KaHD373VrcxlwGvANYDLBnvssd2841HHVc5ee3J03N+/hrtc288L66g+2pyYFyElPJj9zBGOzUynMSuGkibmcNW0MAc2HI3EmnLNClgPl7r4k9Poh4OYeba4DfhYattloZlsI9uLfGkDNEufMjFMm53LK5Fw21+xjyZY97G1uY29TG7v3tVFV38LainpeWLeL/1m8hQm5aXzu9IlcNnccacma4FSkuz7/Rrj7TjPbYWZT3X0DsIDgEE1320PbF5tZPjAV2Bz2aiVuTMrLYFJeRq/7Ojq7eGbtTu5cvIXvP7aW/3hqPdPHZjJjbCYzCjM5rjCLaQUjNZwjca2/d8vMJngrZDLB0L4OuALA3ReZWSHwB2AsYAR78X863DE1LCPhsGzbXv66qpJ1lQ2sq2qgsaUDgECCceyYDCaPyWDMyBGMGZlCYXaKZryUqKeHmCTuuDvle/eztrKBtZXB6RK27W6muqHlg+kSzGBuySjOmZHPhNHpwW1AbkYyJxSP0pz2MuxpJSaJO2ZGcU4axTlpnFdacNC+ptYOttQ28cL6XTy3dhc/ffrdj/x+UXYq/zCniEtOKGLiaE2IJtFNPXeJS1X1+9nT1MaB039TzT7+sryC196vocshKzWJiaPTmTQ6ndOPHc3Fs4t0Z44MCxqWETkCuxpaeHbtTt7b1ciW2iY2Vu9jV0MrU/Iz+NZ50zhr2hj16CWiNCwjcgTyM1P47CkTPnjt7jy9Zie3PLuBz9+9lCn5GSSYsbe5jbrmdkalJTM+N43xuWlMLcjkjGNHc+yYDP0DIBGnnrtIP7R3dnHf2zt4enUV6SMSGZWWRFZqEnua2tm2u4mtu5up3Rdc1KQgM4V5k3LISPmw73RcYRYXzSokY4T6U3J0NCwjMsTK9zbz2vu1vPp+Dcu27aWjM/h3q6PLqd/fTlpygItnFzJvUi7rKhtYum0vayrqKclJY96kXE6elMPpx4wmO02zZcqhKdxFhgl3550dddz31naeWFnF/vZOkgMJzByXxcyiLDbXNrFs6x6a2joZmZLI//3EVK6eN14XcKVXCneRYaihpZ2ttU1MyT/4CdqOzi5Wltdx2/Pv89rGWo4rzOTfLpjB5Lx0RiQFSElKoKPTaWrroLm1k4yUREZr4ZO4pHAXiULuzpOrq/jJX9exq6H1kO0SDBZMz+fqeeM545jRevgqjuhuGZEoZGZceHwhH5s6hhfX76KxpYOW9k5aO7pITDDSRiSSnhzg/ep9PPD2Dp5ft4ui7FQyU5NoDbVLTkwgJz2ZnPRkirJTOWvaGOZNyiU5MSHSH0+GkHruIlGqtaOTZ9bs5KnVVXR2QUpSAiMSA7R2dLKnqY09TW1s293M/vZOMlMSOWvaGHLSR7C/vZOW9k4KslK4et54irJTI/1RZAA0LCMitLR38tr7tTyzdicvv1tNW0cXKcnBMfzKuhYAzi8t4AtnTGJWcfZHfr92XytVdS2UFmXq3v1hQsMyIkJKUoCzZ+Rz9oz8j+yrrNvPH17fyr1LtvPXVVWUFmVy5YklLJxdSGXdfu5avIXHVlTS1tnFjLGZfPHMSVwwcyyJgY8O77g7bZ1dWgd3GFHPXSTO7Wvt4C/Lyrn3re28u7OR5MQE2jq6SE0KcOncIqYWZPKHv29hU00ThVkpzC7JpiAzlcLsFBpbOlhdUc+q8nr2NLUyb1IuFxw/lvOOKyBXd/MMCg3LiMiAuDuryut55J0K8jNTuOqk4g8eqOrqcl56t5p73trO1t1NVNW1sL+9kwSDY8eMpLQoi9yMZJ5ft4sttU0EEoxpBSMpLcyitCiT7LRkttY2saW2ierGVs4rLeCyueO0oMoRCGu4m1k2wcU6SgEHPufub/Ro8zHgl0ASUOvuZx7umAp3kejl7jTs7yAp0Q5a4tDdWV/VyDNrqnhnRx1rKurZ29z+wf7CrBRSkwNsqmkiNz2Za06dwPjcNNZWNrCusoGKuv2kjwgwckRweofTjsnlwuMLGZWup3YPCHe43w0sdvc7zSwZSHP3um77s4HXgfPcfbuZjXH36kMdDxTuIvHA3amsb6FhfzsTctNJTQ7g7ry1ZQ///epmXno3GBPJiQlMzR9JSW4a+9s6adjfTs2+VrbtbiYpYJw1bQxl43No7eikpb2LprYOqhtaqarfT3VjK9MKMvn0ycWcOSX2F00PW7ibWRawApjkh2hsZl8GCt393/pboMJdRLbWNtHS0cnkvAySerlQu66ygYeXl/PoisoPJmYzg7SkAPmZKRRkpZCbMYI3Nu2mdl8rhVkpnHrMaHY1tFC+dz+1ja3Mn5rHP81DRJa0AAAGR0lEQVQbz8kTc2Lijp9whvts4A6Ci2LPApYBN7p7U7c2B4ZjjgNGAr9y9z8e7rgKdxHpr86u4NQLKYkBkgL2kZBu6+jixfW7uOet7ayvaqAwO5XiUWmkjwjwzJqdNLR0MCU/g3Nm5DNuVBpF2amMyRxBwIzgoYwRiQmkJQdIS04kJSlh2P5DEM5wLwPeBE5z9yVm9iugwd2/163N7UAZsABIBd4ALnD393oc6wbgBoCSkpK527ZtG9inEhEZoP1tnTyxspI/LdnGmop6uvpxD8nojBFcMLOAhbMLmVMyis21TfxtQw1/31jLqLRkLjx+LKcdM5rkxAS21jbx6IoKXnmvhtnF2Xzm5BKOGTNy0D5POMO9AHjT3SeEXp8B3OzuF3RrczOQ6u4/CL2+C3jG3R881HHVcxeRodbR2cWuxlYq9u6nprGVLnec4LWB1o4u9rd10tzWyeqKOl5cX01rRxfpyYEPFlifNDqdmn2tNLZ0kJWaxLhRqaytbMAMjivMZMPORto7nZMn5nDFicWcPSOfzJSksH6GsD3E5O47zWyHmU119w0Ee+frejR7DLjdzBKBZOBk4LYjqFtEZNAkBhIoyk7t15QLjS3tPL9uF29t2UNpURZnTsmjOCeN1o5OFr9Xy5Orq9ixp5nvfHIaF80qZGxWKrX7WnlwafCZgW88sJLkQAJnHDuac48rYEZhJhNHp5M+RAu29PdumdkEb4VMBjYD1wFXALj7olCbb4a2dwF3uvsvD3dM9dxFJFZ1dTkryut4alUVT62uorK+5YN9BZkpfP70iXxh/qQjOrYeYhIRGQa6upyNNfvYVL2PzbVNbKrex5lT87h4dtERHU9zy4iIDAMJCcaU/JFMyR+8i6y9vu+QvpuIiAwJhbuISAxSuIuIxCCFu4hIDFK4i4jEIIW7iEgMUriLiMQghbuISAyK2BOqZlYDHOm0kKOB2jCWE+30fRxM38eH9F0cLBa+j/HuntdXo4iF+9Ews6X9efw2Xuj7OJi+jw/puzhYPH0fGpYREYlBCncRkRgUreF+R6QLGGb0fRxM38eH9F0cLG6+j6gccxcRkcOL1p67iIgcRtSFu5mdZ2YbzGxjaO3WuGFmxWb2spmtM7O1ZnZjaHuOmT1vZu+H/ndUpGsdSmYWMLN3zOyvodcTzWxJ6By538ySI13jUDGzbDN7yMzeNbP1ZnZKvJ4fZvbPob8na8zsXjNLiadzI6rC3cwCwG+A84EZwFVmNiOyVQ2pDuBf3H0GMA/4Sujz3wy86O7HAi+GXseTG4H13V7/HLjN3Y8B9gKfj0hVkfErgovTTwNmEfxe4u78MLMi4OtAmbuXAgHgSuLo3IiqcAdOAja6+2Z3bwPuAy6OcE1Dxt2r3H156OdGgn9xiwh+B3eHmt0NfCoyFQ49MxsHXEBwjV/MzICzgIdCTeLm+zCzLGA+cBeAu7e5ex3xe34kAqlmlgikAVXE0bkRbeFeBOzo9ro8tC3umNkE4ARgCZDv7lWhXTuB/AiVFQm/BP6V4MLsALlAnbt3hF7H0zkyEagB/jc0THWnmaUTh+eHu1cAtwLbCYZ6PbCMODo3oi3cBTCzDOAvwE3u3tB9nwdvf4qLW6DM7EKg2t2XRbqWYSIRmAP8zt1PAJroMQQTL+dH6LrCxQT/wSsE0oHzIlrUEIu2cK8Airu9HhfaFjfMLIlgsP/Z3R8Obd5lZmND+8cC1ZGqb4idBiw0s60Eh+jOIjjmnB36T3GIr3OkHCh39yWh1w8RDPt4PD/OBra4e427twMPEzxf4ubciLZwfxs4NnTFO5ngBZLHI1zTkAmNJ98FrHf3/+q263HgmtDP1wCPDXVtkeDu33b3ce4+geC58JK7fwZ4Gbgs1Cyevo+dwA4zmxratABYR3yeH9uBeWaWFvp7c+C7iJtzI+oeYjKzTxIcZw0Av3f3/xfhkoaMmZ0OLAZW8+EY83cIjrs/AJQQnGnzH919T0SKjBAz+xjwf939QjObRLAnnwO8A1zt7q2RrG+omNlsgheXk4HNwHUEO3Fxd36Y2Y+AKwjeZfYOcD3BMfa4ODeiLtxFRKRv0TYsIyIi/aBwFxGJQQp3EZEYpHAXEYlBCncRkRikcBcRiUEKdxGRGKRwFxGJQf8fvsLO/I0iSRgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() \n",
    "train_network(network,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MHLinearGRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MultiHeadedAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(network,\"network_bn_bn5mh_att_linear_ml.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95,num_parts = 5):\n",
    "    part_len = len(data)//num_parts\n",
    "    estimations = []\n",
    "    for i in range(num_parts):\n",
    "        est = np.mean(data[part_len*i:part_len*(i+1)])\n",
    "        estimations.append(est)\n",
    "    a = 1.0*np.array(estimations)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, h\n",
    "\n",
    "def validate_mrr(network,k,test_loader):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:,-2]\n",
    "            _,ind = torch.topk(predictions_logp, k,dim=-1)\n",
    "            mrr = torch.zeros(predictions_logp.size())\n",
    "            mrr.scatter_(-1,ind.cpu(),1/torch.range(1,k).repeat(*ind.size()[:-1],1).type(torch.FloatTensor).cpu())\n",
    "            actual_next_tokens = item_batch_ix[:, -1]\n",
    "\n",
    "            logp_next = torch.gather(mrr.to(device)*mask_batch_ix[:, -2,None], dim=1, index=actual_next_tokens[:,None])\n",
    "#             if mask_batch_ix[:,-2].sum() >0:\n",
    "            loss = logp_next.sum()/mask_batch_ix[:,-2].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect() \n",
    "    m, h = mean_confidence_interval(losses)\n",
    "    return m, h\n",
    "\n",
    "def validate_recall(network,k,test_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    \n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, -2]\n",
    "            minus_kth_biggest_logp,_ = torch.kthvalue(-predictions_logp.cpu(), k,dim=-1,keepdim=True)\n",
    "            prediicted_kth_biggest = (predictions_logp>(-minus_kth_biggest_logp.to(device)))\\\n",
    "                                        .type(torch.FloatTensor).to(device)\n",
    "            actual_next_tokens = item_batch_ix[:, -1]\n",
    "\n",
    "            logp_next = torch.gather(prediicted_kth_biggest*mask_batch_ix[:, -2,None], dim=1, index=actual_next_tokens[:,None])\n",
    "            loss = logp_next.sum()/mask_batch_ix[:,-2].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    m, h = mean_confidence_interval(losses)\n",
    "    return m, h\n",
    "\n",
    "def print_scores(model,name):\n",
    "    network = torch.load(model)\n",
    "    mrr_score, h = validate_mrr(network,20,test_loader)\n",
    "    print(\"MRR@20 score for \", name,\": \",mrr_score,\"±\",h)\n",
    "    recall_score, h = validate_recall(network,20,test_loader)\n",
    "    print(\"Recall@20 score for \"+name+\": \",recall_score,\"±\",h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for  Linear User-based GRU on MovieLens :  0.057397615 ± 0.001635190703477747\n",
      "Recall@20 score for Linear User-based GRU on MovieLens:  0.18177387 ± 0.0037508356024602276\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"network_linear_ml.p\",'Linear User-based GRU on MovieLens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr_score, h = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Linear User-based GRU: \",mrr_score)\n",
    "linear_recall_score, h = validate_recall(network,20,test_loader)\n",
    "# print(\"Recall score for Linear User-based GRU: \",linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.057359595, 0.0022232151609311384)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_confidence_interval(linear_mrr_score,num_parts = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(linear_mrr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on LastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "n_users = int(np.max([lf_train_users.max()+1,lf_val_users.max()+1,lf_test_users.max()])+1)\n",
    "n_items = int(np.max([lf_train_items.max()+1,lf_val_items.max()+1,lf_test_items.max()])+1)\n",
    "# with torch.cuda.device(2):\n",
    "network = LinearGRU(n_users=n_users,n_items=n_items).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "opt = torch.optim.SGD(network.parameters(),lr =1)\n",
    "\n",
    "history = []\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(lf_train_users),torch.LongTensor(lf_train_items),torch.FloatTensor(lf_train_mask))),\\\n",
    "            batch_size=100,shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(lf_val_users),torch.LongTensor(lf_val_items),torch.FloatTensor(lf_val_mask))),\\\n",
    "            batch_size=100,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(lf_test_users),torch.LongTensor(lf_test_items),torch.FloatTensor(lf_test_mask))),\\\n",
    "            batch_size=100,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:463",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-a6b29073dfc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network_linear_lf_bs100.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-cdf91644fd86>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# train with backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generated/../generic/THCTensorMathPointwise.cu:463"
     ]
    }
   ],
   "source": [
    "network = torch.load(\"network_linear_lf_bs100.p\")\n",
    "train_network(network.to(device),train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type LinearGRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(network,\"network_linear_lf_bs100.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for  Linear User-based GRU on LastFM :  0.12185228 ± 0.004911310260730987\n",
      "Recall@20 score for Linear User-based GRU on LastFM:  0.18590595 ± 0.00710542097175407\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"network_linear_lf_bs100.p\",'Linear User-based GRU on LastFM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for  Linear User-based GRU on MovieLens :  0.057497583 ± 0.0007039992875517064\n",
      "Recall@20 score for Linear User-based GRU on MovieLens:  0.18227212 ± 0.003842047864645815\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"network_linear_ml.p\",'Linear User-based GRU on MovieLens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for  Rectified Linear User-based GRU on MovieLens :  0.060260046 ± 0.0005038204951150433\n",
      "Recall@20 score for Rectified Linear User-based GRU on MovieLens:  0.19106193 ± 0.004563955364643368\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"network_rect_linear_ml.p\",'Rectified Linear User-based GRU on MovieLens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for  Attentional User-based GRU on MovieLens :  0.065337464 ± 0.0021981462220191897\n",
      "Recall@20 score for Attentional User-based GRU on MovieLens:  0.1987088 ± 0.0027508449974647546\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"network_att_linear_ml.p\",'Attentional User-based GRU on MovieLens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for  Multi-Head Attentional User-based GRU on MovieLens :  0.06202981 ± 0.0017889912578660427\n",
      "Recall@20 score for Multi-Head Attentional User-based GRU on MovieLens:  0.20207629 ± 0.005651086872747263\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"network_bn5mh_att_linear_ml.p\",'Multi-Head Attentional User-based GRU on MovieLens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
