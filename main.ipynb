{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear User Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class LinearGRU(nn.Module):\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.gru = nn.GRU(input_size = emb_size*2,hidden_size = hidden_units,dropout = dropout,batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        \n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_emb(user_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "\n",
    "        gru_output,_ = self.gru(torch.cat([users,items],dim=-1))\n",
    "        output_ln = self.linear(gru_output)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "# #device = torch.device(\"cpu\")\n",
    "# network = LinearGRU(n_users=3,n_items=3,emb_size=20).to(device)\n",
    "# users = np.array([[1,1,1,1]])\n",
    "# items = np.array([[0,1,2,1]])\n",
    "# pred = network(Variable(torch.LongTensor(users)).to(device),Variable(torch.LongTensor(items)).to(device))\n",
    "# pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Lens Prerocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and provided functions\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import wget\n",
    "from io import StringIO \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from tqdm import tqdm # Very useful library to see progress bar during range iterations: just type `for i in tqdm(range(10)):`\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory...\n",
      "Normalizing indices to avoid gaps\n",
      "Normalizing timesteps of users\n",
      "Removing data with more then 650 points\n",
      "Splitting into train, validation and test parts\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def normalize_timestamp(x):\n",
    "    x[\"timestamp\"] = np.argsort(list(x[\"timestamp\"]))\n",
    "    return x\n",
    "\n",
    "def length_col(x):\n",
    "    x['timestamp'] = len(x)\n",
    "    return x\n",
    "\n",
    "def to_matrices(ml_data):\n",
    "    data_shape = ml_data[['userid', 'timestamp']].max()+1\n",
    "\n",
    "    data_matrix = sp.sparse.csr_matrix((ml_data['movieid'],\n",
    "                                   (ml_data['userid'], ml_data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    mask_matrix = sp.sparse.csr_matrix((np.ones(len(ml_data)),\n",
    "                                   (ml_data['userid'], ml_data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    return data_matrix, mask_matrix\n",
    "\n",
    "def get_movielens_data(local_file=None):\n",
    "    '''Downloads movielens data, normalizes users, timesteps and movies ids,\n",
    "    returns data in sparse CSR format.\n",
    "    '''\n",
    "    if not local_file:\n",
    "        print('Downloading data...')\n",
    "        zip_file_url = 'http://files.grouplens.org/datasets/movielens/ml-10m.zip'\n",
    "        zip_contents = wget.download(zip_file_url)\n",
    "        print('Done.')\n",
    "    else:\n",
    "        zip_contents = local_file\n",
    "    \n",
    "    print('Loading data into memory...')\n",
    "    with zipfile.ZipFile(zip_contents) as zfile:\n",
    "        zdata = zfile.read('ml-10M100K/ratings.dat').decode()\n",
    "        delimiter = ';'\n",
    "        zdata = zdata.replace('::', delimiter) # makes data compatible with pandas c-engine\n",
    "        ml_data = pd.read_csv(StringIO(zdata), sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'movieid' ,'rating','timestamp'],\n",
    "                                  usecols=['userid', 'movieid','rating','timestamp'])\n",
    "    print(\"Normalizing indices to avoid gaps\")\n",
    "    # normalize indices to avoid gaps\n",
    "    ml_data['movieid'] = ml_data.groupby('movieid', sort=False).grouper.group_info[0]\n",
    "    ml_data['userid'] = ml_data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    \n",
    "    # Normalize time for users\n",
    "    print(\"Normalizing timesteps of users\")\n",
    "    ml_data = ml_data.groupby(\"userid\").apply(normalize_timestamp)\n",
    "    print(\"Removing data with more then 650 points\")\n",
    "    \n",
    "    lc = ml_data.groupby(\"userid\").apply(length_col)\n",
    "    ml_data = ml_data[lc['timestamp']<650]\n",
    "    # build sparse user-movie matrix\n",
    "    \n",
    "    print(\"Splitting into train, validation and test parts\")\n",
    "    max_time_stamp = lc[lc['timestamp']<650]['timestamp']\n",
    "    timestamp = ml_data['timestamp']\n",
    "    ml_data_train = ml_data[timestamp<max_time_stamp*0.9]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    ml_data_val = ml_data[(0.9*max_time_stamp<=timestamp)&(timestamp<0.95*max_time_stamp)]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    ml_data_test = ml_data[0.95*max_time_stamp<=timestamp]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "\n",
    "    train_items, train_mask = to_matrices(ml_data_train)\n",
    "    val_items, val_mask = to_matrices(ml_data_val)\n",
    "    test_items, test_mask = to_matrices(ml_data_test)\n",
    "    \n",
    "    print('Done.')\n",
    "    return (train_items, train_mask),(val_items, val_mask),(test_items, test_mask)\n",
    "\n",
    "(train_items, train_mask),(val_items, val_mask),(test_items, test_mask) = get_movielens_data(\"ml-10m.zip\")\n",
    "\n",
    "np.save(\"train_items\",train_items)\n",
    "np.save('train_mask',train_mask)\n",
    "np.save('val_items',val_items)\n",
    "np.save('val_mask',val_mask)\n",
    "np.save('test_items',test_items)\n",
    "np.save('test_mask',test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_items = np.load(\"train_items.npy\")\n",
    "train_mask = np.load(\"train_mask.npy\")\n",
    "val_items = np.load(\"val_items.npy\")\n",
    "val_mask = np.load(\"val_mask.npy\")\n",
    "test_items = np.load(\"test_items.npy\")\n",
    "test_mask = np.load(\"test_mask.npy\")\n",
    "\n",
    "train_users, _ = np.mgrid[:train_items.shape[0],:train_items.shape[1]]\n",
    "val_users, _ = np.mgrid[:val_items.shape[0],:val_items.shape[1]]\n",
    "test_users, _ = np.mgrid[:test_items.shape[0],:test_items.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "n_users = train_items.shape[0]\n",
    "n_items = int(np.max([train_items.max(),val_items.max(),test_items.max()]))\n",
    "network = LinearGRU(n_users=n_users,n_items=n_items).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "opt = torch.optim.Adam(network.parameters(),lr =0.001)\n",
    "\n",
    "history = []\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(train_users),torch.LongTensor(train_items),torch.FloatTensor(train_mask))),\\\n",
    "            batch_size=30,shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(val_users),torch.LongTensor(val_items),torch.FloatTensor(val_mask))),\\\n",
    "            batch_size=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d28c92e755d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlogp_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_logp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactual_next_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogp_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# train with backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "def validate_lce(network):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in val_loader:\n",
    "\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)\n",
    "\n",
    "i=0\n",
    "\n",
    "\n",
    "for user_batch_ix,item_batch_ix, item_mask_batch_ix in train_loader:\n",
    "    network.train()\n",
    "    user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "    item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "    item_mask_batch_ix = Variable(item_mask_batch_ix).to(device)\n",
    "    \n",
    "    logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]*item_mask_batch_ix[:, :-1,None]\n",
    "    actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "    logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "    loss = -logp_next.mean()\n",
    "    \n",
    "    # train with backprop\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "    \n",
    "    if (i+1)%500==0:\n",
    "        val_loss = validate_lce(network)\n",
    "        history.append(val_loss)\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='val loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type LinearGRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(network, 'network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(test_users),torch.LongTensor(test_items),torch.FloatTensor(test_mask))),\\\n",
    "            batch_size=1000,shuffle=True)\n",
    "\n",
    "def validate_mrr(network,k):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]\n",
    "            _,ind = torch.topk(predictions_logp, k,dim=-1)\n",
    "            mrr = torch.zeros(predictions_logp.size())\n",
    "            mrr.scatter_(-1,ind.cpu(),1/torch.range(1,k).repeat(*ind.size()[:-1],1).type(torch.FloatTensor).cpu())\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "            logp_next = torch.gather(mrr.to(device)*mask_batch_ix[:, :-1,None], dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = logp_next.sum()/mask_batch_ix[:, :-1,None].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def validate_recall(network,k):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]\n",
    "            minus_kth_biggest_logp,_ = torch.kthvalue(-predictions_logp.cpu(), k,dim=-1,keepdim=True)\n",
    "            prediicted_kth_biggest = (predictions_logp>(-minus_kth_biggest_logp.to(device)))\\\n",
    "                                        .type(torch.FloatTensor).to(device)\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(prediicted_kth_biggest*mask_batch_ix[:, :-1,None], dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = logp_next.sum()/mask_batch_ix[:, :-1,None].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#torch.cuda.empty_cache()\n",
    "gc.collect() \n",
    "validate_recall(network,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
