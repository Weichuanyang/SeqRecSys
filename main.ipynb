{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LinearGRU(nn.Module):\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = hidden_units\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = hidden_units)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        \n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            gru_input = torch.cat([users[:,i,:],items[:,i,:]],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        \n",
    "        output_ln = self.linear(ln_input)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rectified Linear User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "class RectifiedLinearGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = hidden_units\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.k1 = nn.Linear(hidden_units+2*emb_size,emb_size)\n",
    "        self.k2 = nn.Linear(hidden_units+2*emb_size,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = hidden_units)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users =  self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            rect_users = rectified_users(self,users[:,i,:],items[:,i,:],h)\n",
    "            gru_input = torch.cat([rect_users,items[:,i,:]],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        output_ln = self.linear(ln_input)\n",
    "\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n",
    "def rectified_users(self,users,items,h):\n",
    "    \n",
    "    k1 = self.k1(torch.cat([users,items,h],dim = -1))\n",
    "    k2 = self.k2(torch.cat([users,items,h],dim = -1))\n",
    "    rect_users = users\n",
    "    rect_users[users<k2] = rect_users[users<k2]*0.2\n",
    "    rect_users[users<k1] = 0\n",
    "    return rect_users\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Attentional User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "class AttentionalLinearGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = hidden_units\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = hidden_units)\n",
    "        self.att_linear = nn.Linear(hidden_units+emb_size*2,emb_size)\n",
    "        torch.nn.init.constant_(self.att_linear.weight,1e-6)\n",
    "        torch.nn.init.constant_(self.att_linear.bias,1e-6)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            attention = F.sigmoid(self.att_linear(torch.cat([users[:,i,:],items[:,i,:],h],dim = -1)))\n",
    "            gru_input = torch.cat([attention*users[:,i,:],(1-attention)*items[:,i,:]],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "        output_ln = self.linear(ln_input)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multi-head Attentional User-based GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / np.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class MHLinearGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users,n_items, emb_size=1000,head_num = 5,dropout = 0.8,user_dropout = 0.5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.hidden_units = emb_size\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.grucell = nn.GRUCell(input_size = emb_size*2,hidden_size = self.hidden_units)\n",
    "        #self.att_linear = nn.Linear(hidden_units+emb_size*2,emb_size)\n",
    "#         torch.nn.init.constant_(self.att_linear.weight,1e-6)\n",
    "#         torch.nn.init.constant_(self.att_linear.bias,1e-6)\n",
    "        self.linear = nn.Linear(self.hidden_units,n_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.user_dropout = nn.Dropout(user_dropout)\n",
    "        self.user_attention = MultiHeadedAttention(head_num, self.emb_size)\n",
    "        self.item_attention = MultiHeadedAttention(head_num, self.emb_size)\n",
    "        self.bn_user = nn.BatchNorm1d(self.emb_size)\n",
    "        self.bn_item = nn.BatchNorm1d(self.emb_size)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        batch_size,_ = user_vectors.size()\n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_dropout(self.user_emb(user_vectors))#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_units).to(device)\n",
    "        h_t = h.unsqueeze(0)\n",
    "        for i in range(sequence_size):\n",
    "            #attention = F.sigmoid(self.att_linear(torch.cat([users[:,i,:],items[:,i,:],h],dim = -1)))\n",
    "            attnd_users = self.user_attention(items[:,i,:],h,users[:,i,:]).squeeze(1)\n",
    "            attnd_items = self.item_attention(users[:,i,:],h,items[:,i,:]).squeeze(1)\n",
    "#             attnd_users = self.bn_user(attnd_users)\n",
    "#             attnd_items = self.bn_item(attnd_items)\n",
    "            gru_input = torch.cat([attnd_users,attnd_items],dim=-1)\n",
    "            h = self.grucell(gru_input,h)\n",
    "            h_t = torch.cat([h_t,h.unsqueeze(0)],dim=0)\n",
    "        ln_input = self.dropout(h_t[1:].transpose(0,1))\n",
    "#         output_ln  = self.attention(users,items,ln_input)\n",
    "        output_ln = self.linear(ln_input)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = int(ml_test_users.max()+1)\n",
    "n_items = int(np.max([ml_train_items.max()+1,ml_val_items.max()+1,ml_test_items.max()])+1)\n",
    "n_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10678])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# network = AttentionalLinearGRU(n_users=3,n_items=3,emb_size=20).to(device)\n",
    "network = MHLinearGRU(n_users=n_users,n_items=n_items).to(device)\n",
    "\n",
    "users = np.array([[1,1,1,1,1],\n",
    "                  [2,2,2,2,2]])\n",
    "items = np.array([[0,1,2,1,1],\n",
    "                  [0,2,2,1,0]])\n",
    "pred = network(Variable(torch.LongTensor(users)).to(device),Variable(torch.LongTensor(items)).to(device))\n",
    "pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens Prerocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and provided functions\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import wget\n",
    "from io import StringIO \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from tqdm import tqdm # Very useful library to see progress bar during range iterations: just type `for i in tqdm(range(10)):`\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "\n",
    "def move_timestamps_to_end(x,max_order):\n",
    "    new_order = x.groupby('timestamp', sort=True).grouper.group_info[0]\n",
    "    x[\"timestamp\"] = (max_order - new_order.max())+new_order\n",
    "    return x\n",
    "\n",
    "def normalize_timestamp(x):\n",
    "    x[\"timestamp\"] = x.groupby(['timestamp','itemid'], sort=True).grouper.group_info[0]\n",
    "    return x\n",
    "\n",
    "def set_timestamp_length(x):\n",
    "    x['length'] = len(x)\n",
    "    return x\n",
    "\n",
    "def to_coo(data):\n",
    "    user_idx, item_idx, feedback = ml_data['userid'], ml_data['itemid'], ml_data['rating']\n",
    "    return user_idx, item_idx, feedback\n",
    "\n",
    "def to_matrices(data):\n",
    "    data = split_by_groups(data)\n",
    "    \n",
    "    data_max_order = data['timestamp'].max()\n",
    "    data = data.groupby(\"index\").apply(move_timestamps_to_end,data_max_order)\n",
    "\n",
    "    data_shape = data[['index', 'timestamp']].max()+1\n",
    "    data_matrix = sp.sparse.csr_matrix((data['itemid'],\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    mask_matrix = sp.sparse.csr_matrix((np.ones(len(data)),\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    \n",
    "    data_users = data.drop_duplicates(['index'])\n",
    "    user_data_shape = data_users['index'].max()+1\n",
    "    user_vector = sp.sparse.csr_matrix((data_users['userid'],\n",
    "                                   (data_users['index'],np.zeros(user_data_shape))),\n",
    "                                    shape=(user_data_shape,1), dtype=np.float64).todense()\n",
    "    user_matrix = np.tile(user_vector,(1,data_shape[1]))\n",
    "    return data_matrix, mask_matrix, user_matrix\n",
    "\n",
    "def train_val_test_split(data,frac):\n",
    "    data = data.groupby(\"userid\").apply(set_timestamp_length)\n",
    "    max_time_stamp = data['length']*frac\n",
    "    timestamp = data['timestamp']\n",
    "    data_train = data[timestamp<max_time_stamp*0.9].groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_val = data[(0.9*max_time_stamp<=timestamp)&(timestamp<0.95*max_time_stamp)]\\\n",
    "                                                            .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_test = data[(0.95*max_time_stamp<=timestamp)&(timestamp<=max_time_stamp)].groupby(\"userid\").apply(normalize_timestamp)\n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "def split_by_groups(data,group_length=20):\n",
    "    data[\"group\"] = data['timestamp']//group_length\n",
    "    data[\"timestamp\"] = data['timestamp']%group_length\n",
    "    data[\"index\"] = data.groupby(['userid','group'], sort=False).grouper.group_info[0]\n",
    "    return data\n",
    "\n",
    "def get_prepared_data(data,frac = 1):\n",
    "    print(\"Normalizing indices to avoid gaps\")\n",
    "    # normalize indices to avoid gaps\n",
    "    data['itemid'] = data.groupby('itemid', sort=False).grouper.group_info[0]\n",
    "    data['userid'] = data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    data = data.groupby(\"userid\").apply(normalize_timestamp)\n",
    "\n",
    "    # build sparse user-movie matrix\n",
    "    print(\"Splitting into train, validation and test parts\")\n",
    "    \n",
    "    data_train, data_val, data_test = train_val_test_split(data,frac)\n",
    "    \n",
    "    user_idx, item_idx, feedback =  to_coo(data_train.copy())\n",
    "    \n",
    "    train_items, train_mask, train_users= to_matrices(data_train.copy())\n",
    "    val_items, val_mask, val_users = to_matrices(data_val.copy())\n",
    "    test_items, test_mask, test_users = to_matrices(data_test.copy())\n",
    "    \n",
    "    \n",
    "    print('Done.')\n",
    "    return (train_items, train_mask, train_users),\\\n",
    "           (val_items, val_mask, val_users),\\\n",
    "           (test_items, test_mask, test_users),\\\n",
    "           (user_idx, item_idx, feedback)\n",
    "        \n",
    "\n",
    "def get_movielens_data():\n",
    "    '''Downloads movielens data, normalizes users, timesteps and movies ids,\n",
    "    returns data in sparse CSR format.\n",
    "    '''\n",
    "    print('Loading data into memory...')\n",
    "    with zipfile.ZipFile(\"ml-10m.zip\") as zfile:\n",
    "        zdata = zfile.read('ml-10M100K/ratings.dat').decode()\n",
    "        delimiter = ';'\n",
    "        zdata = zdata.replace('::', delimiter) # makes data compatible with pandas c-engine\n",
    "        ml_data = pd.read_csv(StringIO(zdata), sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'movieid' ,'rating','timestamp'],\n",
    "                                  usecols=['userid', 'movieid','rating','timestamp'])\n",
    "        ml_data['itemid'] = ml_data['movieid']\n",
    "    return ml_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = get_movielens_data()\n",
    "\n",
    "(ml_train_items, ml_train_mask,ml_train_users),\\\n",
    "(ml_val_items, ml_val_mask,ml_val_users),\\\n",
    "(ml_test_items, ml_test_mask,ml_test_users),\\\n",
    "(train_user_idx, train_item_idx, train_feedback) = get_prepared_data(ml_data)\n",
    "\n",
    "# np.save(\"ml_train_items\",ml_train_items)\n",
    "# np.save('ml_train_mask',ml_train_mask)\n",
    "# np.save('ml_train_users',ml_train_users)\n",
    "# np.save('ml_val_items',ml_val_items)\n",
    "# np.save('ml_val_mask',ml_val_mask)\n",
    "# np.save('ml_val_users',ml_val_users)\n",
    "# np.save('ml_test_items',ml_test_items)\n",
    "# np.save('ml_test_mask',ml_test_mask)\n",
    "# np.save('ml_test_users',ml_test_users)\n",
    "np.save('train_user_idx',train_user_idx)\n",
    "np.save('train_item_idx',train_item_idx)\n",
    "np.save('train_feedback',train_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train_items = np.load(\"ml_train_items.npy\")\n",
    "ml_train_mask = np.load(\"ml_train_mask.npy\")\n",
    "ml_train_users = np.load(\"ml_train_users.npy\")\n",
    "ml_val_items = np.load(\"ml_val_items.npy\")\n",
    "ml_val_mask = np.load(\"ml_val_mask.npy\")\n",
    "ml_val_users = np.load(\"ml_val_users.npy\")\n",
    "ml_test_items = np.load(\"ml_test_items.npy\")\n",
    "ml_test_mask = np.load(\"ml_test_mask.npy\")\n",
    "ml_test_users = np.load(\"ml_test_users.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LastFM Prerocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def get_lastfm_data():\n",
    "    with tarfile.TarFile(\"lastfm-dataset-1K.tar\") as tfile:\n",
    "        member = tfile.getmember('lastfm-dataset-1K/userid-timestamp-artid-artname-traid-traname.tsv')\n",
    "        f = tfile.extractfile(member)\n",
    "        delimiter = '\\t'\n",
    "        lf_data = pd.read_csv(f, sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'timestamp','artid','artname','traid','traname'],\n",
    "                                  usecols=['userid', 'timestamp','artid','artname','traid','traname'])\n",
    "        lf_data['timestamp'] = pd.to_datetime(lf_data['timestamp'])\n",
    "        lf_data['itemid'] = lf_data['traname']\n",
    "        lf_data = lf_data[['userid','timestamp','itemid']]\n",
    "        #lf_data = lf_data.sample(frac = 0.1)\n",
    "        lf_data = lf_data.drop_duplicates(['userid','timestamp','itemid'])\n",
    "    return lf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing indices to avoid gaps\n",
      "Splitting into train, validation and test parts\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lf_data = get_lastfm_data()\n",
    "\n",
    "(lf_train_items, lf_train_mask,lf_train_users),\\\n",
    "(lf_val_items, lf_val_mask,lf_val_users),\\\n",
    "(lf_test_items, lf_test_mask,lf_test_users) = get_prepared_data(lf_data,0.1)\n",
    "\n",
    "np.save(\"lf_train_items\",lf_train_items)\n",
    "np.save('lf_train_mask',lf_train_mask)\n",
    "np.save('lf_train_users',lf_train_users)\n",
    "np.save('lf_val_items',lf_val_items)\n",
    "np.save('lf_val_mask',lf_val_mask)\n",
    "np.save('lf_val_users',lf_val_users)\n",
    "np.save('lf_test_items',lf_test_items)\n",
    "np.save('lf_test_mask',lf_test_mask)\n",
    "np.save('lf_test_users',lf_test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_train_items = np.load(\"lf_train_items.npy\")\n",
    "lf_train_mask = np.load(\"lf_train_mask.npy\")\n",
    "lf_train_users = np.load(\"lf_train_users.npy\")\n",
    "lf_val_items = np.load(\"lf_val_items.npy\")\n",
    "lf_val_mask = np.load(\"lf_val_mask.npy\")\n",
    "lf_val_users = np.load(\"lf_val_users.npy\")\n",
    "lf_test_items = np.load(\"lf_test_items.npy\")\n",
    "lf_test_mask = np.load(\"lf_test_mask.npy\")\n",
    "lf_test_users = np.load(\"lf_test_users.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "n_users = int(ml_test_users.max()+1)\n",
    "n_items = int(np.max([ml_train_items.max()+1,ml_val_items.max()+1,ml_test_items.max()])+1)\n",
    "network = MHLinearGRU(n_users=n_users,n_items=n_items).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "opt = torch.optim.Adam(network.parameters(),lr =0.001)\n",
    "\n",
    "history = []\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(ml_train_users),torch.LongTensor(ml_train_items),torch.FloatTensor(ml_train_mask))),\\\n",
    "            batch_size=1000,shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(ml_val_users),torch.LongTensor(ml_val_items),torch.FloatTensor(ml_val_mask))),\\\n",
    "            batch_size=1000,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(ml_test_users),torch.LongTensor(ml_test_items),torch.FloatTensor(ml_test_mask))),\\\n",
    "            batch_size=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MHLinearGRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MultiHeadedAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(network,\"network.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = torch.load(\"network.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from IPython.display import clear_output\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "def validate_lce(network,val_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in val_loader:\n",
    "\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def train_network(network,train_loader,val_loader):\n",
    "    for epoch in range(10):\n",
    "        i=0\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in train_loader:\n",
    "            network.train()\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "\n",
    "            # train with backprop\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(network.parameters(),5)\n",
    "            opt.step()\n",
    "            \n",
    "            if (i+1)%50==0:\n",
    "                val_loss = validate_lce(network,val_loader)\n",
    "                history.append(val_loss)\n",
    "\n",
    "                clear_output(True)\n",
    "                plt.title(\"Validation error\")\n",
    "                plt.plot(history)\n",
    "                plt.ylabel('Cross-entropy Error')\n",
    "                plt.xlabel('#iter')\n",
    "                plt.show()\n",
    "            i+=1\n",
    "            if len(history)==100:\n",
    "                return\n",
    "\n",
    "    val_loss = validate_lce(network,val_loader)\n",
    "    history.append(val_loss)\n",
    "\n",
    "    clear_output(True)\n",
    "    plt.plot(history,label='val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8leWd9/HPL+vJnpCEsCQQkEVZBEtQ3KDW3VZrpypaq9XWqtOOU9uZPnXap9vUZ/p0dKbL03Z4GGtbp9alVsetrd2sK6BAQRBklUASCEnMvi+/+eMcJMRAEkhycs75vl8vXubc98V9fjkevrly3de5LnN3REQkusSFuwARERl+CncRkSikcBcRiUIKdxGRKKRwFxGJQgp3EZEopHAXEYlCCncRkSikcBcRiUIJ4XrivLw8Ly4uDtfTi4hEpHXr1lW7e/5A7cIW7sXFxaxduzZcTy8iEpHMrHQw7TQsIyIShRTuIiJRSOEuIhKFwjbmLiKxrbOzk7KyMtra2sJdypgUCAQoLCwkMTHxuP6+wl1EwqKsrIyMjAyKi4sxs3CXM6a4OzU1NZSVlTFt2rTjuoaGZUQkLNra2sjNzVWw98PMyM3NPaHfahTuIhI2CvajO9HXJuLCfduBRu59bhu1zR3hLkVEZMyKuHB/u7qZHz6/k4r61nCXIiIxJj09fUjHwyniwj07NXjnuK6lM8yViIiMXREX7jmpSYDCXUROzF133cWPfvSjdx9/4xvf4N5776WpqYnzzz+f973vfcyfP58nn3xy0Nd0d774xS8yb9485s+fzyOPPALA/v37Wbp0KQsXLmTevHm89NJLdHd3c9NNN73b9rvf/e6wfn8RNxXyUM+9tkVj7iLR4ptPv8mWioZhveacSZl8/fK5Rz2/fPly7rzzTj772c8C8Oijj/Lcc88RCAR44oknyMzMpLq6miVLlnDFFVcM6gbn448/zoYNG9i4cSPV1dUsXryYpUuX8stf/pKLL76Yr3zlK3R3d9PS0sKGDRsoLy9n8+bNANTV1Q3PNx4SceGelRIM9/pW9dxF5PiddtppHDx4kIqKCqqqqsjJyaGoqIjOzk6+/OUv8+KLLxIXF0d5eTmVlZVMmDBhwGu+/PLLXHfddcTHx1NQUMCyZct4/fXXWbx4MZ/85Cfp7OzkyiuvZOHChUyfPp3du3dzxx138MEPfpCLLrpoWL+/iAv3QGI8KYnxmi0jEkWO1cMeSVdffTWPPfYYBw4cYPny5QA8+OCDVFVVsW7dOhITEykuLj7hT9EuXbqUF198kWeffZabbrqJL3zhC9x4441s3LiR5557jhUrVvDoo49y//33D8e3BUTgmDtATmoideq5i8gJWr58OQ8//DCPPfYYV199NQD19fWMHz+exMREnn/+eUpLB7XCLgDnnnsujzzyCN3d3VRVVfHiiy9y+umnU1paSkFBAZ/+9Ke55ZZbWL9+PdXV1fT09PDRj36Uu+++m/Xr1w/r9xZxPXeArNQk3VAVkRM2d+5cGhsbmTx5MhMnTgTg+uuv5/LLL2f+/PmUlJRw8sknD/p6H/nIR1i1ahULFizAzPjXf/1XJkyYwM9//nPuueceEhMTSU9P54EHHqC8vJybb76Znp4eAL797W8P6/dm7j6sFxyskpISP97NOq5buZrO7h4e+9uzhrkqERktW7du5ZRTTgl3GWNaf6+Rma1z95KB/m5kDsukaVhGRORYIjLcs1KSqNNUSBGRo4rIcM9JTaSupZNwDSmJyPDQv+GjO9HXZlDhbmafN7M3zWyzmT1kZoE+55PN7BEz22lma8ys+ISqGkB2aiJdPU5Te9dIPo2IjKBAIEBNTY0Cvh+H1nMPBAIDNz6KAWfLmNlk4O+BOe7eamaPAtcCP+vV7FNArbvPMLNrge8Ay4+7qgFk91qCICNwfLuUiEh4FRYWUlZWRlVVVbhLGZMO7cR0vAY7FTIBSDGzTiAVqOhz/sPAN0JfPwb80MzMR+hHcnbK4cXDisaNxDOIyEhLTEw87l2GZGADDsu4ezlwL7AX2A/Uu/vv+zSbDOwLte8C6oHc4S31sJy0UM+9VTdVRUT6M2C4m1kOwZ75NGASkGZmHz+eJzOzW81srZmtPZFfxQ713Gv1QSYRkX4N5obqBcDb7l7l7p3A40DfTw+VA0UAZpYAZAE1fS/k7ivdvcTdS/Lz84+76ENj7vWaDiki0q/BhPteYImZpVpwzcvzga192jwFfCL09VXAn0dqvB0OrwypJQhERPo3mDH3NQRvkq4HNoX+zkoz+2czuyLU7CdArpntBL4A3DVC9QKQlBBHenKChmVERI5iULNl3P3rwNf7HP5ar/NtwNXDWNeAslISdUNVROQoIvITqhBaX0Y9dxGRfkVsuGdrfRkRkaOK2HDPSlXPXUTkaCI23LUbk4jI0UVsuB8alunp0aJDIiJ9RW64pybS49ColSFFRN4jgsP90MqQuqkqItJXxIZ7Tqo+pSoicjQRG+7ZqYcWD1PPXUSkrwgO99DiYZoxIyLyHpEb7lo8TETkqCI23LNSNCwjInI0ERvuCfFxZAQS1HMXEelHxIY7QE6q1pcREelPRId7tpYgEBHpV0SHe1ZKojbsEBHpR0SHe05qkvZRFRHpR0SHe3aqeu4iIv0ZMNzNbLaZbej1p8HM7uzTJsvMnjazjWb2ppndPHIlH5admkRDWyfdWhlSROQIA+6h6u7bgIUAZhYPlANP9Gn2WWCLu19uZvnANjN70N1HdMwkOyURd2ho7SQnLWkkn0pEJKIMdVjmfGCXu5f2Oe5AhpkZkA68A4z4Wrw5aaFPqWrGjIjIEQbsufdxLfBQP8d/CDwFVAAZwHJ37znB2gaUndJ72d+0kX46EZGIMeieu5klAVcAv+rn9MXABmASwSGcH5pZZj/XuNXM1prZ2qqqquMs+bBsLfsrItKvoQzLXAqsd/fKfs7dDDzuQTuBt4GT+zZy95XuXuLuJfn5+cdXcS/vbtjRqumQIiK9DSXcr6P/IRmAvQTH4zGzAmA2sPvEShvYoQ07apvVcxcR6W1QY+5mlgZcCNzW69jtAO6+AvgW8DMz2wQY8CV3rx7+co+UEUjETDdURUT6GlS4u3szkNvn2IpeX1cAFw1vaQOLjzNy05Koamwb7acWERnTIvoTqgCTc1Ipq20NdxkiImNKxId7YU4K5Qp3EZEjRH64Z6dQVtdKj5YgEBF5V+SHe04KHV09VDe1h7sUEZExIwrCPRWAfRqaERF5VxSEewoAZbUtYa5ERGTsiPhwn/xuuKvnLiJySMSHe2pSArlpSQp3EZFeIj7cITg0o2EZEZHDoiTcUzXXXUSklygJd811FxHpLWrCXXPdRUQOi5Jw11x3EZHeoiTcNdddRKS3qAh3zXUXETlSVIS75rqLiBwpKsIdNNddRKS3KAp3zXUXETlkwHA3s9lmtqHXnwYzu7Ofdu8PnX/TzF4YmXKPTnPdRUQOG3APVXffBiwEMLN4oBx4oncbM8sGfgxc4u57zWz8CNR6TL3nuo/PDIz204uIjClDHZY5H9jl7qV9jn8MeNzd9wK4+8HhKG4oNNddROSwoYb7tcBD/RyfBeSY2V/MbJ2Z3djfXzazW81srZmtraqqGmqtx6S57iIihw063M0sCbgC+FU/pxOARcAHgYuBr5rZrL6N3H2lu5e4e0l+fv5xltw/zXUXETlswDH3Xi4F1rt7ZT/nyoAad28Gms3sRWABsH0YahwUzXUXETlsKMMy19H/kAzAk8A5ZpZgZqnAGcDWEy1uqDTXXUQkaFA9dzNLAy4Ebut17HYAd1/h7lvN7HfAG0APcJ+7bx6Beo+pMCeVrfsbRvtpRUTGnEGFe2i4JbfPsRV9Ht8D3DN8pQ3d1NxUnnvzAG2d3QQS48NZiohIWEXNJ1QBTi3MpqvH2aLeu4jEuKgK99OmZAOwcV9dmCsREQmvqAr3gswAEzIDbFC4i0iMi6pwB1hQlKWeu4jEvCgM92z21LRQ19IR7lJERMIm6sJ9YWFo3L2sPsyViIiET9SF+/zCLMx0U1VEYlvUhXtGIJEZ+em6qSoiMS3qwh2C4+4b99Xhro07RCQ2RW241zR3aBExEYlZURnupxUduqmqoRkRiU1RGe6zJ2SQlBDHhr0KdxGJTVEZ7onxccyblKmeu4jErKgMdwiOu28qr6eruyfcpYiIjLqoDfeFRdm0dfawvbIp3KWIiIy6qA33903JAWD17powVyIiMvqiNtyLxqUyPS+NF3dUhbsUEZFRN2C4m9lsM9vQ60+Dmd15lLaLzazLzK4a/lKHbumsfFbvrqGtszvcpYiIjKoBw93dt7n7QndfCCwCWoAn+rYzs3jgO8Dvh73K47Rsdj5tnT289vY74S5FRGRUDXVY5nxgl7uX9nPuDuDXwMETrmqYLJmWS1JCHC9u19CMiMSWoYb7tcBDfQ+a2WTgI8B/DEdRwyUlKZ4zpo3jBYW7iMSYQYe7mSUBVwC/6uf094AvufsxJ5Wb2a1mttbM1lZVjU7gLpuVz46DTZTXaZ0ZEYkdQ+m5Xwqsd/fKfs6VAA+b2R7gKuDHZnZl30buvtLdS9y9JD8//7gKHqpls4LPo6EZEYklQwn36+hnSAbA3ae5e7G7FwOPAZ9x9/8ehvpO2Izx6UzKCvDCNoW7iMSOQYW7maUBFwKP9zp2u5ndPlKFDRczY9nsfF7ZWU2nliIQkRgxqHB392Z3z3X3+l7HVrj7in7a3uTujw1nkSdq2ax8Gtu7tDuTiMSMqP2Eam9nzcgjPs74y7YxM0tTRGRExUS4ZwYSOb14HE9uqKC7R1vviUj0i4lwB/jEWVMpq23lD1sOhLsUEZERFzPhfuGcCRSNS+EnL78d7lJEREZczIR7fJxx01nTeH1PLW9ohyYRiXIxE+4A15QUkp6cwP3qvYtIlIupcM8IJHJNSRHPvLGfA/Vt4S5HRGTExFS4A9x8djE97jywak+4SxERGTExF+5F41K5aM4EfvnaXprbu8JdjojIiIi5cAe4bdl06lo6+dmre8JdiojIiIjJcD9tSg4XnDKe///CLupbOsNdjojIsIvJcAf4woWzaWjrYuVLu8JdiojIsIvZcJ8zKZMPnTqRn76yh+qm9nCXIyIyrGI23AE+f+Es2jq7+fHz6r2LSHSJ6XA/KT+dqxYV8os1peyv1zZ8IhI9YjrcAf7+/Jng8J3fvhXuUkREhk3Mh3thTiq3LZvOf2+oYNWumnCXIyIyLGI+3AE+e94Misal8NUnN9PRpa34RCTyDRjuZjbbzDb0+tNgZnf2aXO9mb1hZpvM7FUzWzByJQ+/QGI837h8LjsPNmlJYBGJCgOGu7tvc/eF7r4QWAS0AE/0afY2sMzd5wPfAlYOe6Uj7PxTCrhoTgE/+NMOympbwl2OiMgJGeqwzPnALncv7X3Q3V9199rQw9VA4XAUN9q+dvkcAP73f2/WdnwiEtGGGu7XAg8N0OZTwG+Pr5zwKsxJ5cuXncxftlXxlSc24a6AF5HIlDDYhmaWBFwB/NMx2pxHMNzPOcr5W4FbAaZMmTKkQkfLDWcWU9nQzg+f30l2ahJ3XXpyuEsSERmyQYc7cCmw3t0r+ztpZqcC9wGXunu/cwrdfSWh8fiSkpIx2y3+h4tmUdvSwYoXdpGTmshty04Kd0kiIkMylHC/jqMMyZjZFOBx4AZ33z4chYWTmfHPH55HfWsn3/7tW8ydlMU5M/PCXZaIyKANaszdzNKACwkG+KFjt5vZ7aGHXwNygR+HpkuuHfZKR1l8nPFv1yxgam4q33z6Tbq6Nf9dRCLHoMLd3ZvdPdfd63sdW+HuK0Jf3+LuOYemTLp7yUgVPJqSE+L5ymWnsONgEw+u2RvuckREBk2fUB3AhXMKOGdGHv/+h+3UNneEuxwRkUFRuA/AzPja5XNoau/i3/8Q8bcTRCRGKNwHYVZBBjcsmcqDa0rZur8h3OWIiAxI4T5Id14wk6yURG68/zWtHikiY57CfZCyU5N46NYlZAQSuP6+1fy/P+2gR0sUiMgYpXAfgpMnZPL0353DFQsm8W9/2M4nfvoaDW2d4S5LROQ9FO5DlJacwHeXL+RfPjKfVbtquPo/VlFRpy36RGRsUbgfBzPjY2dM4Wc3n055XSt/8+NXdaNVRMYUhfsJOGdmHo/ediaOc82KVfxl28FwlyQiAijcT9icSZk88ZmzKRyXys0/e50fPb9TSwWLSNgp3IfBpOwUfv23Z/KhUydxz3Pb+MyD62lu7wp3WSISw4ayKqQcQ2pSAj+4diGnTs7i27/dyurdNVwybyKXnzqRM6bnEh9n4S5RRGKIwn0YmRmfXjqd06Zk88CqUp7cUM5Dr+1lQmaAH1x3GqdPGxfuEkUkRijcR0BJ8ThKisfR2tHN89sOcu9z27j+vtXcfeU8li8emztQiUh00Zj7CEpJiuey+RN54jNns2R6Ll/69Sb++ektWhteREaceu6jICs1kZ/etJi7n93K/a+8zVMbK7h4bgGXzpvIkunjSIjXz1gRGV4Wrml7JSUlvnZtxG/YNGR/3FLJ438t4/m3qmjt7GZ8RjKfOmca1y+ZSnqyftaKyLGZ2brBbIikcA+T1o5uXth+kAdWlfLqrhoyAwnceGYxV542mRnj08NdnoiMUcMW7mY2G3ik16HpwNfc/Xu92hjwfeAyoAW4yd3XH+u6sR7uvW3YV8ePn9/J77dUAjA9L40L5hRw3elTmJaXFubqRGQsGZGeu5nFA+XAGe5e2uv4ZcAdBMP9DOD77n7Gsa6lcH+v8rpW/rS1kj9sqWT17hpSkxL4r0+dzqmF2eEuTUTGiMGG+1Dv5J0P7Ood7CEfBh7woNVAtplNHOK1Y97k7BRuPLOY//rUGfzpC+8Prh3/n2tYu+edcJcmIhFmqOF+LfBQP8cnA/t6PS4LHTuCmd1qZmvNbG1VVdUQnzq2TMlN5dHbziQ/I5kbfvIaL26v0po1IjJog56eYWZJwBXAPx3vk7n7SmAlBIdljvc6sWJSdgoP37aEj9+3hhvvf42MQAIzx6cze0IGC4uyWVw8jml5aQRveYiIHDaUuXeXAuvdvbKfc+VAUa/HhaFjcoLGZwT41W1n8dQbFWw/0Mi2ykZ+s+kAD70W/EUpLz2JS+dN5IuXzCYzkBjmakVkrBhKuF9H/0MyAE8Bf2dmDxO8oVrv7vtPtDgJykpN5IYlU9997O7sqmritbdrWb27hgfXlPLHrZX8y9/M57zZ48NYqYiMFYOaLWNmacBeYLq714eO3Q7g7itCUyF/CFxCcCrkze5+zKkwmi0zfDbsq+OLv9rIjoNNfOS0yVw8dwLzJmcyOTtFQzYiUUYfYooxbZ3d/OBPO/jPl3bT2R38f5qTmsgZ03K5YE4B583OJzc9OcxVisiJUrjHqNaObt460MDmigY2ldXxwvYqKhvaMYMFhdksLs5h0dQc3jclh/GZgXCXKyJDpHAXIDg+v7m8gT9ureTlndVsKq+noyu4KuX0/DTOOimXs07K4+yT8shK1Q1ZkbFO4S79au/q5s2KBtbtqeXVXdW89vY7NHd0kxQfx/tn53PlaZP5wMnjCSTGh7tUEemHwl0GpbO7h4376vjt5gM8vbGCg43tZCQncOn8CVx52mSWTMslTlsEiowZCncZsu4eZ/XuGp74azm/23yApvYuJmYFOGPaOGZPyGT2hHQWFGbrxqxIGCnc5YS0dnTzx62VPL2xgs3l9VTUtwGQFB/HRxdN5ralJ1GsFStFRp3CXYZVfWsn2w408uSGcn61royu7h7Omz2ehHijuqmD6qZ2ZhVkcOOZUzlnRp7m14uMEIW7jJiDDW3c/8oent5YQVpyPHnpyeSkJrF6dw01zR1Mz0/jqkWFnDIhk+n5aRTmpBKvcXuRYaFwl1HX3tXNbzbt5+evlrJhX927x5MS4lg0JYdzZ+WxdGY+cyZm6iatyHFSuEtY1TS1s7u6md1VTWyvbOLVXTVs3d8AQEZyAnMnZzJvUhZzJ2dSlJPKpOwUxmcka7NwkQEMNty1I7OMiNz0ZHLTk1lcPO7dYwcb23h5RzXr99ayqbyBB1aXvvuBKoD4OOO82fl89rwZnDYlJxxli0QN9dwlbDq7e9hT3Ux5XSsVdW3srmrisfVl1LV0cvaMXD51zjTOOilPH6gS6UXDMhKRmtu7+OWavax8aTdVje0kJcSxuDiHJdNyyQgEf9E0MyZnp7B42jiyUrRkgsQWhbtEtLbOblbtruGVHdW8vLOatw40vqeNGZwyIZNzZ+bxibOKmZSdEoZKRUaXwl2iSlN7F51dPTjQ487Og02s2f0Oa96u4bW338EMrlpUxGfefxKFOSk0tHVR39KJGRRkBkhK0I1aiQ66oSpRJT05AXqtepCXnsyS6bnATMpqW1jxwi4efb2MR17fi5nR3XO402IWbD9lXCoXnFLA5QsmUpiTOvrfhMgoUs9dosb++lYefm0fXT095KQmkZWSSI87++vb2F/XxluVjWwMzb9fXJzDZfMncsEpBRSNU9BL5BjWYRkzywbuA+YBDnzS3Vf1Op8F/AKYQvC3gXvd/afHuqbCXcJhb00LT79RwZMbytle2QTA7IIMPnDKeM6dmceiqTkkJ2h2joxdwx3uPwdecvf7zCwJSHX3ul7nvwxkufuXzCwf2AZMcPeOo11T4S7htqe6mT9ureSPWyt5fU8t3T1OSmI8JcU55KUnk5wQR1JCHBOyAiwszGZ+YRYZAc3OkfAatjH3UK98KXATQCiw+4a2AxmhjbLTgXeAriHWLDKqivPSuOXc6dxy7nQa2zpZvfsdXt5Rxet7atlT00xHVw9tnT3Ut3YCwbH76XlpnDwxk9kFGcyekMGsggymjNPaOTL2DOaG6jSgCvipmS0A1gGfc/fmXm1+CDwFVAAZwHJ373nPlUTGqIxAIhfOKeDCOQXvOVfX0sEbZfVs3FfHG+X1bC6v5zeb9nPol96khDhOyk9nzsRMzjopl7Nn5DEhS/vTSngNOCxjZiXAauBsd19jZt8HGtz9q73aXAWcDXwBOAn4A7DA3Rv6XOtW4FaAKVOmLCotLR3O70Vk1LR0dLG9sokdlY3sONjE9tDN2tqWYC9/xvh0rjt9CtcuLiIt+cg+VGd3D4laQ0eO07CNuZvZBGC1uxeHHp8L3OXuH+zV5lng/7r7S6HHfw61ee1o19WYu0Sbnh5n64EGXt1Zw3NvHmBtaS1ZKYncsGQq+RnJrC2tZd2ed6iobyMpPo6MQAJZKYl87Iwp3Hz2NA3tyKAM25i7ux8ws31mNtvdtwHnA1v6NNsbOv6SmRUAs4Hdx1G3SMSKizPmTspi7qQsPr10Ouv31rLyhd386C87cYcJmQFKinNYPj6D1s5umto72VHZxN3PbuWZN/Zzz1WnMrMgI9zfhkSJwc6WWUhwKmQSwdC+GVgO4O4rzGwS8DNgImAEe/G/ONY11XOXWFFe14q7Mzk75T07VLk7T26o4JtPv0lzezcfXzKVS+ZN4H1TsrX8sfRLyw+IRJDqpna+9cwWnn1jP109TlZKImedlEteejJpyQmkJ8fT0dVDQ1sXDa2d1LV2UtPcQW1zBy0d3VxTUshnzpsR/CSvRDWFu0gEamjr5OUd1fz5rYO8vucdGlo7aW7vpqO7B7PgRieZKYlkBhLJTU9iXFoSrR3d/H5LJXnpyfzjRbO4uqRI4/dRTOEuEkU6unpIiLOjbk+4YV8d33pmC+tKa8kIJHDyhOA8/LmTsjjrpFym5qa929ZDSzIEEuMZl5Y0Wt+CDBOFu0iMcXeee7OSl3dW8db+RrYdaKSxPfhZwinjUjlzei41zR1sLKujqrGdlMR47rr0ZG5YMlV72kYQhbtIjHN3dlU188rOal7aUc1rb9eQn5HMgsJsTi3M4vltVbywvYqzTsrl238zn+qmDlbtqmbN2+8wMSvANSVFLJqa856bwBJeCncROSZ35+HX93H3M1to7uh+9/jsggzKalto7uhmel4aH144mdOnjWNhUTYpSVpULdy0nruIHJOZcd3pUzhnRh6/Xl/GrIIMlkzPZVxaEs3tXfxm034eXbuP7/5xOwAJccbJEzMoyAiQHkggPTmBSdkpzJ2UybzJWeSlJw/wjDKa1HMXkWOqbe7gr/tqWVday8Z99dS2dNDU3kVjWxfvNB9eQ3BSVoBzZuaxbNZ4zpmRR1aqVtAcCRqWEZER19DWyZaKBjaX17N+by0v76imoa2LuND2hrnpSeSlJzO7IIMbzpyqHbCGgcJdREZdV3cPG8vqeGlHNWW1rdQ0tVPd1MHW/Q048KFTJ/Lpc6czd1KmbtQeJ425i8ioS4iPY9HUcSyaOu6I4xV1rfz0lbf55Zq9PLmhgpzUROZMymTupCzizCirbaGstpXalg7SkhJIDySQGUhgxvgMFhRmcWpRNpOyAvR4cFVNM7Rj1gDUcxeRUVPf2skzb1SwqayeNysa2HagESe47k5hTirj0pJo6QiO59e1dLK7uonO7vdmVJzBqYXZLJ2Vz7JZecwYn0FGckJMzNfXsIyIjHld3T2Y2VGXS2jr7OatA428EfrgVUJcHAnxRnN7F6/squGNsrp3N02JM8hMSSQjkEBSfBxJCfEkJcSRkhhHalICqUnxnD0jj2sXF0X0kJCGZURkzBto5ctAYjwLi7JZWJTd7/na5g5W7a6hoq6V+tZO6ls7aWrror27h46uHtq7emjr6KayoY26lk6eeWM/v9t8gHuuOpXxmf3vltXa0U1dawcTMgMR/UNA4S4iESsnLYnL5k8cVFt35xerS7n72a1c8v2X+Prlc1gyPZfxGcmYGdsONPLgmlKeWF9OY3sXGYEETpmQycyCdDICiaQkxpOSFMcZ03JZcJQfNmOJhmVEJKbsPNjI5x7ewJsVwV1AA4lx5KUnU1bbSlJCHB+cP5GFRdlsr2zkrQON7KpqoiW0MuchHzh5PJ+/YBbzC7MGfL6DDW1UNrQzd1LmsNwT0Ji7iMhRdHT1sHp3DaU1zZTWtFBR38rComyuWlR01JUyu7qD6+k/9NpeVr64m/rWTs6ZkceS6eNoILT3AAAFRUlEQVRYUJTNnImZ1DR3sL2yke0HGtmyv4FN5fVUNrQDMDU3lRuWTOXqRUUn9AEvhbuIyAhpbOvkZ6/s4Ym/lrO7uvk95+MMpuWlcWphNvMnZ5EeSODR1/extrSWlMR4/uGiWdxy7vTjem7dUBURGSEZgUTuOH8md5w/k/rWTjaV1bN1fwP5GcnMLEjnpPx0AolHzsO/pqSIzeX1/NeqUiZlp4x4jYPdQzWb4B6q8wAHPunuq/q0eT/wPSARqHb3Zce6pnruIiJDN9w99+8Dv3P3q8wsCThigYhQ+P8YuMTd95rZ+CFXLCIiw2bAcDezLGApcBOAu3cAHX2afQx43N33htocHN4yRURkKI79CYKgaUAV8FMz+6uZ3WdmaX3azAJyzOwvZrbOzG4c9kpFRGTQBhPuCcD7gP9w99OAZuCuftosAj4IXAx81cxm9b2Qmd1qZmvNbG1VVdWJVS4iIkc1mHAvA8rcfU3o8WMEw75vm+fcvdndq4EXgQV9L+TuK929xN1L8vPzT6RuERE5hgHD3d0PAPvMbHbo0PnAlj7NngTOMbMEM0sFzgC2DmulIiIyaIOdLXMH8GBopsxu4GYzux3A3Ve4+1Yz+x3wBtAD3Ofum0ekYhERGZA+oSoiEkHG/PIDZlYFlB7nX88DqoexnEin1+NIej0O02txpGh4Paa6+4A3LcMW7ifCzNYO5idXrNDrcSS9HofptThSLL0eg5ktIyIiEUbhLiIShSI13FeGu4AxRq/HkfR6HKbX4kgx83pE5Ji7iIgcW6T23EVE5BgiLtzN7BIz22ZmO82s7xo3Uc3MiszseTPbYmZvmtnnQsfHmdkfzGxH6L854a51NJlZfGhRu2dCj6eZ2ZrQe+SR0IfvYoKZZZvZY2b2lpltNbMzY/X9YWafD/072WxmD5lZIJbeGxEV7mYWD/wIuBSYA1xnZnPCW9Wo6gL+wd3nAEuAz4a+/7uAP7n7TOBPvHdht2j3OY5c7uI7wHfdfQZQC3wqLFWFx6G9F04muL7TVmLw/WFmk4G/B0rcfR4QD1xLDL03IircgdOBne6+O7Su/MPAh8Nc06hx9/3uvj70dSPBf7iTCb4GPw81+zlwZXgqHH1mVkhwNdL7Qo8N+ADBBe4ghl6PXnsv/ASCey+4ex2x+/5IAFLMLIHgBkP7iaH3RqSF+2RgX6/HZaFjMcfMioHTgDVAgbvvD506ABSEqaxw+B7wvwiuaQSQC9S5e1focSy9R46290LMvT/cvRy4F9hLMNTrgXXE0Hsj0sJdADNLB34N3OnuDb3PeXD6U0xMgTKzDwEH3X1duGsZIwbceyFW3h+h+wofJvgDbxKQBlwS1qJGWaSFezlQ1OtxYehYzDCzRILB/qC7Px46XGlmE0PnJwKxss3h2cAVZraH4BDdBwiOOWeHfhWH2HqPHG3vhVh8f1wAvO3uVe7eCTxO8P0SM++NSAv314GZoTveSQRvkDwV5ppGTWg8+SfAVnf/916nngI+Efr6EwTX14967v5P7l7o7sUE3wt/dvfrgeeBq0LNYun1ONreC7H4/tgLLDGz1NC/m0OvRcy8NyLuQ0xmdhnBcdZ44H53/z9hLmnUmNk5wEvAJg6PMX+Z4Lj7o8AUgittXuPu74SlyDAxs/cD/+juHzKz6QR78uOAvwIfd/f2cNY3WsxsIcGby+/uvUCwExdz7w8z+yawnOAss78CtxAcY4+J90bEhbuIiAws0oZlRERkEBTuIiJRSOEuIhKFFO4iIlFI4S4iEoUU7iIiUUjhLiIShRTuIiJR6H8AWTVQyLk40eEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_network(network,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MHLinearGRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.5/dist-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type MultiHeadedAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(network,\"network.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mrr(network,k,test_loader):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:,-2]\n",
    "            _,ind = torch.topk(predictions_logp, k,dim=-1)\n",
    "            mrr = torch.zeros(predictions_logp.size())\n",
    "            mrr.scatter_(-1,ind.cpu(),1/torch.range(1,k).repeat(*ind.size()[:-1],1).type(torch.FloatTensor).cpu())\n",
    "            actual_next_tokens = item_batch_ix[:, -1]\n",
    "\n",
    "            logp_next = torch.gather(mrr.to(device)*mask_batch_ix[:, -2,None], dim=1, index=actual_next_tokens[:,None])\n",
    "#             if mask_batch_ix[:,-2].sum() >0:\n",
    "            loss = logp_next.sum()/mask_batch_ix[:,-2].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect() \n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def validate_recall(network,k,test_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    \n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, -2]\n",
    "            minus_kth_biggest_logp,_ = torch.kthvalue(-predictions_logp.cpu(), k,dim=-1,keepdim=True)\n",
    "            prediicted_kth_biggest = (predictions_logp>(-minus_kth_biggest_logp.to(device)))\\\n",
    "                                        .type(torch.FloatTensor).to(device)\n",
    "            actual_next_tokens = item_batch_ix[:, -1]\n",
    "\n",
    "            logp_next = torch.gather(prediicted_kth_biggest*mask_batch_ix[:, -2,None], dim=1, index=actual_next_tokens[:,None])\n",
    "            loss = logp_next.sum()/mask_batch_ix[:,-2].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Linear User-based GRU:  0.053085506\n",
      "Recall score for Linear User-based GRU:  0.16474381\n"
     ]
    }
   ],
   "source": [
    "linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Linear User-based GRU: \",linear_mrr_score)\n",
    "linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Linear User-based GRU: \",linear_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on LastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415031"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.max([lf_train_items.max()+1,lf_val_items.max()+1,lf_test_items.max()])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "n_users = int(np.max([lf_train_users.max()+1,lf_val_users.max()+1,lf_test_users.max()])+1)\n",
    "n_items = int(np.max([lf_train_items.max()+1,lf_val_items.max()+1,lf_test_items.max()])+1)\n",
    "network = LinearGRU(n_users=n_users,n_items=n_items).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "opt = torch.optim.SGD(network.parameters(),lr =0.001)\n",
    "\n",
    "history = []\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(lf_train_users),torch.LongTensor(lf_train_items),torch.FloatTensor(lf_train_mask))),\\\n",
    "            batch_size=20,shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(lf_val_users),torch.LongTensor(lf_val_items),torch.FloatTensor(lf_val_mask))),\\\n",
    "            batch_size=20,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(lf_test_users),torch.LongTensor(lf_test_items),torch.FloatTensor(lf_test_mask))),\\\n",
    "            batch_size=20,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XecVOXZ//HPtYWl9yKwy4IUEREQl2Wxi41oFI0FUFAEJSaWGGLyM3lMYsyTYkxs0cQHQVE60ajEhgUV2y4sRREEXHrvve/u9ftjDnGz2TLAzs7s7Pf9es2LmXPuc891GJjvnHYfc3dEREQqWkK0CxARkfikgBERkYhQwIiISEQoYEREJCIUMCIiEhEKGBERiQgFjEgpzKytmbmZJQWv3zKzW8Jpexzv9QszG30i9YrEGgWMxC0ze9vMHiphen8z23isYeDu33H3FyqgrgvMbG2xvn/v7redaN8isUQBI/HsBWCwmVmx6UOACe6eH4WaYlZJgXusIWwh+l4RQAEj8e1VoAlw7tEJZtYI+C7wYvD6CjObZ2a7zWyNmT1YWmdm9qGZ3RY8TzSzP5vZVjNbDlxRrO2tZva1me0xs+Vm9v1geh3gLaCVme0NHq3M7EEzG19k+avMbKGZ7Qze99Qi81aa2X1m9qWZ7TKzKWZWs4y6hwW17DCz6WaWXmSem9mdZvYN8E0Z084ys9nB+802s7OK/b38zsw+BfYDJ5dWi1QvChiJW+5+AJgK3Fxk8g3AYnf/Ini9L5jfkFBI/MDMrg6j+9sJBdUZQAZwXbH5m4P59YFbgcfMrKe77wO+A6x397rBY33RBc2sEzAJuBdoBrwJ/MvMahRbj35AO6AbMLSkIs2sP/AL4HtBXx8HfRd1NdAb6FLSNDNrDLwBPEkosB8F3jCzJkXaDwFGAPWAVSXVItWPAqYMZnZ98Cuy0MwySmmTZmYfmNmioO2Piszrbmafm9kCM/uXmdUvMq9bMG9hML9mMH1A8Mt0oZk9HEaNnYN+DpnZfRWx3nHmBeC6Ir/wbw6mAeDuH7r7AncvdPcvCX35nh9GvzcAj7v7GnffDvyh6Ex3f8Pdl3nIR8A7FNmSKscA4A13f9fdjwB/BmoBZxVp86S7rw/e+19Aj1L6ugP4g7t/HewS/D3Qo+hWTDB/exDIJU27AvjG3ce5e767TwIWA1cWaT/W3RcG84+EuZ4S5xQwgeDA69hik78i9MtvZhmL5gM/cfcuQBZwp5kd/SU4Grjf3U8HXgF+GrxXEjAeuMPdTwMuAI4EvwgfAS4Kpp9kZheVU/p24B5CX0JSjLt/AmwFrjaz9kAmMPHofDPrHfxA2GJmuwh9ITcNo+tWwJoir//jV7uZfcfMss1su5ntBC4Ps9+jff+7P3cvDN6rdZE2G4s83w/ULaWvdOCJYFfbTkL/XqxYX2tKWK7otP+oJ7AqjD6kmlPAlCH41beknDYb3H1u8HwP8DXf/sfrxLfh9C5wbfD8UuDLo7tp3H2buxcQ2nf9jbtvCdq9d3QZM2tmZi8H+79nm9nZwbKb3X02oF+NpXuR0JbLYGC6u28qMm8iMA1Ic/cGwDOEvoDLswFIK/K6zdEnZpYCvEwo9Fu4e0NCu7mO9lveEObrCQXD0f4seK91YdRV3Brg++7esMijlrt/VqRNSfUUnfYf9QTaFKtHw7LLf1HAVCAza0ton3xOMGkh0D94fj3ffiF1Ajw44DrXzH4WTM8DTrHQNRVJhPaDH13mCeAxd+9FKHR0zUT4XgQuJnTcpPhpxvWA7e5+0MwygRvD7HMqcI+ZpQYnDtxfZF4NIAXYAuSb2XcI/ag4ahPQxMwalNH3FWZ2kZklAz8BDgGfldK+LM8APzez0wDMrIGZXX+MfbwJdDKzG80sycwGEDpe8/px1CPVyHFdFBZPzCyH0JdBXaCxmc0PZv0/d59+DP3UJfSr9V533x1MHgY8aWa/JPQr+XAwPQk4B+hFaPfG+2Y2x93fN7MfAFOAQkJfKO2DZS4mdMD16FvWN7O67r73mFe6mnH3lWb2GdCd0OdQ1A+Bv5jZU8BHhL7cG4bR7bOEfih8AewmtLXSN3i/PWZ2T9BXCqFjJP9+X3dfbGaTgOVmlsh/HlzH3ZeY2WDgr4S2hucDV7r7YY6Ru78S/NucHBx32UVoa/ofx9DHNjP7LqEfOX8n9EPou+6+9VjrkerFdMOxEDO7ABjq7kNLmPchcJ+755aybDKhX3PT3f3RUtp0Asa7e6aZDQS+4+63BPN+CRx090eKLTMC6ODuPzOzrUCqux8spf8Hgb3urmMxIhITtIvsBAX7x8cAXxcPFzNrHvyZADxAaHcFwHTgdDOrHewKOx9YVGyZRoR+XR/dFfYOcHeRvks7a0hEJCYoYMpgZtdYaEiPPoTO+58eTG9lZm8Gzc4mdA1AXzObHzwuD+YNMrOlhE7pXA88D+DuOwhdSzCb0O6Pue7+RrDME2a2CPgU+KO7Lw2m3wNkBKcwLyJ0thNmdlJQ40jgATNbW/R0aBGRaNEuMhERiQhtwYiISERU67PImjZt6m3bto12GSIiVcqcOXO2unuz8tpV64Bp27YtubklnhgmIiKlMLOwxpvTLjIREYkIBYyIiESEAkZERCJCASMiIhGhgBERkYhQwIiISEQoYEREJCIUMMfhvUWbeHnO2miXISIS06r1hZbHw92ZOGs1HyzZTEICXHNGarRLEhGJSdqCOUZmxt9u6slZ7Zvwk6lf8Oq847mLrYhI/FPAHIeayYmMvrkXvds1YeTU+bw2XyEjIlKcAuY41aqRyJihGWS2a8yPp8znX1+sj3ZJIiIxRQFzAmrXSOK5ob3IaNuYe6fM540vN0S7JBGRmBHRgDGzfma2xMzyzOz+EuanmNmUYH6OmbUtMu/nwfQlZnZZeX2a2UVmNje4o+QnZtYhkut2VO0aSTw/tBc92zTknsnzeGuBQkZEBCIYMGaWCDwNfAfoQuj2wV2KNRsO7HD3DsBjwMPBsl2AgcBpQD/gb2aWWE6ffwducvcewETggUitW3F1UpJ4/tZMeqQ15O5J83j7q42V9dYiIjErklswmUCeuy9398PAZKB/sTb9gReC5y8BF5mZBdMnu/shd18B5AX9ldWnA0fvRd8AqNSDInVTkhh7ay+6pTbgrolzeWehQkZEqrdIBkxrYE2R12uDaSW2cfd8YBfQpIxly+rzNuBNM1sLDAH+WFJRZjbCzHLNLHfLli3HsVqlq1czmbHDMunaugF3TpzLe4s2VWj/IiJVSTwd5P8xcLm7pwLPA4+W1MjdR7l7hrtnNGtW7h0/j1n9msm8ODyTLi3r88MJc5mxWCEjItVTJANmHZBW5HVqMK3ENmaWRGjX1rYyli1xupk1A7q7e04wfQpwVsWsxrELhUxvOresxx3j5vLBks3RKkVEJGoiGTCzgY5m1s7MahA6aD+tWJtpwC3B8+uAGe7uwfSBwVlm7YCOwKwy+twBNDCzTkFflwBfR3DdytWgVjLjhvWm00l1+f64OXy0tGJ3x4mIxLqIBUxwTOUuYDqhL/up7r7QzB4ys6uCZmOAJmaWB4wE7g+WXQhMBRYBbwN3untBaX0G028HXjazLwgdg/lppNYtXA1qJzN+eG86NKvL7S/mMlMhIyLViIU2GKqnjIwMz83Njfj77Nh3mBtH57B8y17G3NKLczo2jfh7iohEipnNcfeM8trF00H+mNWoTg0m3Nabdk3rcNuLs/ksb2u0SxIRiTgFTCVpHIRMeuM6DHthNp8v2xbtkkREIkoBU4ma1E1hwu29SWtUm2FjZ5OzXCEjIvFLAVPJmtZNYeLtWbRuVItbx85m1ort0S5JRCQiFDBR0KxeChNv703LBjW59flZ5K5UyIhI/FHAREnzejWZdHsWLerX5JbnZjFnlUJGROKLAiaKmtevyaQRWTSvX5NbnpvN3NU7ol2SiEiFUcBEWYv6oS2ZpnVrcMuYWcxfszPaJYmIVAgFTAw4qUFoS6ZRnRoMGZPDl2sVMiJS9SlgYkTLBrWYNCKLhrWTGTw6hwVrd0W7JBGRE6KAiSGtG9Zi0u1Z1K+VzOAxOXy1TiEjIlWXAibGpDaqzaTbs6ibksTgMTksXK+QEZGqSQETg9Ia12byiCxqJycyeHQOX2/YHe2SRESOmQImRqU1rs2kEVnUTE7kptE5LN6okBGRqkUBE8PSm9Rh0u1Z1EhM4KZnc1i6aU+0SxIRCZsCJsa1bVqHSSOySEo0bnw2m28UMiJSRShgqoB2Tesw8fYsEswY9GwOeZsVMiIS+xQwVUT7ZnWZeHsWAIOezWHZlr1RrkhEpGwKmCqkQ/O6TB7RG3dn0KhslitkRCSGKWCqmA7N6zHp9iwKCp1Bz2azYuu+aJckIlIiBUwV1LFFPSbensWRgtCWzEqFjIjEIAVMFXXKSfWYeHtvDuUXMOjZbFZv2x/tkkRE/oMCpgrrfFJ9JtyWxYEjoZBZs10hIyKxQwFTxXVpVZ8Jt/Vm76F8Bo5SyIhI7FDAxIHTWjVgwm292XPwCIOezWbdzgPRLklERAETL7q2bsCE27LYdeAIA0d9znqFjIhEmQImjpye2oDxw3uzc98RBo7KZsMuhYyIRI8CJs50T2vIi8Mz2bHvMINGZbNx18FolyQi1ZQCJg6d0aYRY4dlsnXvYQY9m82m3QoZEal8Cpg4dWZ6I14Y1ovNuw8y6NlsNitkRKSSKWDi2JnpjRk7LJONu4KQ2aOQEZHKo4CJc73aNmbsrZls2HWQm57NYcueQ9EuSUSqCQVMNZDZrjHPDe3F2h0HuGl0Nlv3KmREJPIiGjBm1s/MlphZnpndX8L8FDObEszPMbO2Reb9PJi+xMwuK69PM/vYzOYHj/Vm9mok162qyTq5CWOGZrB6+34Gj85hm0JGRCIsYgFjZonA08B3gC7AIDPrUqzZcGCHu3cAHgMeDpbtAgwETgP6AX8zs8Sy+nT3c929h7v3AD4H/hmpdauqzmrflDG39GLF1n3cNDqH7fsOR7skEYljkdyCyQTy3H25ux8GJgP9i7XpD7wQPH8JuMjMLJg+2d0PufsKIC/or9w+zaw+0BfQFkwJzu7wbcgMHp3DDoWMiERIJAOmNbCmyOu1wbQS27h7PrALaFLGsuH0eTXwvrvvLqkoMxthZrlmlrtly5ZjWqF4cU7Hpjx7cwZ5W/YyeEwOO/crZESk4sXjQf5BwKTSZrr7KHfPcPeMZs2aVWJZseW8Ts0YNeRMvtkUCpld+49EuyQRiTNlBkxw3OPHx9n3OiCtyOvUYFqJbcwsCWgAbCtj2TL7NLOmhHajvXGcNVcrF5zSnP8bciZLN+5lyHM57DqgkBGRilNmwLh7AaEtguMxG+hoZu3MrAahg/bTirWZBtwSPL8OmOHuHkwfGJxl1g7oCMwKo8/rgNfdXVcUhunCzs35++CefL1hNzePyWH3QYWMiFSMcHaRfWpmT5nZuWbW8+ijvIWCYyp3AdOBr4Gp7r7QzB4ys6uCZmOAJmaWB4wE7g+WXQhMBRYBbwN3untBaX0WeduBlLF7TEp20akt+NtNZ7Jow25uHjOLPQoZEakAFtpgKKOB2QclTHZ37xuZkipPRkaG5+bmRruMmDF94UbunDCXbqkNeHF4b+qmJEW7JBGJQWY2x90zymtX7haMu19YwqPKh4v8t8tOO4mnbjyDL9buYuhzs9h7KD/aJYlIFVZuwJhZAzN79OipvWb2FzNrUBnFSeXr17Ulfx10BvPW7OTW52exTyEjIscpnGMwzwF7gBuCx27g+UgWJdF1+ekteXLgGcxdvZNbx85m/2GFjIgcu3ACpr27/zq4en65u/8GODnShUl0XdGtJY8P6EHuyu0MU8iIyHEIJ2AOmNk5R1+Y2dmAbvZeDVzZvRWPDejBrBXbGT42lwOHC6JdkohUIeGcJnQH8GKR4y47+PbaFYlz/Xu0ptCdkVO/4LYXZzPmll7UTE6MdlkiUgWUGTBmlgCc4u7dg0EkKW2ML4lf15yRSmEh3PfSF9z+Yi7P3pyhkBGRcpV3JX8h8LPg+W6FS/V17Zmp/OnabnySt5UR4+Zw8Ih2l4lI2cI5BvOemd1nZmlm1vjoI+KVScy5PiONh7/XjZlLt3DH+DkcylfIiEjpwjkGMyD4884i0xydSVYt3dArjUJ37v/nAn4wfi5/H9yTlCTtLhOR/1beaMoJwGB3b1fsoXCpxgZmtuH315zOjMWbuXPCXA7nF0a7JBGJQeEcg3mqkmqRKuTG3m347dVdee/rzdw5USEjIv8tnGMw75vZtcGtjEX+bUhWOg/1P413F23i7klzOVKgkBGRb4UTMN8H/gEcMrPdZrbHzHQ2mQBwc5+2PHhlF6Yv3MQ9k+YpZETk38IZTbmeuye4ew13rx+8rl8ZxUnVMPTsdvzyu11466uN/GiyQkZEQkoNGDMbXOT52cXm3RXJoqTqGX5OOx644lTeXLCRe6fMJ18hI1LtlbUFM7LI878WmzcsArVIFXfbuSfzi8s788aXG/jx1C8UMiLVXFnXwVgpz0t6LQLAiPPaU+jwx7cWk2Dw6A09SEzQPxeR6qisgPFSnpf0WuTf7ji/PQWFziPTl5BoxiPXd1fIiFRDZQVMZzP7ktDWSvvgOcFrXWgpZbrzwg64O39+Zylmxp+u66aQEalmygqYUyutColLd/XtSEEhPPbeUhIMHr62GwkKGZFqo9SAcfdVlVmIxKcfXdyRQneeeP8bEsz4w/dOV8iIVBPhDHYpckLuDULmrzPySEiA312tkBGpDhQwEnFmxshLOlHoztMfLMPM+N/+XRUyInGu3IAxsyuBN4KBL0WOi5lx36WnUFAIz3y0jASD3/bvioa4E4lf4d4P5nEzexl4zt0XR7gmiVNmxv/rdwruzv/NXE6iGQ9edZpCRiROlRsw7j7YzOoDg4CxZubA88Akd98T6QIlvpgZ93+nMwWFzuhPVmBm/PrKLgoZkTgUzmjKuPtu4CVgMtASuAaYa2Z3R7A2iVNmxv9ccSrDzm7H2M9W8tvXv8Zd1+6KxJtwjsFcBdwKdABeBDLdfbOZ1QYW8d/jlImUy8z45XdPpdCd5z5dQWIC/OLyU7UlIxJHwjkGcy3wmLvPLDrR3feb2fDIlCXVwdHdY4XuPPvxChKC3WcKGZH4EM4xmFvM7KRgS8aB2e6+MZj3fqQLlPhmZvzmqtMoDA78JyQYP7vsFIWMSBwIZxfZcODXwAxC45D91cwecvfnIl2cVA9mxkNXdaXQ4e8fhk5hvu9ShYxIVRfOLrKfAWe4+zYAM2sCfAYoYKTCJCSELr704GLMRDNGXnpKtMsSkRMQzllk24CipyPvCaaVy8z6mdkSM8szs/tLmJ9iZlOC+Tlm1rbIvJ8H05eY2WXl9WkhvzOzpWb2tZndE06NEjsSEozfXX06AzLSeHJGHo+/tzTaJYnICQhnCyYPyDGz1wgdg+kPfGlmIwHc/dGSFjKzROBp4BJgLTDbzKa5+6IizYYDO9y9g5kNBB4GBphZF2AgcBrQCnjPzDoFy5TW51AgDejs7oVm1jzsvwWJGQkJoQExC9x5/L1vMIwfXdwx2mWJyHEIJ2CWBY+jXgv+rFfOcplAnrsvBzCzyYTCqWjA9AceDJ6/BDxloR3v/YHJ7n4IWGFmeUF/lNHnD4Abjw5p4+6bw1g3iUEJCcbD13aj0J3H3ltKYkJo6H8RqVrCOYvsNwBmVjd4vTfMvlsDa4q8Xgv0Lq2Nu+eb2S6gSTA9u9iyrYPnpfXZntDWzzXAFuAed/+meFFmNgIYAdCmTZswV0UqW2KC8ch13XHn3zctu/PCDtEuS0SOQbnHYMysq5nNAxYCC81sjpmdFvnSjlkKcNDdM4BnKeUkBHcf5e4Z7p7RrFmzSi1Qjk1igvHn67vTv0crHpm+hGc+Wlb+QiISM8LZRTYKGOnuHwCY2QWEvsDPKme5dYSOiRyVGkwrqc1aM0sCGhA6gaCsZUubvhb4Z/D8FULjpUkVl5hg/OX67hQ6/PGtxSQYjDivfbTLEpEwhHMWWZ2j4QLg7h8CdcJYbjbQ0czamVkNQgftpxVrMw24JXh+HTDDQ4NSTQMGBmeZtQM6ArPK6fNV4MLg+fmATkGKE0mJCTx2Q3eu6NaS37+5mNEfL492SSIShnC2YJab2S+BccHrwUC5/8ODYyp3AdOBREJD/S80s4eAXHefBowBxgUH8bcTCgyCdlMJHbzPB+509wKAkvoM3vKPwAQz+zGwF7gtjHWTKiIpMYHHB/TA3fnfN74mwYxh57SLdlkiUgYrbxRbM2sE/AY4h9Bpyh8Dv3H3HZEvL7IyMjI8Nzc32mXIMThSUMjdE+fx9sKNPHhlF4aerZARqWxmNic43l2mMrdggmtZ/sfdddGixITkxASeHHQGd02cy4P/WkRCgnFzn7bRLktESlDmMZhgt9Q5lVSLSFhqJCXw1I09ufjUFvzqtYWMy14V7ZJEpAThHIOZZ2bTgH8A+45OdPd/lr6ISGTVSErg6ZvO4Ifj5/LLV78i0Ywbe+u6JpFYEk7A1CR06nDfItOcb08JFomKlKRE/ja4J3eMm8MvXllAgsHATIWMSKwIJ2BGu/unRSeY2dkRqkfkmKQkJfL3wWfy/XFzuP+fC3jzq40MyUqnb+fmJCZouH+RaArnLLK57t6zvGlVkc4iix8HjxQwauZyJuSsYtPuQ7RuWIsbe7dhQK80mtZNiXZ5InEl3LPISg0YM+tD6Gr9e4HHisyqD1zj7t0rotBoUsDEnyMFhbz/9SbGZa/i07xtJCcal5/ekiFZ6ZyZ3kg3MROpABVxmnINoG7QpujIybsJXXUvEnOSExPo17Ul/bq2JG/zXsZnr+LlOWt5bf56Op9UjyF90rm6R2vqpISzd1hETkQ4u8jS3T0uzwPVFkz1sP9wPq/NX8+4z1exaMNu6qYkcW3P1gzOSqdji/LuOiEixZ3wLrIiHXUC7gPaUmSLx937lrZMVaGAqV7cnbmrdzI+exVvfLmBwwWFZJ3cmCFZbbn0tBYkJ4YzNJ+IVGTAfAE8A8wBCo5Od/c5J1pktClgqq9tew/xjzlrGZ+9irU7DtC8XgoDM9swKDONlg1qRbs8kZhWkQEzx93PrLDKYogCRgoKnY+Wbmbc56v4cOkWEsy45NQWDOmTzlntm+ikAJESVMhYZIF/mdkPCd1j5dDRie6+/QTqE4kJiQlG384t6Nu5Bau37WfCrFVMnb2Gtxdu5ORmdRjcO51rz0ylQa3kaJcqUuWEswWzooTJ7u4nR6akyqMtGCnJwSMFvLlgA+OyVzFv9U5qJidwdY/QSQFdWzeIdnkiUVdhu8jimQJGyvPVul2Mz17Fq/PXcfBIIWe0aciQrHQuP70lNZMTo12eSFRU5DGY2sBIoI27jzCzjsAp7v56xZQaPQoYCdeuA0d4OTgpYPnWfTSqncwNvdIY3DudtMa1o12eSKWqyICZQugMspvdvWsQOJ+5e4+KKTV6FDByrNydz5ZtY9znq3j3600UunNBp2YM6ZPO+Z00/plUDxV5kL+9uw8ws0EA7r7fdGqNVFNmxtkdmnJ2h6Zs2HWASbPWMGnWaoaNzSW1US1u6p3ODRmpNNH4ZyJl33AscNjMahEaoh8za0+Rs8lEqquWDWox8pJOfHZ/X56+sSepjWrx8NuL6fOHGfx4ynzmrNpBdT7GKRLOFsyvgbeBNDObAJwNDI1kUSJVSXJiAld0a8kV3VryzaY9ofHP5q7jlXnr6NKyPkP6pNO/Rytq19D4Z1K9hHUWmZk1AbIAA7LdfWukC6sMOgYjkbLvUD6vzl/HuM9XsXjjHurVTOLanqkMzkqnQ/O60S5P5IRE5DRlM3vQ3R88kcJiiQJGIs3dmbNqB+OyV/Hmgg0cKXDOat+EIVnpXNKlBUka/0yqoEgFTFzcaOwoBYxUpq17DzFl9hom5qxm3c4DtKifwo2Z6QzMTKNF/ZrRLk8kbJEKmHnufsYJVRZDFDASDQWFzgeLNzMuexUfLd1CUoJx6WktGJyVTp+TNf6ZxL5IBUyCuxeeUGUxRAEj0bZy6z4mzlrN1Nw17Nx/hA7N6zK4dxu+d2Yq9Wtq/DOJTRV5oeWfgP8FDhA6m6wb8GN3H18RhUaTAkZixcEjBbz+ZWj8sy/W7KR2jUT692jNkKx0urSqH+3yRP5DRQbMfHfvYWbXAN8lNGzMTHfvXjGlRo8CRmLRl2tDN0V7bf56DuUXkpHeiCF90unX9SRSkjT+mURfRQbMV8EQMaOBl9z9bTP7QgEjElk79x/mpWD8s5Xb9tOkTg0G9Erjxt5tSG2k8c8keioyYP4IXE1oF1km0BB43d17V0Sh0aSAkaqgsND5dNlWxn2+ive+3oQDF3VuzuCsdM7r2IwEjX8mlaxCD/KbWWNgl7sXBINd1nf3jRVQZ1QpYKSqWb/zAJNmrWbSrDVs3XuINo1rMzirDdefmUajOjWiXZ5UExW5BXM98La77zGzB4CewP+6+9yKKTV6FDBSVR3OL2T6wo2My17FrBXbqZGUwJXdWjGkTzrdUxvoVGeJqIoMmC/dvZuZnUPobLJHgF9pF5lIbFiyMTT+2T/nrmXf4QJOb92AIVnpXNm9FbVq6KQAqXgVGTDz3P0MM/sDsMDdJ8bLBZcKGIknew/l88q8dYz7fCVLN+2lfs0krs9I46bebTi5mcY/k4oTbsCEMxDSOjP7P2AA8KaZpYS5HGbWz8yWmFmemd1fwvwUM5sSzM8xs7ZF5v08mL7EzC4rr08zG2tmK8xsfvCo8jdEEzkWdVOSGJKVzvR7z2Pq9/tw/inNeeGzlfT9y0cMGZPD9IUbyS+Im+ukpQoI95bJ/QhtvXxjZi2B0939nXKWSwSWApcAa4HZwCB3X1SkzQ+Bbu5+h5kNBK4Jbm7WBZhE6Ky1VsB7QKdgsRL7NLOxhM5ueyncldcWjMS7zXsOMnX2GibkrGbDroO0bFCTGzPbMCAzjeb1NP6ZHJ8K24Jx9/3AMuAyM7sLaF5euAQygTx3X+7uh4HJQP9ibfoDLwTPXwIuCu6W2R+Y7O6H3H0FkBf0F048ce2FAAASs0lEQVSfIhJoXq8md/XtyMc/u5BRQ86kQ/O6/OXdpZz1hxncNXEuOcu36aZoEjHlBoyZ/QiYADQPHuPN7O4w+m4NrCnyem0wrcQ27p4P7AKalLFseX3+zsy+NLPHgl15Ja3PCDPLNbPcLVu2hLEaIlVfUmICl552EuOG9+aD+y5g6Fltmbl0CwNGZXPZ4zMZ9/lK9hw8Eu0yJc6EcyxlONDb3X/l7r8idOOx2yNb1nH5OdAZ6AU0Bv5fSY3cfZS7Z7h7RrNmzSqzPpGY0K5pHR74bhdyfnExf7quGylJifzytYVk/f59Hnh1AYs37o52iRInwrmHqwEFRV4XBNPKsw5IK/I6NZhWUpu1ZpYENAC2lbNsidPdfUMw7ZCZPQ/cF0aNItVWrRqJ3JCRxg0ZaXyxZifjslcxNXct47NXk9m2MYP7pNPvtJOokaSbosnxCSdgngdyzOyV4PXVwJgwlpsNdDSzdoRCYCBwY7E204BbgM+B64AZ7u5mNg2YaGaPEjrI3xGYRSjYSuzTzFq6+4bgGM7VwFdh1CgiQPe0hnRPa8j/XH4q/5izhvHZq7ln0jya1q3BwF5tGNS7Da0b1op2mVLFhDtUTE/gnODlx+4+L6zOzS4HHgcSgefc/Xdm9hCQ6+7TzKwmMA44A9gODHT35cGy/wMMA/KBe939rdL6DKbPAJoRCqH5wB3uvres+nQWmUjJCgudmd9sYXz2amYs3gTARae2YEhWOud0aKrxz6q5CrnQMjjVeKG7d67I4mKFAkakfGt37GfSrNVMnrWGbfsO07ZJbQZnpXPdmak0rK3xz6qjiryS/zXgbndfXVHFxQoFjEj4DuUX8PZXGxmfvYrZK3eQkpTAVd1D4591S20Y7fKkEoUbMOEcg2kELDSzWcC+oxPd/aoTqE9EqpiUpNBdNvv3aM2i9bsZn7OKV+et4x9z1tI9tQGDg/HPaiZr/DMJCWcL5vySprv7RxGpqBJpC0bkxOw+eIRX5q5jXPYq8jbvpUGtZG7ISOWm3um0bVon2uVJhJzwLjIz6wC0cPdPi00/B9jg7ssqpNIoUsCIVAx3J3v5dsZnrwqNeVbonNepGUOy0unbuTmJOikgrlTELrLHCV28WNyuYN6Vx1mbiMQZM6NP+yb0ad+ETbsPMnnWGibOWsXtL+bSrmkdRl7SiStOb6mzz6qZsrZgZrt7r1LmLXD30yNaWSXQFoxI5OQXFPLOok088d43LNm0h1Nb1uenl3XiwlOa64ZoVVxFDHZZ1mkhuuJKRMqUlJjA5ae35M0fncsTA3uw/3A+w8bmcv0zn5OzfFu0y5NKUFbA5JrZf405Zma3AXMiV5KIxJPEBKN/j9a8N/J8fndNV9bs2M+AUdnc/NwsFqzdFe3yJILK2kXWAngFOMy3gZIB1CB035aNlVJhBGkXmUjlO3ikgBc/X8nfPlzGzv1HuPz0kxh5SSc6NK8X7dIkTBV5oeWFQNfg5UJ3n1EB9cUEBYxI9Ow5eITRH69g9MfLOXCkgO/1TOXeizuS2qh2tEuTclRYwMQzBYxI9G3be4i/f7iMF7NX4e7c1DudOy/sQLN6Jd7SSWKAAiYMChiR2LFh1wGefD+PqblrqJGYwLBz2jLi3PY0qJ0c7dKkGAVMGBQwIrFnxdZ9PPbuUqZ9sZ76NZP4/vntufXsttSuEc7IVlIZFDBhUMCIxK5F63fzl3eW8P7izTStm8LdfTswMDONlCSNdRZtCpgwKGBEYt+cVdv509tLyFmxndYNa3HvxR35Xs9UDT8TRRVxoaWISNSdmd6YySOyGDc8kyZ1a/DTl77kssdn8taCDVTnH8hVgQJGRGKemXFux2a8dufZPDO4JwA/mDCXq576lJlLtyhoYpQCRkSqDDOjX9eWTL/3PP58fXe27zvMzc/NYuCobOas2h7t8qQYHYPRMRiRKutQfgFTZq/hyffz2Lr3EH07N+e+S0+hS6v60S4trukgfxgUMCLxYf/hfMZ+tpJnPlzG7oP5XNm9FSMv6UQ73fQsIhQwYVDAiMSXXQeO8OzM5Yz5ZAWHCwq5ISOVu/t2pFVDDQBfkRQwYVDAiMSnLXsO8fQHeUzMWQ0GQ7LS+eEF7WlSV8PPVAQFTBgUMCLxbe2O/Tzx3je8PHcttZITGX7uydx2bjvq19TwMydCARMGBYxI9ZC3eS+PvbuUNxZsoGHtZH5wfntuOastNZM1KsDxUMCEQQEjUr18tW4Xj0xfwkdLt9Cifgp39+3IgF5pJCfqio1joSv5RUSK6dq6AS8My2TKiCzSGtXmgVe/4qK/fMSr89ZRUFh9f2xHigJGRKqd3ic34R939OH5ob2om5LEvVPmc/kTH/POwo0aFaACKWBEpFoyMy7s3JzX7z6Hp248gyMFhYwYN4dr/vYZn+VtjXZ5cUEBIyLVWkKC8d1urXjnx+fx8LWns3n3QW4cncNNo7OZt3pHtMur0nSQXwf5RaSIg0cKmJizmqc/yGPbvsNc2qUFP7n0FE45qV60S4sZOossDAoYESnN3kP5PP/JCkbNXM7ew/lc3aM1P764E22a1I52aVGngAmDAkZEyrNz/2H+/tEyXvhsJfkFzsDMNO7u25EW9WtGu7SoUcCEQQEjIuHatPsgT83IY9Ks1SQmGEPPassd57enUZ0a0S6t0sXEdTBm1s/MlphZnpndX8L8FDObEszPMbO2Reb9PJi+xMwuO4Y+nzSzvZFaJxGpnlrUr8lvr+7KjJ9cwBWnt2TUx8s5708f8OT737D3UH60y4tJEQsYM0sEnga+A3QBBplZl2LNhgM73L0D8BjwcLBsF2AgcBrQD/ibmSWW16eZZQCNIrVOIiJtmtTm0QE9mH7veZzVoQmPvruU8//0AWM+WcHBIwXRLi+mRHILJhPIc/fl7n4YmAz0L9amP/BC8Pwl4CIzs2D6ZHc/5O4rgLygv1L7DMLnEeBnEVwnEREAOrWox/8NyeDVO8/m1Jb1+e3ri7jwzx8yedZq8gsKo11eTIhkwLQG1hR5vTaYVmIbd88HdgFNyli2rD7vAqa5+4ayijKzEWaWa2a5W7ZsOaYVEhEprkdaQ8bf1puJt/WmRf2a3P/PBVzy2Ez+9cV6Cqv58DNxcaGlmbUCrgf+Wl5bdx/l7hnuntGsWbPIFyci1cJZHZryyg/P4tmbM6iRmMDdk+ZxxV8/YcbiTdV2+JlIBsw6IK3I69RgWoltzCwJaABsK2PZ0qafAXQA8sxsJVDbzPIqakVERMJhZlzSpQVv/uhcnhjYg/2H8xk2Npfrn/mcnOXbol1epYtkwMwGOppZOzOrQeig/bRibaYBtwTPrwNmeCjqpwEDg7PM2gEdgVml9enub7j7Se7e1t3bAvuDEwdERCpdYoLRv0dr3ht5Pr+7pitrduxnwKhsbn5uFgvW7op2eZUmKVIdu3u+md0FTAcSgefcfaGZPQTkuvs0YAwwLtja2E4oMAjaTQUWAfnAne5eAFBSn5FaBxGRE5GcmMBNvdO5tmcqL36+kr99uIwrn/qEy08/iZGXdKJD8/gefkYXWupCSxGpJHsOHmH0xysY/fFyDhwp4Hs9U7n34o6kNqpaw8/oSv4wKGBEJBq27T3E3z9cxovZq3B3buqdzp0XdqBZvZRolxYWBUwYFDAiEk0bdh3gyffzmJq7hhqJCQw7py0jzm1Pg9rJ0S6tTAqYMChgRCQWrNi6j8feXcq0L9ZTv2YS3z+/Pbee3ZbaNSJ2mPyEKGDCoIARkViyaP1u/vLOEt5fvJmmdVO4u28HBmamkZKUGO3S/oMCJgwKGBGJRXNWbedPby8hZ8V2Wjesxb0Xd+R7PVNJTLBolwbEyGjKIiJy7M5Mb8zkEVmMG55Jk7o1+OlLX3LZ4zN5a8GGKjUqgAJGRCQGmRnndmzGa3eezTODewLwgwlzueqpT5m5dEuVCBoFjIhIDDMz+nVtyfR7z+PP13dn+77D3PzcLAaOymbOqu3RLq9MOgajYzAiUoUcyi9gyuw1PPl+Hlv3HqJv5+bcd+kpdGlVv9Jq0EH+MChgRKSq2n84n7GfreSZD5ex+2A+V3ZvxchLOtGuaZ2Iv7cCJgwKGBGp6nYdOMKzM5cz5pMVHC4o5IaMVO7u25FWDWtF7D0VMGFQwIhIvNiy5xBPf5DHxJzVYDAkK50fXtCeJnUrfvgZBUwYFDAiEm/W7tjPE+99w8tz11IrOZHh557Mbee2o37Niht+RgETBgWMiMSrvM17eezdpbyxYAMNayfzg/Pbc8tZbamZfOKjAihgwqCAEZF499W6XTwyfQkfLd1Ci/op3N23IwN6pZGcePxXqehKfhERoWvrBrwwLJMpI7JIa1SbB179iov+8hFLNu6J+HsrYEREqoHeJzfhH3f04fmhvWjbtA5pjSN3ltlRsTkWtIiIVDgz48LOzbmwc/NKeT9twYiISEQoYEREJCIUMCIiEhEKGBERiQgFjIiIRIQCRkREIkIBIyIiEaGAERGRiKjWY5GZ2RZg1XEu3hTYWoHlRFO8rEu8rAdoXWJVvKzLia5Hurs3K69RtQ6YE2FmueEM9lYVxMu6xMt6gNYlVsXLulTWemgXmYiIRIQCRkREIkIBc/xGRbuAChQv6xIv6wFal1gVL+tSKeuhYzAiIhIR2oIREZGIUMCIiEhEKGDKYWb9zGyJmeWZ2f0lzE8xsynB/Bwza1v5VZYvjPUYamZbzGx+8LgtGnWGw8yeM7PNZvZVKfPNzJ4M1vVLM+tZ2TWGI4z1uMDMdhX5TH5V2TWGy8zSzOwDM1tkZgvN7EcltIn5zyXM9agSn4uZ1TSzWWb2RbAuvymhTWS/v9xdj1IeQCKwDDgZqAF8AXQp1uaHwDPB84HAlGjXfZzrMRR4Ktq1hrk+5wE9ga9KmX858BZgQBaQE+2aj3M9LgBej3adYa5LS6Bn8LwesLSEf2Mx/7mEuR5V4nMJ/p7rBs+TgRwgq1ibiH5/aQumbJlAnrsvd/fDwGSgf7E2/YEXgucvAReZmVVijeEIZz2qDHefCWwvo0l/4EUPyQYamlnLyqkufGGsR5Xh7hvcfW7wfA/wNdC6WLOY/1zCXI8qIfh73hu8TA4exc/qiuj3lwKmbK2BNUVer+W//7H9u4275wO7gCaVUl34wlkPgGuDXRcvmVla5ZQWEeGub1XQJ9jF8ZaZnRbtYsIR7GY5g9Av5qKq1OdSxnpAFflczCzRzOYDm4F33b3UzyQS318KGDnqX0Bbd+8GvMu3v2okeuYSGvOpO/BX4NUo11MuM6sLvAzc6+67o13P8SpnParM5+LuBe7eA0gFMs2sa2W+vwKmbOuAor/kU4NpJbYxsySgAbCtUqoLX7nr4e7b3P1Q8HI0cGYl1RYJ4XxuMc/ddx/dxeHubwLJZtY0ymWVysySCX0pT3D3f5bQpEp8LuWtR1X7XADcfSfwAdCv2KyIfn8pYMo2G+hoZu3MrAahg2DTirWZBtwSPL8OmOHBEbMYUu56FNsXfhWhfc9V1TTg5uCspSxgl7tviHZRx8rMTjq6P9zMMgn9f421Hy9A6AwxYAzwtbs/WkqzmP9cwlmPqvK5mFkzM2sYPK8FXAIsLtYsot9fSRXVUTxy93wzuwuYTuhMrOfcfaGZPQTkuvs0Qv8Yx5lZHqEDtgOjV3HJwlyPe8zsKiCf0HoMjVrB5TCzSYTO5GlqZmuBXxM6gIm7PwO8SeiMpTxgP3BrdCotWxjrcR3wAzPLBw4AA2Pwx8tRZwNDgAXBPn+AXwBtoEp9LuGsR1X5XFoCL5hZIqEQnOrur1fm95eGihERkYjQLjIREYkIBYyIiESEAkZERCJCASMiIhGhgBERkYhQwIhUMjP7g5ldaGZXm9nPg2kPmdnFwfN7zax2dKsUOXE6TVmkkpnZDOAK4PfAS+7+abH5K4EMd996DH0muntBhRYqcoJ0oaVIJTGzR4DLgHbA50B7QqPXvkToVgqvA62CxwdmttXdLzSzS4HfACmEbrtwq7vvDYJoCqErtP9EaJRskZihXWQilcTdfwoMB8YCvYAv3b2buz9UpM2TwHrgwiBcmgIPABe7e08gFxhZpNtt7t7T3RUuEnO0BSNSuXoSuuFbZ8Ib7y0L6AJ8Ggx/VYPQ1s9RUyq6QJGKooARqQRm1oPQlksqsBWoHZps84E+ZS1K6D4eg0qZv68i6xSpSNpFJlIJ3H1+cF+OpYS2SGYAl7l7D3c/UKz5HkK36wXIBs42sw4AZlbHzDpVVt0iJ0IBI1JJzKwZsMPdC4HO7r6olKajgLfN7AN330JoZOtJZvYlod1jnSulYJETpNOURUQkIrQFIyIiEaGAERGRiFDAiIhIRChgREQkIhQwIiISEQoYERGJCAWMiIhExP8Hj/lIQcCCCkEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1552dbd56400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-4f235c82d8fa>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0muser_batch_ix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_batch_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_batch_ix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0muser_batch_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_batch_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mitem_batch_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_batch_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mmask_batch_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_batch_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(network,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Linear User-based GRU:  0.05772805\n",
      "Recall score for Linear User-based GRU:  0.18285066\n"
     ]
    }
   ],
   "source": [
    "linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Linear User-based GRU: \",linear_mrr_score)\n",
    "linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Linear User-based GRU: \",linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Rectified Linear User-based GRU:  0.05866462\n",
      "Recall score for Rectified Linear User-based GRU:  0.18724447\n"
     ]
    }
   ],
   "source": [
    "rect_linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Rectified Linear User-based GRU: \",rect_linear_mrr_score)\n",
    "rect_linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Rectified Linear User-based GRU: \",rect_linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Attentional User-based GRU:  0.06445735\n",
      "Recall score for Attentional User-based GRU:  0.20091988\n"
     ]
    }
   ],
   "source": [
    "att_linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Attentional User-based GRU: \",att_linear_mrr_score)\n",
    "att_linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Attentional User-based GRU: \",att_linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Multi-Head Attentional User-based GRU:  0.054245885\n",
      "Recall score for Multi-Head Attentional User-based GRU:  0.18811351\n"
     ]
    }
   ],
   "source": [
    "mh_att_linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Multi-Head Attentional User-based GRU: \",mh_att_linear_mrr_score)\n",
    "mh_att_linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Multi-Head Attentional User-based GRU: \",mh_att_linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Multi-Head Attentional User-based GRU:  0.062313363\n",
      "Recall score for Multi-Head Attentional User-based GRU:  0.2006795\n"
     ]
    }
   ],
   "source": [
    "mh_att_linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Multi-Head Attentional User-based GRU: \",mh_att_linear_mrr_score)\n",
    "mh_att_linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Multi-Head Attentional User-based GRU: \",mh_att_linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Multi-Head Attentional User-based GRU:  0.062356792\n",
      "Recall score for Multi-Head Attentional User-based GRU:  0.2015281\n"
     ]
    }
   ],
   "source": [
    "mh_att_linear_mrr_score = validate_mrr(network,20,test_loader)\n",
    "print(\"MRR score for Multi-Head Attentional User-based GRU: \",mh_att_linear_mrr_score)\n",
    "mh_att_linear_recall_score = validate_recall(network,20,test_loader)\n",
    "print(\"Recall score for Multi-Head Attentional User-based GRU: \",mh_att_linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
