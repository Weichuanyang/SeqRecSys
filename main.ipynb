{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear User Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class LinearGRU(nn.Module):\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        self.emb_size = emb_size\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.gru = nn.GRU(input_size = emb_size*2,hidden_size = hidden_units,dropout = dropout,batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_units,n_items)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        \n",
    "        user_vectors = user_vectors\n",
    "        item_vectors = item_vectors\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        \n",
    "        users = self.user_emb(user_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "        items = self.item_emb(item_vectors)#.view(-1,sequence_size,self.emb_size)\n",
    "\n",
    "        gru_output,_ = self.gru(torch.cat([users,items],dim=-1))\n",
    "        output_ln = self.linear(gru_output)\n",
    "        output = F.log_softmax(output_ln, dim=-1)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "# #device = torch.device(\"cpu\")\n",
    "# network = LinearGRU(n_users=3,n_items=3,emb_size=20).to(device)\n",
    "# users = np.array([[1,1,1,1]])\n",
    "# items = np.array([[0,1,2,1]])\n",
    "# pred = network(Variable(torch.LongTensor(users)).to(device),Variable(torch.LongTensor(items)).to(device))\n",
    "# pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Lens Prerocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and provided functions\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import wget\n",
    "from io import StringIO \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from tqdm import tqdm # Very useful library to see progress bar during range iterations: just type `for i in tqdm(range(10)):`\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "\n",
    "def move_timestamps_to_end(x,max_order):\n",
    "    new_order = x.groupby('timestamp', sort=True).grouper.group_info[0]\n",
    "    x[\"timestamp\"] = (max_order - new_order.max())+new_order\n",
    "    return x\n",
    "\n",
    "def normalize_timestamp(x):\n",
    "    x[\"timestamp\"] = x.groupby(['timestamp','movieid'], sort=True).grouper.group_info[0]\n",
    "    return x\n",
    "\n",
    "def set_timestamp_length(x):\n",
    "    x['length'] = len(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def to_matrices(ml_data):\n",
    "    ml_data = split_by_groups(ml_data)\n",
    "    \n",
    "    ml_data_max_order = ml_data['timestamp'].max()\n",
    "    ml_data = ml_data.groupby(\"index\").apply(move_timestamps_to_end,ml_data_max_order)\n",
    "\n",
    "    data_shape = ml_data[['index', 'timestamp']].max()+1\n",
    "    data_matrix = sp.sparse.csr_matrix((ml_data['movieid'],\n",
    "                                   (ml_data['index'], ml_data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    mask_matrix = sp.sparse.csr_matrix((np.ones(len(ml_data)),\n",
    "                                   (ml_data['index'], ml_data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    \n",
    "    ml_data_users = ml_data.drop_duplicates(['index'])\n",
    "    user_data_shape = ml_data_users['index'].max()+1\n",
    "    user_vector = sp.sparse.csr_matrix((ml_data_users['userid'],\n",
    "                                   (ml_data_users['index'],np.zeros(user_data_shape))),\n",
    "                                    shape=(user_data_shape,1), dtype=np.float64).todense()\n",
    "    user_matrix = np.tile(user_vector,(1,data_shape[1]))\n",
    "    return data_matrix, mask_matrix, user_matrix\n",
    "\n",
    "def train_val_test_split(ml_data):\n",
    "    ml_data = ml_data.groupby(\"userid\").apply(set_timestamp_length)\n",
    "    max_time_stamp = ml_data['length']\n",
    "    timestamp = ml_data['timestamp']\n",
    "    ml_data_train = ml_data[timestamp<max_time_stamp*0.9].groupby(\"userid\").apply(normalize_timestamp)\n",
    "    ml_data_val = ml_data[(0.9*max_time_stamp<=timestamp)&(timestamp<0.95*max_time_stamp)]\\\n",
    "                                                            .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    ml_data_test = ml_data[0.95*max_time_stamp<=timestamp].groupby(\"userid\").apply(normalize_timestamp)\n",
    "    return ml_data_train, ml_data_val, ml_data_test\n",
    "\n",
    "def split_by_groups(ml_data,group_length=20):\n",
    "    ml_data[\"group\"] = ml_data['timestamp']//group_length\n",
    "    ml_data[\"timestamp\"] = ml_data['timestamp']%group_length\n",
    "    ml_data[\"index\"] = ml_data.groupby(['userid','group'], sort=False).grouper.group_info[0]\n",
    "    return ml_data\n",
    "\n",
    "def get_movielens_data(local_file=None):\n",
    "    '''Downloads movielens data, normalizes users, timesteps and movies ids,\n",
    "    returns data in sparse CSR format.\n",
    "    '''\n",
    "    if not local_file:\n",
    "        print('Downloading data...')\n",
    "        zip_file_url = 'http://files.grouplens.org/datasets/movielens/ml-10m.zip'\n",
    "        zip_contents = wget.download(zip_file_url)\n",
    "        print('Done.')\n",
    "    else:\n",
    "        zip_contents = local_file\n",
    "    \n",
    "    print('Loading data into memory...')\n",
    "    with zipfile.ZipFile(\"ml-10m.zip\") as zfile:\n",
    "        zdata = zfile.read('ml-10M100K/ratings.dat').decode()\n",
    "        delimiter = ';'\n",
    "        zdata = zdata.replace('::', delimiter) # makes data compatible with pandas c-engine\n",
    "        ml_data = pd.read_csv(StringIO(zdata), sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'movieid' ,'rating','timestamp'],\n",
    "                                  usecols=['userid', 'movieid','rating','timestamp'])\n",
    "\n",
    "    print(\"Normalizing indices to avoid gaps\")\n",
    "\n",
    "    # normalize indices to avoid gaps\n",
    "    ml_data['movieid'] = ml_data.groupby('movieid', sort=False).grouper.group_info[0]\n",
    "    ml_data['userid'] = ml_data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    ml_data = ml_data.groupby(\"userid\").apply(normalize_timestamp)\n",
    "\n",
    "    # build sparse user-movie matrix\n",
    "    print(\"Splitting into train, validation and test parts\")\n",
    "    \n",
    "    ml_data_train, ml_data_val, ml_data_test = train_val_test_split(ml_data)\n",
    "        \n",
    "    train_items, train_mask, train_users= to_matrices(ml_data_train.copy())\n",
    "    val_items, val_mask, val_users = to_matrices(ml_data_val.copy())\n",
    "    test_items, test_mask, test_users = to_matrices(ml_data_test.copy())\n",
    "    \n",
    "    print('Done.')\n",
    "    return (train_items, train_mask, train_users),\\\n",
    "           (val_items, val_mask, val_users),\\\n",
    "           (test_items, test_mask, test_users)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory...\n",
      "Normalizing indices to avoid gaps\n",
      "Splitting into train, validation and test parts\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "(train_items, train_mask,train_users),\\\n",
    "(val_items, val_mask,val_users),\\\n",
    "(test_items, test_mask,test_users) = get_movielens_data(\"ml-10m.zip\")\n",
    "\n",
    "np.save(\"train_items\",train_items)\n",
    "np.save('train_mask',train_mask)\n",
    "np.save('train_users',train_users)\n",
    "np.save('val_items',val_items)\n",
    "np.save('val_mask',val_mask)\n",
    "np.save('val_users',val_users)\n",
    "np.save('test_items',test_items)\n",
    "np.save('test_mask',test_mask)\n",
    "np.save('test_users',test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_items = np.load(\"train_items.npy\")\n",
    "train_mask = np.load(\"train_mask.npy\")\n",
    "train_users = np.load(\"train_users.npy\")\n",
    "val_items = np.load(\"val_items.npy\")\n",
    "val_mask = np.load(\"val_mask.npy\")\n",
    "val_users = np.load(\"val_users.npy\")\n",
    "test_items = np.load(\"test_items.npy\")\n",
    "test_mask = np.load(\"test_mask.npy\")\n",
    "test_users = np.load(\"test_users.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "n_users = int(test_users.max()+1)\n",
    "n_items = int(np.max([train_items.max()+1,val_items.max()+1,test_items.max()])+1)\n",
    "network = LinearGRU(n_users=n_users,n_items=n_items).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "opt = torch.optim.Adam(network.parameters(),lr =0.001)\n",
    "\n",
    "history = []\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(train_users),torch.LongTensor(train_items),torch.FloatTensor(train_mask))),\\\n",
    "            batch_size=100,shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.LongTensor(val_users),torch.LongTensor(val_items),torch.FloatTensor(val_mask))),\\\n",
    "            batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4805c2d7a19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# train with backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "def validate_lce(network):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in val_loader:\n",
    "\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "            actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "            loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    i=0\n",
    "    for user_batch_ix,item_batch_ix, mask_batch_ix in train_loader:\n",
    "        network.train()\n",
    "        user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "        item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "        mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "        logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "        # compute loss\n",
    "        predictions_logp = logp_seq[:, :-1]*mask_batch_ix[:, :-1,None]\n",
    "        actual_next_tokens = item_batch_ix[:, 1:]\n",
    "\n",
    "        logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "        loss = -logp_next.sum()/mask_batch_ix[:, :-1].sum()\n",
    "\n",
    "        # train with backprop\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        if (i+1)%500==0:\n",
    "            val_loss = validate_lce(network)\n",
    "            history.append(val_loss)\n",
    "\n",
    "            clear_output(True)\n",
    "            plt.title(\"Validation error\")\n",
    "            plt.plot(history)\n",
    "            plt.ylabel('Cross-entropy Error')\n",
    "            plt.xlabel('#iter')\n",
    "            plt.show()\n",
    "        i+=1\n",
    "\n",
    "val_loss = validate_lce(network)\n",
    "history.append(val_loss)\n",
    "\n",
    "clear_output(True)\n",
    "plt.plot(history,label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mrr(network,k):\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:,-2]\n",
    "            _,ind = torch.topk(predictions_logp, k,dim=-1)\n",
    "            mrr = torch.zeros(predictions_logp.size())\n",
    "            mrr.scatter_(-1,ind.cpu(),1/torch.range(1,k).repeat(*ind.size()[:-1],1).type(torch.FloatTensor).cpu())\n",
    "            actual_next_tokens = item_batch_ix[:, -1]\n",
    "\n",
    "            logp_next = torch.gather(mrr.to(device)*mask_batch_ix[:, -2,None], dim=1, index=actual_next_tokens[:,None])\n",
    "#             if mask_batch_ix[:,-2].sum() >0:\n",
    "            loss = logp_next.sum()/mask_batch_ix[:,-2].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect() \n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def validate_recall(network,k):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    \n",
    "    network.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for user_batch_ix,item_batch_ix, mask_batch_ix in test_loader:\n",
    "            user_batch_ix = Variable(user_batch_ix).to(device)\n",
    "            item_batch_ix = Variable(item_batch_ix).to(device)\n",
    "            mask_batch_ix = Variable(mask_batch_ix).to(device)\n",
    "\n",
    "            logp_seq = network(user_batch_ix, item_batch_ix)\n",
    "            # compute loss\n",
    "            predictions_logp = logp_seq[:, -2]\n",
    "            minus_kth_biggest_logp,_ = torch.kthvalue(-predictions_logp.cpu(), k,dim=-1,keepdim=True)\n",
    "            prediicted_kth_biggest = (predictions_logp>(-minus_kth_biggest_logp.to(device)))\\\n",
    "                                        .type(torch.FloatTensor).to(device)\n",
    "            actual_next_tokens = item_batch_ix[:, -1]\n",
    "\n",
    "            logp_next = torch.gather(prediicted_kth_biggest*mask_batch_ix[:, -2,None], dim=1, index=actual_next_tokens[:,None])\n",
    "            loss = logp_next.sum()/mask_batch_ix[:,-2].sum()\n",
    "            losses.append(loss.cpu().data.numpy())\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR score for Linear User-based GRU:  0.053085506\n",
      "Recall score for Linear User-based GRU:  0.16474381\n"
     ]
    }
   ],
   "source": [
    "linear_mrr_score = validate_mrr(network,20)\n",
    "print(\"MRR score for Linear User-based GRU: \",linear_mrr_score)\n",
    "linear_recall_score = validate_recall(network,20)\n",
    "print(\"Recall score for Linear User-based GRU: \",linear_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
