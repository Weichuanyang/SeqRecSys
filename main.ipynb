{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear User Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class LinearGRU(nn.Module):\n",
    "    def __init__(self, n_users,n_items, emb_size=None, hidden_units=1000,dropout = 0):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        if emb_size == None:\n",
    "            emb_size = hidden_units\n",
    "        ## todo why embeding?\n",
    "        self.user_emb = nn.Embedding(n_users,emb_size)\n",
    "        self.item_emb = nn.Embedding(n_items,emb_size)\n",
    "        self.gru = nn.GRU(input_size = n_users+n_items,hidden_size = hidden_units,dropout = dropout,batch_first=True)\n",
    "        \n",
    "    def forward(self, user_vectors, item_vectors):\n",
    "        \n",
    "#         print(user_vectors.size())\n",
    "#         print(user_vectors.squeeze(0).size())\n",
    "        user_vectors = user_vectors.unsqueeze(-1)\n",
    "        item_vectors = item_vectors.unsqueeze(-1)\n",
    "        sequence_size = user_vectors.size()[1]\n",
    "        users = self.user_emb(user_vectors.squeeze(0)).view(-1,sequence_size,self.n_users)\n",
    "        items = self.item_emb(item_vectors.squeeze(0)).view(-1,sequence_size,self.n_items)\n",
    "        \n",
    "        gru_output,_ = self.gru(torch.cat([users,items],dim=-1))\n",
    "\n",
    "        output = F.log_softmax(gru_output, dim=-1)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "network = LinearGRU(3,3,3,3)\n",
    "users = np.array([[1,1,1,1]])\n",
    "items = np.array([[0,1,2,1]])\n",
    "print(users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       " -1.2552 -1.0975 -0.9642\n",
       " -1.4716 -0.9283 -0.9803\n",
       " -1.5249 -1.3298 -0.6581\n",
       " -1.6313 -1.0054 -0.8246\n",
       "[torch.FloatTensor of size 1x4x3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network(Variable(torch.from_numpy(users)),Variable(torch.from_numpy(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory...\n",
      "   userid  movieid  rating  timestamp\n",
      "0       1      122     5.0  838985046\n",
      "1       1      185     5.0  838983525\n",
      "2       1      231     5.0  838983392\n",
      "3       1      292     5.0  838983421\n",
      "4       1      316     5.0  838983392\n",
      "   userid  movieid  rating  timestamp\n",
      "0       0        0     5.0          0\n",
      "1       0        1     5.0          1\n",
      "2       0        2     5.0          2\n",
      "3       0        3     5.0          3\n",
      "4       0        4     5.0          2\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Libraries and provided functions\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import wget\n",
    "from io import StringIO \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from tqdm import tqdm # Very useful library to see progress bar during range iterations: just type `for i in tqdm(range(10)):`\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import namedtuple\n",
    "import sys\n",
    "\n",
    "def get_movielens_data(local_file=None):\n",
    "    '''Downloads movielens data, normalizes users and movies ids,\n",
    "    returns data in sparse CSR format.\n",
    "    '''\n",
    "    if not local_file:\n",
    "        print('Downloading data...')\n",
    "        zip_file_url = 'http://files.grouplens.org/datasets/movielens/ml-10m.zip'\n",
    "        zip_contents = wget.download(zip_file_url)\n",
    "        print('Done.')\n",
    "    else:\n",
    "        zip_contents = local_file\n",
    "    \n",
    "    print('Loading data into memory...')\n",
    "    with zipfile.ZipFile(zip_contents) as zfile:\n",
    "        zdata = zfile.read('ml-10M100K/ratings.dat').decode()\n",
    "        delimiter = ';'\n",
    "        zdata = zdata.replace('::', delimiter) # makes data compatible with pandas c-engine\n",
    "        ml_data = pd.read_csv(StringIO(zdata), sep=delimiter, header=None, engine='c',\n",
    "                                  names=['userid', 'movieid', 'rating', 'timestamp'],\n",
    "                                  usecols=['userid', 'movieid', 'rating','timestamp'])\n",
    "    print(ml_data.head())\n",
    "    # normalize indices to avoid gaps\n",
    "    ml_data['movieid'] = ml_data.groupby('movieid', sort=False).grouper.group_info[0]\n",
    "    ml_data['userid'] = ml_data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    ml_data['timestamp'] = ml_data.groupby('timestamp', sort=False).grouper.group_info[0]\n",
    "    print(ml_data.head())\n",
    "    # build sparse user-movie matrix\n",
    "    data_shape = ml_data[['userid', 'movieid']].max() + 1\n",
    "    data_matrix = sp.sparse.csr_matrix((ml_data['rating'],\n",
    "                                       (ml_data['userid'], ml_data['movieid'])),\n",
    "                                        shape=data_shape, dtype=np.float64)\n",
    "    \n",
    "    print('Done.')\n",
    "    return data_matrix\n",
    "\n",
    "def split_data(data, test_ratio=0.2):\n",
    "    '''Randomly splits data into training and testing datasets. Default ratio is 80%/20%.\n",
    "    Returns datasets in namedtuple format for convenience. Usage:\n",
    "    \n",
    "    train_data, test_data = split_data(data_matrix)\n",
    "    \n",
    "    or\n",
    "    \n",
    "    movielens_data = split_data(data_matrix)\n",
    "    \n",
    "    and later in code: \n",
    "    \n",
    "    do smth with movielens_data.train \n",
    "    do smth with movielens_data.test\n",
    "    '''\n",
    "    \n",
    "    num_users = data.shape[0]\n",
    "    idx = np.zeros((num_users,), dtype=bool)\n",
    "    sel = np.random.choice(num_users, int(test_ratio*num_users), replace=False)\n",
    "    np.put(idx, sel, True)\n",
    "    \n",
    "    Movielens_data = namedtuple('MovieLens10M', ['train', 'test'])\n",
    "    movielens_data = Movielens_data(train=data[~idx, :], test=data[idx, :])\n",
    "    return movielens_data\n",
    "\n",
    "Data = get_movielens_data(\"ml-10m.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5., 5., 5., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 3., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
