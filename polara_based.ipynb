{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara import RecommenderData\n",
    "from polara import SVDModel\n",
    "from polara import get_movielens_data\n",
    "from polara.tools.preprocessing import filter_sessions_by_length\n",
    "from polara.evaluation import evaluation_engine as ee\n",
    "import numpy as np\n",
    "import scipy.sparse as SP\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np, scipy.stats as st\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_train_items = np.load(\"ml_train_items.npy\")\n",
    "ml_train_mask = np.load(\"ml_train_mask.npy\")\n",
    "ml_train_users = np.load(\"ml_train_users.npy\")\n",
    "ml_val_items = np.load(\"ml_val_items.npy\")\n",
    "ml_val_mask = np.load(\"ml_val_mask.npy\")\n",
    "ml_val_users = np.load(\"ml_val_users.npy\")\n",
    "ml_test_items = np.load(\"ml_test_items.npy\")\n",
    "ml_test_mask = np.load(\"ml_test_mask.npy\")\n",
    "ml_test_users = np.load(\"ml_test_users.npy\")\n",
    "ml_train_user_idx = np.load('ml_train_user_idx.npy')\n",
    "ml_train_item_idx = np.load('ml_train_item_idx.npy')\n",
    "ml_train_feedback = np.load('ml_train_feedback.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_train_items = np.load(\"lf_train_items.npy\")\n",
    "lf_train_mask = np.load(\"lf_train_mask.npy\")\n",
    "lf_train_users = np.load(\"lf_train_users.npy\")\n",
    "lf_val_items = np.load(\"lf_val_items.npy\")\n",
    "lf_val_mask = np.load(\"lf_val_mask.npy\")\n",
    "lf_val_users = np.load(\"lf_val_users.npy\")\n",
    "lf_test_items = np.load(\"lf_test_items.npy\")\n",
    "lf_test_mask = np.load(\"lf_test_mask.npy\")\n",
    "lf_test_users = np.load(\"lf_test_users.npy\")\n",
    "lf_train_user_idx = np.load('lf_train_user_idx.npy')\n",
    "lf_train_item_idx = np.load('lf_train_item_idx.npy')\n",
    "lf_train_feedback = np.load('lf_train_feedback.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Evfro/polara.git@develop\n",
      "  Cloning https://github.com/Evfro/polara.git (to revision develop) to /tmp/pip-req-build-0a3rx0t8\n",
      "Building wheels for collected packages: polara\n",
      "  Running setup.py bdist_wheel for polara ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-x7hk2c0d/wheels/95/b2/f8/18e769bc21d1fc5323b933f0ab7261b9521a589243f7549bf4\n",
      "Successfully built polara\n",
      "Installing collected packages: polara\n",
      "  Found existing installation: polara 0.5.3\n",
      "    Uninstalling polara-0.5.3:\n",
      "      Successfully uninstalled polara-0.5.3\n",
      "Successfully installed polara-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade git+https://github.com/Evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gaps(data):\n",
    "    data['movieid'] = ml_data.groupby('movieid', sort=False).grouper.group_info[0]\n",
    "    data['userid'] = ml_data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_timestamp(x):\n",
    "    x[\"timestamp\"] = np.argsort(list(x[\"timestamp\"]))\n",
    "    return x\n",
    "\n",
    "def length_col(x):\n",
    "    x['timestamp'] = len(x)\n",
    "    return x\n",
    "\n",
    "def train_test_val_split(data):\n",
    "    \n",
    "    data = data.groupby(\"userid\").apply(normalize_timestamp)\n",
    "    lc = data.groupby(\"userid\").apply(length_col)\n",
    "    max_time_stamp = lc['timestamp']\n",
    "    timestamp = data['timestamp']\n",
    "    data_train = data[timestamp<max_time_stamp*0.9]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_val = data[(0.9*max_time_stamp<=timestamp)&(timestamp<0.95*max_time_stamp)]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_test = data[0.95*max_time_stamp<=timestamp]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    return data_train, data_val,data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrices(data):\n",
    "    data = split_by_groups(data)\n",
    "    \n",
    "    data_max_order = data['timestamp'].max()\n",
    "    data = data.groupby(\"index\").apply(move_timestamps_to_end,data_max_order)\n",
    "\n",
    "    data_shape = data[['index', 'timestamp']].max()+1\n",
    "    data_matrix = sp.sparse.csr_matrix((data['itemid'],\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    mask_matrix = sp.sparse.csr_matrix((np.ones(len(data)),\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    \n",
    "    data_users = data.drop_duplicates(['index'])\n",
    "    user_data_shape = data_users['index'].max()+1\n",
    "    user_vector = sp.sparse.csr_matrix((data_users['userid'],\n",
    "                                   (data_users['index'],np.zeros(user_data_shape))),\n",
    "                                    shape=(user_data_shape,1), dtype=np.float64).todense()\n",
    "    user_matrix = np.tile(user_vector,(1,data_shape[1]))\n",
    "    return data_matrix, mask_matrix, user_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = get_movielens_data(\"ml-10m.zip\",include_time=True)\n",
    "ml_data = remove_gaps(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train, ml_data_val,ml_data_test = train_test_val_split(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_ml_data_train, um_ml_data_val,um_ml_data_test =\\\n",
    "                    ml_data_train[[\"userid\",\"movieid\",\"rating\"]],\\\n",
    "                    ml_data_val[[\"userid\",\"movieid\",\"rating\"]],\\\n",
    "                    ml_data_test[[\"userid\",\"movieid\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_time_train, ml_time_val,ml_time_test =\\\n",
    "                    ml_data_train[[\"timestamp\"]],\\\n",
    "                    ml_data_val[[\"timestamp\"]],\\\n",
    "                    ml_data_test[[\"timestamp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = RecommenderData(None, 'userid', 'movieid', 'rating', seed=0)\n",
    "data_model.holdout_size = 1\n",
    "data_model.random_holdout = False\n",
    "data_model.warm_start = False\n",
    "data_model.permute_tops = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_model.prepare_training_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurentModel(RecommenderModel):\n",
    "    def __init__(self, train ,*args, **kwargs):\n",
    "        super(RecurentModel, self).__init__(None, 'userid', 'movieid', 'rating', *args, **kwargs)\n",
    "        \n",
    "        self.method = 'RecommenderModel' # pick some meaningful name\n",
    "\n",
    "    def build(self):\n",
    "        # build model - calculate item-to-item matrix\n",
    "        user_item_matrix = self.get_training_matrix()\n",
    "        # rating matrix product  R^T R  gives cooccurrences count\n",
    "        i2i_matrix = user_item_matrix.T.dot(user_item_matrix) # gives CSC format\n",
    "        # exclude \"self-links\" and ensure only non-zero elements are stored\n",
    "        i2i_matrix.setdiag(0)\n",
    "        i2i_matrix.eliminate_zeros()\n",
    "        # store matrix for generating recommendations\n",
    "        self.i2i_matrix = i2i_matrix\n",
    "\n",
    "    def get_recommendations(self):\n",
    "        # get test users information and generate top-k recommendations\n",
    "        test_matrix, test_data = self.get_test_matrix()\n",
    "        # calculate predicted scores\n",
    "        i2i_scores = test_matrix.dot(self.i2i_matrix)\n",
    "        # prevent seen items from appearing in recommendations\n",
    "        if self.filter_seen:\n",
    "            self.downvote_seen_items(i2i_scores, test_data)\n",
    "        # generate top-k recommendations for every test user\n",
    "        top_recs = self.get_topk_elements(i2i_scores)\n",
    "        return top_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara.lib.optimize import sgd_step, sgd_step_biased\n",
    "\n",
    "def basic_matrix_factorization(user_idx, item_idx, feedback,\n",
    "                               rank=10, lrate=0.01, reg=0.1,\n",
    "                               num_epochs=30, tol=1e-4, biased=False,\n",
    "                               seed=None, verbose=True):\n",
    "    n_users = user_idx.max() + 1\n",
    "    n_items = item_idx.max() + 1\n",
    "   \n",
    "    random_state = np.random.RandomState(seed) if seed else np.random\n",
    "    P = random_state.normal(scale=0.1, size=(n_users, rank))\n",
    "    Q = random_state.normal(scale=0.1, size=(n_items, rank))\n",
    "   \n",
    "    if biased:\n",
    "        t = random_state.normal(scale=0.1, size=n_users)\n",
    "        f = random_state.normal(scale=0.1, size=n_items)\n",
    "        m = np.mean(feedback[np.where(feedback != 0)])\n",
    "        biases = [t, f, m]\n",
    "    else:\n",
    "        biases = []\n",
    "       \n",
    "    basic_sgd_step = sgd_step_biased if biases else sgd_step\n",
    " \n",
    "    last_err = np.finfo(np.float64).max\n",
    "    for epoch in range(num_epochs):\n",
    "        new_err = basic_sgd_step(user_idx, item_idx, feedback, P, Q, *biases, lrate, reg)       \n",
    "        err_delta = abs(last_err - new_err) / last_err\n",
    "       \n",
    "        if verbose:\n",
    "            rmse = np.sqrt(new_err / len(feedback))\n",
    "            print('Epoch {} RMSE: {}'.format(epoch+1, rmse))\n",
    "       \n",
    "        last_err = new_err\n",
    "        if err_delta < tol: break\n",
    "    return P, Q, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True, nogil=True)\n",
    "def sgd_step_update(users_idx, items_idx, feedbacks, P, Q, eta, lambd):\n",
    "    cum_error = 0\n",
    "    for k, a in enumerate(feedbacks):\n",
    "        i = users_idx[k]\n",
    "        j = items_idx[k]\n",
    "\n",
    "        pi = P[i, :]\n",
    "        qj = Q[j, :]\n",
    "\n",
    "        e = a - np.dot(pi, qj)\n",
    "\n",
    "        new_pi = pi + eta * (e*qj - lambd*pi)\n",
    "        #new_qj = qj + eta * (e*pi - lambd*qj)\n",
    "\n",
    "        P[i, :] = new_pi\n",
    "        #Q[j, :] = new_qj\n",
    "\n",
    "        cum_error += e*e\n",
    "    return cum_error\n",
    "\n",
    "def basic_matrix_factorization_folding_in(user_idx, item_idx, feedback,P,Q,\n",
    "                               lrate=0.01, reg=0.1,\n",
    "                               num_epochs=30, tol=1e-4, verbose=True):\n",
    "    last_err = np.finfo(np.float64).max\n",
    "    for epoch in range(num_epochs):\n",
    "        new_err = sgd_step_update(user_idx, item_idx, feedback, P, Q, lrate, reg)       \n",
    "        err_delta = abs(last_err - new_err) / last_err\n",
    "       \n",
    "        if verbose:\n",
    "            rmse = np.sqrt(new_err / len(feedback))\n",
    "            print('Epoch {} RMSE: {}'.format(epoch+1, rmse))\n",
    "       \n",
    "        last_err = new_err\n",
    "        if err_delta < tol: break\n",
    "    return P, Q\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(items, mask, users):\n",
    "    targets = items[:,-1]\n",
    "    items = [items[i,:-1][mask[i,:-1]==1] for i in range(items.shape[0])]\n",
    "    users = [users[i][mask[i]==1] for i in range(users.shape[0])]\n",
    "    return items,users,targets\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95,num_parts = 5):\n",
    "    part_len = len(data)//num_parts\n",
    "    estimations = []\n",
    "    for i in range(num_parts):\n",
    "        est = np.mean(data[part_len*i:part_len*(i+1)])\n",
    "        estimations.append(est)\n",
    "    a = 1.0*np.array(estimations)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, h\n",
    "\n",
    "#@jit(nopython=True, nogil=True)\n",
    "def estimate_model(P,Q,items,masks,users,reg = 0.1):\n",
    "    items,users,targets  = prepare_data(items, masks, users)\n",
    "    mrrs = []\n",
    "    recalls = []\n",
    "   \n",
    "    for row_inx in range(len(items)):\n",
    "        new_P = P.copy()\n",
    "        \n",
    "        feedback = np.ones(items[row_inx].shape[0])\n",
    "        if len(feedback)!=0:\n",
    "            basic_matrix_factorization_folding_in(users[row_inx][:-1].astype(np.int32), items[row_inx].astype(np.int32),feedback,new_P,Q.copy(),\n",
    "                                   lrate=0.01, reg=reg,\n",
    "                                   num_epochs=30, tol=1e-4, verbose=False)\n",
    "        user = int(users[row_inx][-1])\n",
    "        consumed_items = np.argwhere(train_matrix[user]>=1).T[0]\n",
    "        recommendation = new_P[user].dot(Q.T)\n",
    "        recommendation[consumed_items] = -np.inf\n",
    " \n",
    "        true_consumption = targets[row_inx]\n",
    "        mrrs.append(mrr_at_k(recommendation,true_consumption,k=20))\n",
    "        recalls.append(recall_at_k(recommendation,true_consumption,k=20))\n",
    "        \n",
    "    mrr, h_mrr = mean_confidence_interval(mrrs)\n",
    "    recall, h_recall = mean_confidence_interval(recalls)\n",
    "    \n",
    "    return (mrr, h_mrr),(recall, h_recall)\n",
    "    \n",
    "@jit(nopython=True, nogil=True)\n",
    "def recall_at_k(recommendation,true_consumption,k=20):\n",
    "    topk_inds = recommendation.argsort()[-k:][::-1]\n",
    "    reccommnded_topk_items = np.zeros(recommendation.shape)\n",
    "    reccommnded_topk_items[topk_inds] = 1\n",
    "    \n",
    "    recall = reccommnded_topk_items[int(true_consumption)]\n",
    "    return recall\n",
    "\n",
    "@jit(nopython=True, nogil=True)\n",
    "def mrr_at_k(recommendation,true_consumption,k=20):\n",
    "    topk_inds = recommendation.argsort()[-k:][::-1]\n",
    "    rr = np.zeros(recommendation.shape)\n",
    "    rr[topk_inds] = 1/np.arange(1,k+1)    \n",
    "    current_rr = rr[int(true_consumption)]\n",
    "    return current_rr\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "train_matrix = np.array(sp.sparse.csr_matrix((np.ones(len(ml_train_user_idx)),\n",
    "                               (ml_train_user_idx, ml_train_item_idx)),\n",
    "                                shape=(max(ml_train_user_idx)+1,max(ml_train_item_idx)+1), dtype=np.float64).todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 1.1889509722951297\n",
      "Epoch 2 RMSE: 0.9005314957384513\n",
      "Epoch 3 RMSE: 0.8463680763042712\n",
      "Epoch 4 RMSE: 0.8188051422034335\n",
      "Epoch 5 RMSE: 0.8004663158387065\n",
      "Epoch 6 RMSE: 0.7855627864243409\n",
      "Epoch 7 RMSE: 0.7732885934551574\n",
      "Epoch 8 RMSE: 0.7632023403587169\n",
      "Epoch 9 RMSE: 0.7548784181251089\n",
      "Epoch 10 RMSE: 0.7479567842743502\n",
      "Epoch 11 RMSE: 0.742152630887336\n",
      "Epoch 12 RMSE: 0.7372427424804076\n",
      "Epoch 13 RMSE: 0.7330523912264771\n",
      "Epoch 14 RMSE: 0.7294447595737159\n",
      "Epoch 15 RMSE: 0.7263125637673405\n",
      "Epoch 16 RMSE: 0.7235714286511026\n",
      "Epoch 17 RMSE: 0.7211546768303492\n",
      "Epoch 18 RMSE: 0.7190092797572853\n",
      "Epoch 19 RMSE: 0.7170927493456211\n",
      "Epoch 20 RMSE: 0.7153707702341925\n",
      "Epoch 21 RMSE: 0.7138154014210378\n",
      "Epoch 22 RMSE: 0.7124037087144436\n",
      "Epoch 23 RMSE: 0.7111167205435434\n",
      "Epoch 24 RMSE: 0.7099386259592084\n",
      "Epoch 25 RMSE: 0.708856154402729\n",
      "Epoch 26 RMSE: 0.7078580925338287\n",
      "Epoch 27 RMSE: 0.706934905051986\n",
      "Epoch 28 RMSE: 0.7060784349627898\n",
      "Epoch 29 RMSE: 0.7052816649704758\n",
      "Epoch 30 RMSE: 0.7045385262243349\n"
     ]
    }
   ],
   "source": [
    "# train_feedback[:] = 1\n",
    "P, Q, _ = basic_matrix_factorization(ml_train_user_idx, ml_train_item_idx, ml_train_feedback\\\n",
    "                                     ,rank=20,reg = 0.01,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for MF on  MovieLens :  0.004567202376613807 ± 0.001339522261853232\n",
      "Recall@20 score for MF on MovieLens :  0.019013581129378128 ± 0.005759417598196718\n"
     ]
    }
   ],
   "source": [
    "(mrr, h_mrr),(recall, h_recall), = estimate_model(P,Q,ml_test_items, ml_test_mask, ml_test_users,reg = 0.01)\n",
    "ds_name = \"MovieLens\"\n",
    "print(\"MRR@20 score for MF on \", ds_name,\": \",mrr,\"±\",h_mrr)\n",
    "print(\"Recall@20 score for MF on\",ds_name,\": \",recall,\"±\",h_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "train_matrix = np.array(sp.sparse.csr_matrix((np.ones(len(lf_train_user_idx)),\n",
    "                               (lf_train_user_idx, lf_train_item_idx)),\n",
    "                                shape=(max(lf_train_user_idx)+1,max(lf_train_item_idx)+1), dtype=np.float64).todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 0.3340596669149536\n",
      "Epoch 2 RMSE: 0.13568696368576577\n",
      "Epoch 3 RMSE: 0.1049218383223705\n",
      "Epoch 4 RMSE: 0.09057622314985833\n",
      "Epoch 5 RMSE: 0.08137660911293546\n",
      "Epoch 6 RMSE: 0.07470498836488523\n",
      "Epoch 7 RMSE: 0.06951899132109102\n",
      "Epoch 8 RMSE: 0.06530498687693317\n",
      "Epoch 9 RMSE: 0.06177382659572118\n",
      "Epoch 10 RMSE: 0.0587471278538926\n",
      "Epoch 11 RMSE: 0.05610737578875198\n",
      "Epoch 12 RMSE: 0.053773248417684535\n",
      "Epoch 13 RMSE: 0.051686261604353495\n",
      "Epoch 14 RMSE: 0.049803024791237875\n",
      "Epoch 15 RMSE: 0.04809050290396788\n",
      "Epoch 16 RMSE: 0.04652299033682407\n",
      "Epoch 17 RMSE: 0.045080108428995055\n",
      "Epoch 18 RMSE: 0.04374543945472753\n",
      "Epoch 19 RMSE: 0.0425055698978244\n",
      "Epoch 20 RMSE: 0.041349404662183384\n",
      "Epoch 21 RMSE: 0.040267665327025186\n",
      "Epoch 22 RMSE: 0.039252516348822174\n",
      "Epoch 23 RMSE: 0.03829728207687136\n",
      "Epoch 24 RMSE: 0.0373962294371177\n",
      "Epoch 25 RMSE: 0.03654439889919639\n",
      "Epoch 26 RMSE: 0.035737471478104015\n",
      "Epoch 27 RMSE: 0.03497166299194902\n",
      "Epoch 28 RMSE: 0.03424363918652938\n",
      "Epoch 29 RMSE: 0.033550447010573206\n",
      "Epoch 30 RMSE: 0.03288945851658866\n"
     ]
    }
   ],
   "source": [
    "P, Q, _ = basic_matrix_factorization(lf_train_user_idx, lf_train_item_idx, lf_train_feedback\\\n",
    "                                     ,rank=20,reg = 0.01,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@20 score for MF on  LastFM :  1.7397007492385337e-05 ± 2.091678324531542e-05\n",
      "Recall@20 score for MF on LastFM :  0.00018341892883345562 ± 0.00027892912945554624\n"
     ]
    }
   ],
   "source": [
    "(mrr, h_mrr),(recall, h_recall), = estimate_model(P,Q,lf_test_items, lf_test_mask, lf_test_users,reg = 0.01)\n",
    "ds_name = \"LastFM\"\n",
    "print(\"MRR@20 score for MF on \", ds_name,\": \",mrr,\"±\",h_mrr)\n",
    "print(\"Recall@20 score for MF on\",ds_name,\": \",recall,\"±\",h_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating  timestamp\n",
       "0       1      122     5.0  838985046\n",
       "1       1      185     5.0  838983525\n",
       "2       1      231     5.0  838983392\n",
       "3       1      292     5.0  838983421\n",
       "4       1      316     5.0  838983392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data = get_movielens_data(\"ml-10m.zip\", include_time=True)\n",
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (filter_sessions_by_length(ml_data, min_session_length=20)\n",
    "        #.query('rating >= 4')\n",
    "        #.assign(rating=1)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = RecommenderData(data, 'userid', 'movieid', 'rating', custom_order='timestamp', seed=0)\n",
    "data_model.holdout_size = 1\n",
    "data_model.random_holdout = False\n",
    "data_model.warm_start = False\n",
    "data_model.permute_tops = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_model.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, val, shp = data_model.to_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 1.3085293049789994\n",
      "Epoch 2 RMSE: 0.9151132113832263\n",
      "Epoch 3 RMSE: 0.8808651366877939\n",
      "Epoch 4 RMSE: 0.8676692047213754\n",
      "Epoch 5 RMSE: 0.8587222170703273\n",
      "Epoch 6 RMSE: 0.8525469762850404\n",
      "Epoch 7 RMSE: 0.8479598409933002\n",
      "Epoch 8 RMSE: 0.8442665480920708\n",
      "Epoch 9 RMSE: 0.8411850669634959\n",
      "Epoch 10 RMSE: 0.8385955015689102\n"
     ]
    }
   ],
   "source": [
    "P, Q, biases = basic_matrix_factorization(*idx.T, val,rank=20,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Q.dot(P.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = np.argsort(R,axis = 1)[:,-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69878, 20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx, item_idx, fdbk_val = data_model.test_to_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1f95bf1c491b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdbk_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'shape'"
     ]
    }
   ],
   "source": [
    "SP.coo_matrix(fdbk_val,(user_idx,item_idx),shape =(user_idx.max()+1,item_idx.max()+1) ).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 108, 1557, 1564, ..., 1365,  775, 2300])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara import RecommenderData\n",
    "from polara import SVDModel\n",
    "from polara import get_movielens_data\n",
    "from polara.tools.preprocessing import filter_sessions_by_length\n",
    "from polara.evaluation import evaluation_engine as ee\n",
    "import numpy as np\n",
    "import scipy.sparse as SP\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def train_MF():\n",
    "    ml_data = get_movielens_data(\"ml-10m.zip\", include_time=True)\n",
    "    data = (filter_sessions_by_length(ml_data, min_session_length=20)\n",
    "        #.query('rating >= 4')\n",
    "        #.assign(rating=1)\n",
    "       )\n",
    "    data_model = RecommenderData(data, 'userid', 'movieid', 'rating', custom_order='timestamp', seed=0)\n",
    "    #data_model.holdout_size = 1\n",
    "    data_model.random_holdout = False\n",
    "    data_model.warm_start = False\n",
    "    data_model.permute_tops = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
