{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara import RecommenderData\n",
    "from polara import SVDModel\n",
    "from polara import get_movielens_data\n",
    "from polara.tools.preprocessing import filter_sessions_by_length\n",
    "from polara.evaluation import evaluation_engine as ee\n",
    "import numpy as np\n",
    "import scipy.sparse as SP\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "ml_train_items = np.load(\"ml_train_items.npy\")\n",
    "ml_train_mask = np.load(\"ml_train_mask.npy\")\n",
    "ml_train_users = np.load(\"ml_train_users.npy\")\n",
    "ml_val_items = np.load(\"ml_val_items.npy\")\n",
    "ml_val_mask = np.load(\"ml_val_mask.npy\")\n",
    "ml_val_users = np.load(\"ml_val_users.npy\")\n",
    "ml_test_items = np.load(\"ml_test_items.npy\")\n",
    "ml_test_mask = np.load(\"ml_test_mask.npy\")\n",
    "ml_test_users = np.load(\"ml_test_users.npy\")\n",
    "train_user_idx = np.load('train_user_idx.npy')\n",
    "train_item_idx = np.load('train_item_idx.npy')\n",
    "train_feedback = np.load('train_feedback.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Evfro/polara.git@develop\n",
      "  Cloning https://github.com/Evfro/polara.git (to revision develop) to /tmp/pip-req-build-0a3rx0t8\n",
      "Building wheels for collected packages: polara\n",
      "  Running setup.py bdist_wheel for polara ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-x7hk2c0d/wheels/95/b2/f8/18e769bc21d1fc5323b933f0ab7261b9521a589243f7549bf4\n",
      "Successfully built polara\n",
      "Installing collected packages: polara\n",
      "  Found existing installation: polara 0.5.3\n",
      "    Uninstalling polara-0.5.3:\n",
      "      Successfully uninstalled polara-0.5.3\n",
      "Successfully installed polara-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade git+https://github.com/Evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gaps(data):\n",
    "    data['movieid'] = ml_data.groupby('movieid', sort=False).grouper.group_info[0]\n",
    "    data['userid'] = ml_data.groupby('userid', sort=False).grouper.group_info[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_timestamp(x):\n",
    "    x[\"timestamp\"] = np.argsort(list(x[\"timestamp\"]))\n",
    "    return x\n",
    "\n",
    "def length_col(x):\n",
    "    x['timestamp'] = len(x)\n",
    "    return x\n",
    "\n",
    "def train_test_val_split(data):\n",
    "    \n",
    "    data = data.groupby(\"userid\").apply(normalize_timestamp)\n",
    "    lc = data.groupby(\"userid\").apply(length_col)\n",
    "    max_time_stamp = lc['timestamp']\n",
    "    timestamp = data['timestamp']\n",
    "    data_train = data[timestamp<max_time_stamp*0.9]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_val = data[(0.9*max_time_stamp<=timestamp)&(timestamp<0.95*max_time_stamp)]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    data_test = data[0.95*max_time_stamp<=timestamp]\\\n",
    "                    .groupby(\"userid\").apply(normalize_timestamp)\n",
    "    return data_train, data_val,data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrices(data):\n",
    "    data = split_by_groups(data)\n",
    "    \n",
    "    data_max_order = data['timestamp'].max()\n",
    "    data = data.groupby(\"index\").apply(move_timestamps_to_end,data_max_order)\n",
    "\n",
    "    data_shape = data[['index', 'timestamp']].max()+1\n",
    "    data_matrix = sp.sparse.csr_matrix((data['itemid'],\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    mask_matrix = sp.sparse.csr_matrix((np.ones(len(data)),\n",
    "                                   (data['index'], data['timestamp'])),\n",
    "                                    shape=data_shape, dtype=np.float64).todense()\n",
    "    \n",
    "    data_users = data.drop_duplicates(['index'])\n",
    "    user_data_shape = data_users['index'].max()+1\n",
    "    user_vector = sp.sparse.csr_matrix((data_users['userid'],\n",
    "                                   (data_users['index'],np.zeros(user_data_shape))),\n",
    "                                    shape=(user_data_shape,1), dtype=np.float64).todense()\n",
    "    user_matrix = np.tile(user_vector,(1,data_shape[1]))\n",
    "    return data_matrix, mask_matrix, user_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = get_movielens_data(\"ml-10m.zip\",include_time=True)\n",
    "ml_data = remove_gaps(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train, ml_data_val,ml_data_test = train_test_val_split(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_ml_data_train, um_ml_data_val,um_ml_data_test =\\\n",
    "                    ml_data_train[[\"userid\",\"movieid\",\"rating\"]],\\\n",
    "                    ml_data_val[[\"userid\",\"movieid\",\"rating\"]],\\\n",
    "                    ml_data_test[[\"userid\",\"movieid\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_time_train, ml_time_val,ml_time_test =\\\n",
    "                    ml_data_train[[\"timestamp\"]],\\\n",
    "                    ml_data_val[[\"timestamp\"]],\\\n",
    "                    ml_data_test[[\"timestamp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = RecommenderData(None, 'userid', 'movieid', 'rating', seed=0)\n",
    "data_model.holdout_size = 1\n",
    "data_model.random_holdout = False\n",
    "data_model.warm_start = False\n",
    "data_model.permute_tops = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_model.prepare_training_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurentModel(RecommenderModel):\n",
    "    def __init__(self, train ,*args, **kwargs):\n",
    "        super(RecurentModel, self).__init__(None, 'userid', 'movieid', 'rating', *args, **kwargs)\n",
    "        \n",
    "        self.method = 'RecommenderModel' # pick some meaningful name\n",
    "\n",
    "    def build(self):\n",
    "        # build model - calculate item-to-item matrix\n",
    "        user_item_matrix = self.get_training_matrix()\n",
    "        # rating matrix product  R^T R  gives cooccurrences count\n",
    "        i2i_matrix = user_item_matrix.T.dot(user_item_matrix) # gives CSC format\n",
    "        # exclude \"self-links\" and ensure only non-zero elements are stored\n",
    "        i2i_matrix.setdiag(0)\n",
    "        i2i_matrix.eliminate_zeros()\n",
    "        # store matrix for generating recommendations\n",
    "        self.i2i_matrix = i2i_matrix\n",
    "\n",
    "    def get_recommendations(self):\n",
    "        # get test users information and generate top-k recommendations\n",
    "        test_matrix, test_data = self.get_test_matrix()\n",
    "        # calculate predicted scores\n",
    "        i2i_scores = test_matrix.dot(self.i2i_matrix)\n",
    "        # prevent seen items from appearing in recommendations\n",
    "        if self.filter_seen:\n",
    "            self.downvote_seen_items(i2i_scores, test_data)\n",
    "        # generate top-k recommendations for every test user\n",
    "        top_recs = self.get_topk_elements(i2i_scores)\n",
    "        return top_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara.lib.optimize import sgd_step, sgd_step_biased\n",
    "\n",
    "def basic_matrix_factorization(user_idx, item_idx, feedback,\n",
    "                               rank=10, lrate=0.01, reg=0.1,\n",
    "                               num_epochs=30, tol=1e-4, biased=False,\n",
    "                               seed=None, verbose=True):\n",
    "    n_users = user_idx.max() + 1\n",
    "    n_items = item_idx.max() + 1\n",
    "   \n",
    "    random_state = np.random.RandomState(seed) if seed else np.random\n",
    "    P = random_state.normal(scale=0.1, size=(n_users, rank))\n",
    "    Q = random_state.normal(scale=0.1, size=(n_items, rank))\n",
    "   \n",
    "    if biased:\n",
    "        t = random_state.normal(scale=0.1, size=n_users)\n",
    "        f = random_state.normal(scale=0.1, size=n_items)\n",
    "        m = np.mean(feedback[np.where(feedback != 0)])\n",
    "        biases = [t, f, m]\n",
    "    else:\n",
    "        biases = []\n",
    "       \n",
    "    basic_sgd_step = sgd_step_biased if biases else sgd_step\n",
    " \n",
    "    last_err = np.finfo(np.float64).max\n",
    "    for epoch in range(num_epochs):\n",
    "        new_err = basic_sgd_step(user_idx, item_idx, feedback, P, Q, *biases, lrate, reg)       \n",
    "        err_delta = abs(last_err - new_err) / last_err\n",
    "       \n",
    "        if verbose:\n",
    "            rmse = np.sqrt(new_err / len(feedback))\n",
    "            print('Epoch {} RMSE: {}'.format(epoch+1, rmse))\n",
    "       \n",
    "        last_err = new_err\n",
    "        if err_delta < tol: break\n",
    "    return P, Q, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True, nogil=True)\n",
    "def sgd_step_update(users_idx, items_idx, feedbacks, P, Q, eta, lambd):\n",
    "    cum_error = 0\n",
    "    for k, a in enumerate(feedbacks):\n",
    "        i = users_idx[k]\n",
    "        j = items_idx[k]\n",
    "\n",
    "        pi = P[i, :]\n",
    "        qj = Q[j, :]\n",
    "\n",
    "        e = a - np.dot(pi, qj)\n",
    "\n",
    "        new_pi = pi + eta * (e*qj - lambd*pi)\n",
    "        #new_qj = qj + eta * (e*pi - lambd*qj)\n",
    "\n",
    "        P[i, :] = new_pi\n",
    "        #Q[j, :] = new_qj\n",
    "\n",
    "        cum_error += e*e\n",
    "    return cum_error\n",
    "\n",
    "def basic_matrix_factorization_folding_in(user_idx, item_idx, feedback,P,Q,\n",
    "                               lrate=0.01, reg=0.1,\n",
    "                               num_epochs=30, tol=1e-4, verbose=True):\n",
    "    last_err = np.finfo(np.float64).max\n",
    "    for epoch in range(num_epochs):\n",
    "        new_err = sgd_step_update(user_idx, item_idx, feedback, P, Q, lrate, reg)       \n",
    "        err_delta = abs(last_err - new_err) / last_err\n",
    "       \n",
    "        if verbose:\n",
    "            rmse = np.sqrt(new_err / len(feedback))\n",
    "            print('Epoch {} RMSE: {}'.format(epoch+1, rmse))\n",
    "       \n",
    "        last_err = new_err\n",
    "        if err_delta < tol: break\n",
    "    return P, Q\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(items, mask, users):\n",
    "    targets = items[:,-1]\n",
    "    items = [items[i,:-1][mask[i,:-1]==1] for i in range(items.shape[0])]\n",
    "    users = [users[i][mask[i]==1] for i in range(users.shape[0])]\n",
    "    return items,users,targets\n",
    "\n",
    "#@jit(nopython=True, nogil=True)\n",
    "def estimate_model(P,Q,items,masks,users,reg = 0.1):\n",
    "    items,users,targets  = prepare_data(items, masks, users)\n",
    "    recall = 0\n",
    "    mrr = 0\n",
    "    for row_inx in range(len(items)):\n",
    "        new_P = P.copy()\n",
    "        \n",
    "        feedback = np.ones(items[row_inx].shape[0])\n",
    "        if len(feedback)!=0:\n",
    "            basic_matrix_factorization_folding_in(users[row_inx][:-1].astype(np.int32), items[row_inx].astype(np.int32),feedback,new_P,Q.copy(),\n",
    "                                   lrate=0.01, reg=reg,\n",
    "                                   num_epochs=30, tol=1e-4, verbose=False)\n",
    "        user = int(users[row_inx][-1])\n",
    "#         consumed_items = np.argwhere(train_matrix[user]==1).T[0]\n",
    "        recommendation = new_P[user].dot(Q.T)\n",
    "#         print(recommendation.shape,consumed_items.shape)\n",
    "#         recommendation[consumed_items] = np.inf\n",
    " \n",
    "        true_consumption = targets[row_inx]\n",
    "        recall += recall_at_k(recommendation,true_consumption,k=20)\n",
    "        mrr += mrr_at_k(recommendation,true_consumption,k=20)\n",
    "\n",
    "    recall = recall/len(items)\n",
    "    mrr = mrr/len(items)\n",
    "    return recall,mrr\n",
    "    \n",
    "@jit(nopython=True, nogil=True)\n",
    "def recall_at_k(recommendation,true_consumption,k=20):\n",
    "    topk_inds = recommendation.argsort()[-k:][::-1]\n",
    "#     print(recommendation.min(),recommendation.max(),recommendation[topk_inds])\n",
    "    reccommnded_topk_items = np.zeros(recommendation.shape)\n",
    "    reccommnded_topk_items[topk_inds] = 1\n",
    "    \n",
    "    recall = reccommnded_topk_items[int(true_consumption)]\n",
    "    return recall\n",
    "\n",
    "@jit(nopython=True, nogil=True)\n",
    "def mrr_at_k(recommendation,true_consumption,k=20):\n",
    "    topk_inds = recommendation.argsort()[-k:][::-1]\n",
    "    rr = np.zeros(recommendation.shape)\n",
    "    rr[topk_inds] = 1/np.arange(1,k+1)    \n",
    "    current_rr = rr[int(true_consumption)]\n",
    "    return current_rr\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "train_matrix = np.array(sp.sparse.csr_matrix((np.ones(len(train_user_idx)),\n",
    "                               (train_user_idx, train_item_idx)),\n",
    "                                shape=(max(train_user_idx)+1,max(train_item_idx)+1), dtype=np.float64).todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69877.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_val_users.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  30,  31,  34,  36,  39,  79,  93,  96,  97,  98,  99, 100,\n",
       "       101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "       114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "       127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "       153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "       166, 167, 168, 169, 170, 171, 172, 173, 174])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.argwhere(train_matrix[4]==1).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 1.1602116733082892\n",
      "Epoch 2 RMSE: 0.892380105119991\n",
      "Epoch 3 RMSE: 0.8412350319342731\n",
      "Epoch 4 RMSE: 0.8160498939745181\n",
      "Epoch 5 RMSE: 0.7992666407327196\n",
      "Epoch 6 RMSE: 0.7852194692923646\n",
      "Epoch 7 RMSE: 0.7734121705251865\n",
      "Epoch 8 RMSE: 0.7635637318224214\n",
      "Epoch 9 RMSE: 0.7554188518579745\n",
      "Epoch 10 RMSE: 0.7487078576846461\n",
      "Epoch 11 RMSE: 0.7431573060642813\n",
      "Epoch 12 RMSE: 0.7385267966384735\n",
      "Epoch 13 RMSE: 0.7346225165824813\n",
      "Epoch 14 RMSE: 0.7312942653030555\n",
      "Epoch 15 RMSE: 0.72842721000599\n",
      "Epoch 16 RMSE: 0.7259335561372116\n",
      "Epoch 17 RMSE: 0.7237457171834016\n",
      "Epoch 18 RMSE: 0.7218111361414851\n",
      "Epoch 19 RMSE: 0.7200884793067465\n",
      "Epoch 20 RMSE: 0.7185448648570794\n",
      "Epoch 21 RMSE: 0.7171538421982119\n",
      "Epoch 22 RMSE: 0.7158939088541791\n",
      "Epoch 23 RMSE: 0.7147474118842385\n",
      "Epoch 24 RMSE: 0.7136997257628244\n",
      "Epoch 25 RMSE: 0.7127386306173366\n",
      "Epoch 26 RMSE: 0.7118538370030286\n",
      "Epoch 27 RMSE: 0.7110366189071847\n",
      "Epoch 28 RMSE: 0.7102795274808512\n",
      "Epoch 29 RMSE: 0.7095761655894096\n",
      "Epoch 30 RMSE: 0.7089210086310169\n"
     ]
    }
   ],
   "source": [
    "# train_feedback[:] = 1\n",
    "P, Q, _ = basic_matrix_factorization(train_user_idx, train_item_idx, train_feedback,rank=20,reg = 0.01,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.019819351484826823, 0.004013395621811478)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall,mrr = estimate_model(P,Q,ml_test_items, ml_test_mask, ml_test_users,reg = 0.01)\n",
    "recall,mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,  402., 6696.,  458.,  874., 4069.,  795., 1852.,\n",
       "        267., 1337., 3829., 1199.,  631., 2238., 2003., 1376., 1863.,\n",
       "        815.,  526.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_test_items[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating  timestamp\n",
       "0       1      122     5.0  838985046\n",
       "1       1      185     5.0  838983525\n",
       "2       1      231     5.0  838983392\n",
       "3       1      292     5.0  838983421\n",
       "4       1      316     5.0  838983392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data = get_movielens_data(\"ml-10m.zip\", include_time=True)\n",
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (filter_sessions_by_length(ml_data, min_session_length=20)\n",
    "        #.query('rating >= 4')\n",
    "        #.assign(rating=1)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = RecommenderData(data, 'userid', 'movieid', 'rating', custom_order='timestamp', seed=0)\n",
    "data_model.holdout_size = 1\n",
    "data_model.random_holdout = False\n",
    "data_model.warm_start = False\n",
    "data_model.permute_tops = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_model.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, val, shp = data_model.to_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 RMSE: 1.3085293049789994\n",
      "Epoch 2 RMSE: 0.9151132113832263\n",
      "Epoch 3 RMSE: 0.8808651366877939\n",
      "Epoch 4 RMSE: 0.8676692047213754\n",
      "Epoch 5 RMSE: 0.8587222170703273\n",
      "Epoch 6 RMSE: 0.8525469762850404\n",
      "Epoch 7 RMSE: 0.8479598409933002\n",
      "Epoch 8 RMSE: 0.8442665480920708\n",
      "Epoch 9 RMSE: 0.8411850669634959\n",
      "Epoch 10 RMSE: 0.8385955015689102\n"
     ]
    }
   ],
   "source": [
    "P, Q, biases = basic_matrix_factorization(*idx.T, val,rank=20,num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Q.dot(P.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = np.argsort(R,axis = 1)[:,-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69878, 20)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx, item_idx, fdbk_val = data_model.test_to_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1f95bf1c491b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdbk_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'shape'"
     ]
    }
   ],
   "source": [
    "SP.coo_matrix(fdbk_val,(user_idx,item_idx),shape =(user_idx.max()+1,item_idx.max()+1) ).todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 108, 1557, 1564, ..., 1365,  775, 2300])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polara import RecommenderData\n",
    "from polara import SVDModel\n",
    "from polara import get_movielens_data\n",
    "from polara.tools.preprocessing import filter_sessions_by_length\n",
    "from polara.evaluation import evaluation_engine as ee\n",
    "import numpy as np\n",
    "import scipy.sparse as SP\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def train_MF():\n",
    "    ml_data = get_movielens_data(\"ml-10m.zip\", include_time=True)\n",
    "    data = (filter_sessions_by_length(ml_data, min_session_length=20)\n",
    "        #.query('rating >= 4')\n",
    "        #.assign(rating=1)\n",
    "       )\n",
    "    data_model = RecommenderData(data, 'userid', 'movieid', 'rating', custom_order='timestamp', seed=0)\n",
    "    #data_model.holdout_size = 1\n",
    "    data_model.random_holdout = False\n",
    "    data_model.warm_start = False\n",
    "    data_model.permute_tops = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
